{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:08.823964Z",
     "iopub.status.busy": "2020-09-12T05:47:08.823205Z",
     "iopub.status.idle": "2020-09-12T05:47:15.758339Z",
     "shell.execute_reply": "2020-09-12T05:47:15.757303Z"
    },
    "papermill": {
     "duration": 6.954489,
     "end_time": "2020-09-12T05:47:15.758481",
     "exception": false,
     "start_time": "2020-09-12T05:47:08.803992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01294,
     "end_time": "2020-09-12T05:47:15.784990",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.772050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define helper functions and useful vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.817688Z",
     "iopub.status.busy": "2020-09-12T05:47:15.815907Z",
     "iopub.status.idle": "2020-09-12T05:47:15.818497Z",
     "shell.execute_reply": "2020-09-12T05:47:15.818980Z"
    },
    "papermill": {
     "duration": 0.020522,
     "end_time": "2020-09-12T05:47:15.819094",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.798572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will tell us the columns we are predicting\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.856138Z",
     "iopub.status.busy": "2020-09-12T05:47:15.855349Z",
     "iopub.status.idle": "2020-09-12T05:47:15.859535Z",
     "shell.execute_reply": "2020-09-12T05:47:15.859055Z"
    },
    "papermill": {
     "duration": 0.027513,
     "end_time": "2020-09-12T05:47:15.859623",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.832110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.GRU(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.LSTM(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def build_model(gru=False,seq_len=107, pred_len=68, dropout=0.25,\n",
    "                embed_dim=128, hidden_dim=384):\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n",
    "    \n",
    "    inputs_bpps = tf.keras.layers.Input(shape=(seq_len, 1))\n",
    "    \n",
    "\n",
    "    embed0 = tf.keras.layers.Embedding(input_dim=len(token2int0), output_dim=embed_dim)(inputs[:, :, 0])\n",
    "    embed1 = tf.keras.layers.Embedding(input_dim=len(token2int1), output_dim=embed_dim)(inputs[:, :, 1])\n",
    "    embed2 = tf.keras.layers.Embedding(input_dim=len(token2int2), output_dim=embed_dim)(inputs[:, :, 2])\n",
    "    \n",
    "    \n",
    "    embed0 = tf.keras.layers.SpatialDropout1D(.2)(embed0)\n",
    "    embed1 = tf.keras.layers.SpatialDropout1D(.2)(embed1)\n",
    "    embed2 = tf.keras.layers.SpatialDropout1D(.2)(embed2)\n",
    "    \n",
    "    embed = tf.concat([embed0, embed1, embed2], axis=2)\n",
    "    \n",
    "    #reshaped = tf.reshape(\n",
    "    #    embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n",
    "    \n",
    "    embed = tf.keras.layers.SpatialDropout1D(.2)(embed)\n",
    "    \n",
    "    bpps = tf.keras.layers.Dense(embed_dim, activation='linear')(inputs_bpps)\n",
    "    \n",
    "    embed = tf.concat([embed, bpps], axis=2)\n",
    "    \n",
    "    transformer_block = TransformerBlock(512, 8, 512)\n",
    "    embed = transformer_block(embed)\n",
    "    \n",
    "    hidden = gru_layer(hidden_dim, dropout)(embed)\n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "\n",
    "    \n",
    "    #only making predictions on the first part of each sequence\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    \n",
    "    out1 = tf.keras.layers.Dense(5, activation='linear', name='out1')(truncated)\n",
    "    out2 = tf.keras.layers.Dense(5, activation='linear', name='out2')(truncated)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs, inputs_bpps], outputs=[out1, out2])\n",
    "\n",
    "    #some optimizers\n",
    "    adam = tf.optimizers.Adam()\n",
    "    def MCRMSE(y_true, y_pred):\n",
    "        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
    "    \n",
    "    model.compile(optimizer = adam, loss={'out1': MCRMSE, 'out2': 'mae'}, loss_weights={'out1': 0.7, 'out2': 0.3})\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.894673Z",
     "iopub.status.busy": "2020-09-12T05:47:15.893039Z",
     "iopub.status.idle": "2020-09-12T05:47:15.895372Z",
     "shell.execute_reply": "2020-09-12T05:47:15.895926Z"
    },
    "papermill": {
     "duration": 0.023046,
     "end_time": "2020-09-12T05:47:15.896053",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.873007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    return np.transpose(\n",
    "        np.array(\n",
    "            df[cols]\n",
    "            .applymap(lambda seq: [token2int[x] for x in seq])\n",
    "            .values\n",
    "            .tolist()\n",
    "        ),\n",
    "        (0, 2, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013134,
     "end_time": "2020-09-12T05:47:15.922732",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.909598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.957048Z",
     "iopub.status.busy": "2020-09-12T05:47:15.956359Z",
     "iopub.status.idle": "2020-09-12T05:47:16.951033Z",
     "shell.execute_reply": "2020-09-12T05:47:16.950138Z"
    },
    "papermill": {
     "duration": 1.012628,
     "end_time": "2020-09-12T05:47:16.951150",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.938522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('../input//train.json', lines=True)\n",
    "test = pd.read_json('../input//test.json', lines=True)\n",
    "sample_df = pd.read_csv('../input//sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target columns\n",
    "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2int0 = {'G': 0, 'A': 1, 'C': 2, 'U': 3}\n",
    "token2int1 = {'.': 0,  '(': 1, ')': 2}\n",
    "token2int2 = {'E': 0, 'S': 1, 'H': 2, 'B': 3, 'X': 4, 'I': 5, 'M': 6}\n",
    "\n",
    "def convert_seq(x, tmp_dict):\n",
    "    return [tmp_dict[ele] for ele in x]\n",
    "\n",
    "train['sequence'] = train['sequence'].apply(lambda x: [token2int0[ele] for ele in x])\n",
    "train['structure'] = train['structure'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "train['predicted_loop_type'] = train['predicted_loop_type'].apply(lambda x: [token2int2[ele] for ele in x])\n",
    "train_inputs = np.transpose(np.array(train[['sequence', 'structure', 'predicted_loop_type']].values.tolist()), (0, 2, 1))\n",
    "\n",
    "train_inputs = train_inputs[train.signal_to_noise > 1]\n",
    "train_labels = np.array(train[train.signal_to_noise > 1][target_cols].values.tolist()).transpose((0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in train['id']])\n",
    "train_bpps = train_bpps[train.signal_to_noise > 1][:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output\n",
    "    \n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        return config\n",
    "    \n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like(train_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 107, 128)     512         tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 107, 128)     384         tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 107, 128)     896         tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 107, 128)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 107, 128)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 107, 128)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 107, 384)]   0           spatial_dropout1d[0][0]          \n",
      "                                                                 spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 107, 384)     0           tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 107, 128)     256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_3[0][0]        \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block (TransformerB (None, 107, 512)     1577984     tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 107, 768)     2068992     transformer_block[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 107, 768)     2658816     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 107, 768)     2658816     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 68, 768)]    0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_3[0][0]\n",
      "==================================================================================================\n",
      "Total params: 8,974,346\n",
      "Trainable params: 8,974,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 5s - loss: 0.6805 - out1_loss: 0.7333 - out2_loss: 0.5571 - val_loss: 0.3631 - val_out1_loss: 0.3978 - val_out2_loss: 0.2824\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3537 - out1_loss: 0.3929 - out2_loss: 0.2623 - val_loss: 0.3537 - val_out1_loss: 0.3964 - val_out2_loss: 0.2540\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3317 - out1_loss: 0.3691 - out2_loss: 0.2444 - val_loss: 0.3127 - val_out1_loss: 0.3481 - val_out2_loss: 0.2303\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3074 - out1_loss: 0.3423 - out2_loss: 0.2259 - val_loss: 0.2860 - val_out1_loss: 0.3175 - val_out2_loss: 0.2123\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.2910 - out1_loss: 0.3246 - out2_loss: 0.2127 - val_loss: 0.2803 - val_out1_loss: 0.3119 - val_out2_loss: 0.2068\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2809 - out1_loss: 0.3132 - out2_loss: 0.2056 - val_loss: 0.2723 - val_out1_loss: 0.3027 - val_out2_loss: 0.2012\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2685 - out1_loss: 0.2993 - out2_loss: 0.1966 - val_loss: 0.2609 - val_out1_loss: 0.2904 - val_out2_loss: 0.1920\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2613 - out1_loss: 0.2914 - out2_loss: 0.1909 - val_loss: 0.2570 - val_out1_loss: 0.2855 - val_out2_loss: 0.1905\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2561 - out1_loss: 0.2850 - out2_loss: 0.1886 - val_loss: 0.2484 - val_out1_loss: 0.2773 - val_out2_loss: 0.1808\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2480 - out1_loss: 0.2763 - out2_loss: 0.1818 - val_loss: 0.2427 - val_out1_loss: 0.2705 - val_out2_loss: 0.1779\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2411 - out1_loss: 0.2684 - out2_loss: 0.1773 - val_loss: 0.2334 - val_out1_loss: 0.2575 - val_out2_loss: 0.1774\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2342 - out1_loss: 0.2607 - out2_loss: 0.1722 - val_loss: 0.2315 - val_out1_loss: 0.2575 - val_out2_loss: 0.1710\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2277 - out1_loss: 0.2528 - out2_loss: 0.1693 - val_loss: 0.2275 - val_out1_loss: 0.2495 - val_out2_loss: 0.1761\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2219 - out1_loss: 0.2463 - out2_loss: 0.1649 - val_loss: 0.2210 - val_out1_loss: 0.2451 - val_out2_loss: 0.1650\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2161 - out1_loss: 0.2398 - out2_loss: 0.1606 - val_loss: 0.2191 - val_out1_loss: 0.2441 - val_out2_loss: 0.1609\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2118 - out1_loss: 0.2353 - out2_loss: 0.1570 - val_loss: 0.2139 - val_out1_loss: 0.2359 - val_out2_loss: 0.1625\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2074 - out1_loss: 0.2301 - out2_loss: 0.1544 - val_loss: 0.2143 - val_out1_loss: 0.2370 - val_out2_loss: 0.1613\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2052 - out1_loss: 0.2276 - out2_loss: 0.1530 - val_loss: 0.2096 - val_out1_loss: 0.2314 - val_out2_loss: 0.1586\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.2004 - out1_loss: 0.2225 - out2_loss: 0.1490 - val_loss: 0.2111 - val_out1_loss: 0.2351 - val_out2_loss: 0.1552\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.2005 - out1_loss: 0.2223 - out2_loss: 0.1495 - val_loss: 0.2051 - val_out1_loss: 0.2276 - val_out2_loss: 0.1526\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.1961 - out1_loss: 0.2177 - out2_loss: 0.1457 - val_loss: 0.2087 - val_out1_loss: 0.2300 - val_out2_loss: 0.1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1940 - out1_loss: 0.2144 - out2_loss: 0.1465 - val_loss: 0.2039 - val_out1_loss: 0.2263 - val_out2_loss: 0.1518\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1920 - out1_loss: 0.2125 - out2_loss: 0.1442 - val_loss: 0.2040 - val_out1_loss: 0.2268 - val_out2_loss: 0.1507\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1874 - out1_loss: 0.2078 - out2_loss: 0.1400 - val_loss: 0.2072 - val_out1_loss: 0.2312 - val_out2_loss: 0.1511\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1851 - out1_loss: 0.2052 - out2_loss: 0.1383 - val_loss: 0.2010 - val_out1_loss: 0.2225 - val_out2_loss: 0.1509\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1827 - out1_loss: 0.2023 - out2_loss: 0.1369 - val_loss: 0.2020 - val_out1_loss: 0.2240 - val_out2_loss: 0.1505\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1803 - out1_loss: 0.1994 - out2_loss: 0.1357 - val_loss: 0.2020 - val_out1_loss: 0.2247 - val_out2_loss: 0.1490\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1781 - out1_loss: 0.1971 - out2_loss: 0.1339 - val_loss: 0.1997 - val_out1_loss: 0.2222 - val_out2_loss: 0.1474\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1777 - out1_loss: 0.1963 - out2_loss: 0.1343 - val_loss: 0.2050 - val_out1_loss: 0.2263 - val_out2_loss: 0.1553\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1757 - out1_loss: 0.1941 - out2_loss: 0.1328 - val_loss: 0.1995 - val_out1_loss: 0.2220 - val_out2_loss: 0.1472\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1723 - out1_loss: 0.1906 - out2_loss: 0.1298 - val_loss: 0.2019 - val_out1_loss: 0.2246 - val_out2_loss: 0.1491\n",
      "Epoch 32/120\n",
      "53/53 - 5s - loss: 0.1715 - out1_loss: 0.1890 - out2_loss: 0.1306 - val_loss: 0.2030 - val_out1_loss: 0.2247 - val_out2_loss: 0.1523\n",
      "Epoch 33/120\n",
      "53/53 - 5s - loss: 0.1714 - out1_loss: 0.1881 - out2_loss: 0.1325 - val_loss: 0.1967 - val_out1_loss: 0.2183 - val_out2_loss: 0.1464\n",
      "Epoch 34/120\n",
      "53/53 - 5s - loss: 0.1660 - out1_loss: 0.1829 - out2_loss: 0.1265 - val_loss: 0.2000 - val_out1_loss: 0.2231 - val_out2_loss: 0.1461\n",
      "Epoch 35/120\n",
      "53/53 - 5s - loss: 0.1661 - out1_loss: 0.1826 - out2_loss: 0.1276 - val_loss: 0.1957 - val_out1_loss: 0.2173 - val_out2_loss: 0.1453\n",
      "Epoch 36/120\n",
      "53/53 - 5s - loss: 0.1626 - out1_loss: 0.1790 - out2_loss: 0.1243 - val_loss: 0.1954 - val_out1_loss: 0.2168 - val_out2_loss: 0.1455\n",
      "Epoch 37/120\n",
      "53/53 - 5s - loss: 0.1617 - out1_loss: 0.1780 - out2_loss: 0.1236 - val_loss: 0.1980 - val_out1_loss: 0.2205 - val_out2_loss: 0.1454\n",
      "Epoch 38/120\n",
      "53/53 - 5s - loss: 0.1606 - out1_loss: 0.1766 - out2_loss: 0.1232 - val_loss: 0.1956 - val_out1_loss: 0.2178 - val_out2_loss: 0.1438\n",
      "Epoch 39/120\n",
      "53/53 - 5s - loss: 0.1579 - out1_loss: 0.1736 - out2_loss: 0.1213 - val_loss: 0.1957 - val_out1_loss: 0.2172 - val_out2_loss: 0.1458\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1579 - out1_loss: 0.1736 - out2_loss: 0.1213 - val_loss: 0.1963 - val_out1_loss: 0.2181 - val_out2_loss: 0.1454\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1560 - out1_loss: 0.1716 - out2_loss: 0.1194 - val_loss: 0.1960 - val_out1_loss: 0.2167 - val_out2_loss: 0.1477\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1550 - out1_loss: 0.1700 - out2_loss: 0.1200 - val_loss: 0.1969 - val_out1_loss: 0.2192 - val_out2_loss: 0.1449\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1557 - out1_loss: 0.1707 - out2_loss: 0.1206 - val_loss: 0.1941 - val_out1_loss: 0.2156 - val_out2_loss: 0.1440\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1520 - out1_loss: 0.1670 - out2_loss: 0.1171 - val_loss: 0.1956 - val_out1_loss: 0.2166 - val_out2_loss: 0.1465\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1505 - out1_loss: 0.1651 - out2_loss: 0.1166 - val_loss: 0.1965 - val_out1_loss: 0.2184 - val_out2_loss: 0.1456\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1505 - out1_loss: 0.1650 - out2_loss: 0.1168 - val_loss: 0.1995 - val_out1_loss: 0.2203 - val_out2_loss: 0.1509\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1491 - out1_loss: 0.1635 - out2_loss: 0.1155 - val_loss: 0.1930 - val_out1_loss: 0.2142 - val_out2_loss: 0.1433\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1474 - out1_loss: 0.1615 - out2_loss: 0.1143 - val_loss: 0.1957 - val_out1_loss: 0.2174 - val_out2_loss: 0.1452\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1463 - out1_loss: 0.1603 - out2_loss: 0.1138 - val_loss: 0.1949 - val_out1_loss: 0.2161 - val_out2_loss: 0.1453\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1454 - out1_loss: 0.1591 - out2_loss: 0.1132 - val_loss: 0.1939 - val_out1_loss: 0.2155 - val_out2_loss: 0.1435\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1452 - out1_loss: 0.1590 - out2_loss: 0.1130 - val_loss: 0.1942 - val_out1_loss: 0.2154 - val_out2_loss: 0.1448\n",
      "Epoch 52/120\n",
      "53/53 - 5s - loss: 0.1463 - out1_loss: 0.1592 - out2_loss: 0.1161 - val_loss: 0.1962 - val_out1_loss: 0.2175 - val_out2_loss: 0.1466\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1436 - out1_loss: 0.1563 - out2_loss: 0.1140 - val_loss: 0.1926 - val_out1_loss: 0.2135 - val_out2_loss: 0.1437\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1407 - out1_loss: 0.1540 - out2_loss: 0.1099 - val_loss: 0.1940 - val_out1_loss: 0.2152 - val_out2_loss: 0.1446\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1418 - out1_loss: 0.1548 - out2_loss: 0.1113 - val_loss: 0.1931 - val_out1_loss: 0.2145 - val_out2_loss: 0.1432\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1411 - out1_loss: 0.1545 - out2_loss: 0.1100 - val_loss: 0.1944 - val_out1_loss: 0.2161 - val_out2_loss: 0.1438\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1385 - out1_loss: 0.1514 - out2_loss: 0.1086 - val_loss: 0.2028 - val_out1_loss: 0.2257 - val_out2_loss: 0.1493\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1400 - out1_loss: 0.1525 - out2_loss: 0.1109 - val_loss: 0.1945 - val_out1_loss: 0.2157 - val_out2_loss: 0.1450\n",
      "Epoch 59/120\n",
      "53/53 - 5s - loss: 0.1391 - out1_loss: 0.1516 - out2_loss: 0.1100 - val_loss: 0.1934 - val_out1_loss: 0.2140 - val_out2_loss: 0.1452\n",
      "Epoch 60/120\n",
      "53/53 - 5s - loss: 0.1369 - out1_loss: 0.1494 - out2_loss: 0.1077 - val_loss: 0.1923 - val_out1_loss: 0.2137 - val_out2_loss: 0.1423\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1348 - out1_loss: 0.1473 - out2_loss: 0.1057 - val_loss: 0.1931 - val_out1_loss: 0.2141 - val_out2_loss: 0.1441\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1360 - out1_loss: 0.1480 - out2_loss: 0.1080 - val_loss: 0.1952 - val_out1_loss: 0.2158 - val_out2_loss: 0.1471\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1354 - out1_loss: 0.1473 - out2_loss: 0.1078 - val_loss: 0.1968 - val_out1_loss: 0.2162 - val_out2_loss: 0.1516\n",
      "Epoch 64/120\n",
      "53/53 - 5s - loss: 0.1334 - out1_loss: 0.1451 - out2_loss: 0.1060 - val_loss: 0.1917 - val_out1_loss: 0.2128 - val_out2_loss: 0.1425\n",
      "Epoch 65/120\n",
      "53/53 - 5s - loss: 0.1327 - out1_loss: 0.1447 - out2_loss: 0.1049 - val_loss: 0.1937 - val_out1_loss: 0.2150 - val_out2_loss: 0.1439\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1345 - out1_loss: 0.1463 - out2_loss: 0.1069 - val_loss: 0.1936 - val_out1_loss: 0.2154 - val_out2_loss: 0.1427\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1314 - out1_loss: 0.1434 - out2_loss: 0.1036 - val_loss: 0.1922 - val_out1_loss: 0.2127 - val_out2_loss: 0.1444\n",
      "Epoch 68/120\n",
      "53/53 - 5s - loss: 0.1305 - out1_loss: 0.1418 - out2_loss: 0.1042 - val_loss: 0.1927 - val_out1_loss: 0.2141 - val_out2_loss: 0.1426\n",
      "Epoch 69/120\n",
      "53/53 - 5s - loss: 0.1298 - out1_loss: 0.1412 - out2_loss: 0.1032 - val_loss: 0.1941 - val_out1_loss: 0.2154 - val_out2_loss: 0.1445\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1305 - out1_loss: 0.1419 - out2_loss: 0.1039 - val_loss: 0.1924 - val_out1_loss: 0.2141 - val_out2_loss: 0.1417\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1286 - out1_loss: 0.1400 - out2_loss: 0.1020 - val_loss: 0.1919 - val_out1_loss: 0.2129 - val_out2_loss: 0.1429\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1280 - out1_loss: 0.1392 - out2_loss: 0.1018 - val_loss: 0.1948 - val_out1_loss: 0.2164 - val_out2_loss: 0.1445\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1278 - out1_loss: 0.1390 - out2_loss: 0.1016 - val_loss: 0.1928 - val_out1_loss: 0.2143 - val_out2_loss: 0.1427\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1273 - out1_loss: 0.1383 - out2_loss: 0.1016 - val_loss: 0.1953 - val_out1_loss: 0.2168 - val_out2_loss: 0.1451\n",
      "Epoch 75/120\n",
      "53/53 - 5s - loss: 0.1215 - out1_loss: 0.1321 - out2_loss: 0.0969 - val_loss: 0.1899 - val_out1_loss: 0.2110 - val_out2_loss: 0.1408\n",
      "Epoch 76/120\n",
      "53/53 - 5s - loss: 0.1186 - out1_loss: 0.1288 - out2_loss: 0.0949 - val_loss: 0.1894 - val_out1_loss: 0.2105 - val_out2_loss: 0.1402\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1177 - out1_loss: 0.1278 - out2_loss: 0.0942 - val_loss: 0.1894 - val_out1_loss: 0.2104 - val_out2_loss: 0.1402\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1169 - out1_loss: 0.1268 - out2_loss: 0.0937 - val_loss: 0.1892 - val_out1_loss: 0.2103 - val_out2_loss: 0.1400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1163 - out1_loss: 0.1262 - out2_loss: 0.0934 - val_loss: 0.1890 - val_out1_loss: 0.2101 - val_out2_loss: 0.1400\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1160 - out1_loss: 0.1258 - out2_loss: 0.0931 - val_loss: 0.1891 - val_out1_loss: 0.2102 - val_out2_loss: 0.1400\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.1156 - out1_loss: 0.1254 - out2_loss: 0.0929 - val_loss: 0.1892 - val_out1_loss: 0.2103 - val_out2_loss: 0.1400\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1153 - out1_loss: 0.1250 - out2_loss: 0.0927 - val_loss: 0.1891 - val_out1_loss: 0.2102 - val_out2_loss: 0.1400\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1149 - out1_loss: 0.1246 - out2_loss: 0.0925 - val_loss: 0.1888 - val_out1_loss: 0.2098 - val_out2_loss: 0.1398\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1147 - out1_loss: 0.1244 - out2_loss: 0.0922 - val_loss: 0.1889 - val_out1_loss: 0.2100 - val_out2_loss: 0.1398\n",
      "Epoch 85/120\n",
      "53/53 - 5s - loss: 0.1144 - out1_loss: 0.1240 - out2_loss: 0.0922 - val_loss: 0.1890 - val_out1_loss: 0.2101 - val_out2_loss: 0.1398\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1143 - out1_loss: 0.1239 - out2_loss: 0.0920 - val_loss: 0.1887 - val_out1_loss: 0.2097 - val_out2_loss: 0.1397\n",
      "Epoch 87/120\n",
      "53/53 - 5s - loss: 0.1140 - out1_loss: 0.1235 - out2_loss: 0.0918 - val_loss: 0.1889 - val_out1_loss: 0.2099 - val_out2_loss: 0.1398\n",
      "Epoch 88/120\n",
      "53/53 - 5s - loss: 0.1136 - out1_loss: 0.1231 - out2_loss: 0.0916 - val_loss: 0.1888 - val_out1_loss: 0.2099 - val_out2_loss: 0.1397\n",
      "Epoch 89/120\n",
      "53/53 - 5s - loss: 0.1136 - out1_loss: 0.1230 - out2_loss: 0.0915 - val_loss: 0.1888 - val_out1_loss: 0.2099 - val_out2_loss: 0.1397\n",
      "Epoch 90/120\n",
      "53/53 - 5s - loss: 0.1134 - out1_loss: 0.1229 - out2_loss: 0.0914 - val_loss: 0.1888 - val_out1_loss: 0.2099 - val_out2_loss: 0.1397\n",
      "Epoch 91/120\n",
      "53/53 - 5s - loss: 0.1132 - out1_loss: 0.1226 - out2_loss: 0.0913 - val_loss: 0.1888 - val_out1_loss: 0.2098 - val_out2_loss: 0.1396\n",
      "Epoch 92/120\n",
      "53/53 - 5s - loss: 0.1132 - out1_loss: 0.1226 - out2_loss: 0.0913 - val_loss: 0.1887 - val_out1_loss: 0.2098 - val_out2_loss: 0.1396\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1128 - out1_loss: 0.1221 - out2_loss: 0.0909 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1396\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1127 - out1_loss: 0.1220 - out2_loss: 0.0909 - val_loss: 0.1889 - val_out1_loss: 0.2099 - val_out2_loss: 0.1398\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1126 - out1_loss: 0.1220 - out2_loss: 0.0908 - val_loss: 0.1889 - val_out1_loss: 0.2100 - val_out2_loss: 0.1397\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1124 - out1_loss: 0.1218 - out2_loss: 0.0907 - val_loss: 0.1888 - val_out1_loss: 0.2098 - val_out2_loss: 0.1396\n",
      "Epoch 97/120\n",
      "53/53 - 5s - loss: 0.1119 - out1_loss: 0.1211 - out2_loss: 0.0903 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 98/120\n",
      "53/53 - 5s - loss: 0.1118 - out1_loss: 0.1210 - out2_loss: 0.0903 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1118 - out1_loss: 0.1210 - out2_loss: 0.0903 - val_loss: 0.1885 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1118 - out1_loss: 0.1210 - out2_loss: 0.0902 - val_loss: 0.1885 - val_out1_loss: 0.2096 - val_out2_loss: 0.1394\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1117 - out1_loss: 0.1209 - out2_loss: 0.0902 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1394\n",
      "Epoch 102/120\n",
      "53/53 - 5s - loss: 0.1116 - out1_loss: 0.1208 - out2_loss: 0.0901 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1116 - out1_loss: 0.1208 - out2_loss: 0.0902 - val_loss: 0.1886 - val_out1_loss: 0.2097 - val_out2_loss: 0.1395\n",
      "Epoch 104/120\n",
      "53/53 - 5s - loss: 0.1116 - out1_loss: 0.1207 - out2_loss: 0.0901 - val_loss: 0.1885 - val_out1_loss: 0.2096 - val_out2_loss: 0.1394\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1116 - out1_loss: 0.1208 - out2_loss: 0.0901 - val_loss: 0.1885 - val_out1_loss: 0.2096 - val_out2_loss: 0.1394\n",
      "Epoch 106/120\n",
      "53/53 - 5s - loss: 0.1116 - out1_loss: 0.1208 - out2_loss: 0.0901 - val_loss: 0.1886 - val_out1_loss: 0.2097 - val_out2_loss: 0.1395\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1115 - out1_loss: 0.1207 - out2_loss: 0.0901 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1116 - out1_loss: 0.1207 - out2_loss: 0.0902 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 109/120\n",
      "53/53 - 5s - loss: 0.1114 - out1_loss: 0.1206 - out2_loss: 0.0901 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 110/120\n",
      "53/53 - 5s - loss: 0.1113 - out1_loss: 0.1205 - out2_loss: 0.0900 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1113 - out1_loss: 0.1205 - out2_loss: 0.0901 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1394\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1114 - out1_loss: 0.1205 - out2_loss: 0.0900 - val_loss: 0.1885 - val_out1_loss: 0.2096 - val_out2_loss: 0.1394\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1113 - out1_loss: 0.1205 - out2_loss: 0.0899 - val_loss: 0.1885 - val_out1_loss: 0.2096 - val_out2_loss: 0.1394\n",
      "Epoch 114/120\n",
      "53/53 - 5s - loss: 0.1113 - out1_loss: 0.1205 - out2_loss: 0.0900 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1113 - out1_loss: 0.1204 - out2_loss: 0.0900 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1115 - out1_loss: 0.1206 - out2_loss: 0.0901 - val_loss: 0.1885 - val_out1_loss: 0.2096 - val_out2_loss: 0.1394\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1115 - out1_loss: 0.1207 - out2_loss: 0.0900 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 118/120\n",
      "53/53 - 5s - loss: 0.1114 - out1_loss: 0.1205 - out2_loss: 0.0901 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.1114 - out1_loss: 0.1205 - out2_loss: 0.0900 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1115 - out1_loss: 0.1207 - out2_loss: 0.0900 - val_loss: 0.1886 - val_out1_loss: 0.2096 - val_out2_loss: 0.1395\n",
      "#################### 0.3657723474952673\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 107, 128)     512         tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 107, 128)     0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 107, 128)     0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, 107, 128)     0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo [(None, 107, 384)]   0           spatial_dropout1d_12[0][0]       \n",
      "                                                                 spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 107, 384)     0           tf_op_layer_concat_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 107, 128)     256         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_7 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_15[0][0]       \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_3 (Transforme (None, 107, 512)     1577984     tf_op_layer_concat_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 107, 768)     2068992     transformer_block_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 107, 768)     2658816     bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 107, 768)     2658816     bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [(None, 68, 768)]    0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_15[0][0\n",
      "==================================================================================================\n",
      "Total params: 8,974,346\n",
      "Trainable params: 8,974,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 7s - loss: 0.6524 - out1_loss: 0.7291 - out2_loss: 0.4733 - val_loss: 0.3638 - val_out1_loss: 0.3971 - val_out2_loss: 0.2859\n",
      "Epoch 2/120\n",
      "53/53 - 5s - loss: 0.3529 - out1_loss: 0.3919 - out2_loss: 0.2618 - val_loss: 0.3395 - val_out1_loss: 0.3793 - val_out2_loss: 0.2466\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3245 - out1_loss: 0.3602 - out2_loss: 0.2414 - val_loss: 0.3103 - val_out1_loss: 0.3514 - val_out2_loss: 0.2145\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3055 - out1_loss: 0.3383 - out2_loss: 0.2291 - val_loss: 0.2975 - val_out1_loss: 0.3325 - val_out2_loss: 0.2159\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.2891 - out1_loss: 0.3218 - out2_loss: 0.2126 - val_loss: 0.2733 - val_out1_loss: 0.3033 - val_out2_loss: 0.2031\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2807 - out1_loss: 0.3121 - out2_loss: 0.2076 - val_loss: 0.2686 - val_out1_loss: 0.3007 - val_out2_loss: 0.1936\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2685 - out1_loss: 0.2992 - out2_loss: 0.1969 - val_loss: 0.2558 - val_out1_loss: 0.2873 - val_out2_loss: 0.1822\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2614 - out1_loss: 0.2910 - out2_loss: 0.1924 - val_loss: 0.2480 - val_out1_loss: 0.2756 - val_out2_loss: 0.1836\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2535 - out1_loss: 0.2820 - out2_loss: 0.1870 - val_loss: 0.2462 - val_out1_loss: 0.2743 - val_out2_loss: 0.1808\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2455 - out1_loss: 0.2732 - out2_loss: 0.1810 - val_loss: 0.2372 - val_out1_loss: 0.2651 - val_out2_loss: 0.1720\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2385 - out1_loss: 0.2657 - out2_loss: 0.1752 - val_loss: 0.2321 - val_out1_loss: 0.2564 - val_out2_loss: 0.1754\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2326 - out1_loss: 0.2583 - out2_loss: 0.1727 - val_loss: 0.2408 - val_out1_loss: 0.2663 - val_out2_loss: 0.1814\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2277 - out1_loss: 0.2527 - out2_loss: 0.1692 - val_loss: 0.2239 - val_out1_loss: 0.2493 - val_out2_loss: 0.1647\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2247 - out1_loss: 0.2486 - out2_loss: 0.1688 - val_loss: 0.2165 - val_out1_loss: 0.2407 - val_out2_loss: 0.1599\n",
      "Epoch 15/120\n",
      "53/53 - 5s - loss: 0.2175 - out1_loss: 0.2412 - out2_loss: 0.1621 - val_loss: 0.2168 - val_out1_loss: 0.2405 - val_out2_loss: 0.1617\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2118 - out1_loss: 0.2349 - out2_loss: 0.1580 - val_loss: 0.2112 - val_out1_loss: 0.2346 - val_out2_loss: 0.1566\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2078 - out1_loss: 0.2305 - out2_loss: 0.1547 - val_loss: 0.2121 - val_out1_loss: 0.2365 - val_out2_loss: 0.1551\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2039 - out1_loss: 0.2262 - out2_loss: 0.1519 - val_loss: 0.2227 - val_out1_loss: 0.2443 - val_out2_loss: 0.1725\n",
      "Epoch 19/120\n",
      "53/53 - 5s - loss: 0.2020 - out1_loss: 0.2238 - out2_loss: 0.1513 - val_loss: 0.2093 - val_out1_loss: 0.2325 - val_out2_loss: 0.1550\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.1976 - out1_loss: 0.2191 - out2_loss: 0.1475 - val_loss: 0.2049 - val_out1_loss: 0.2282 - val_out2_loss: 0.1506\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.1967 - out1_loss: 0.2177 - out2_loss: 0.1477 - val_loss: 0.2037 - val_out1_loss: 0.2271 - val_out2_loss: 0.1492\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1938 - out1_loss: 0.2149 - out2_loss: 0.1446 - val_loss: 0.2033 - val_out1_loss: 0.2269 - val_out2_loss: 0.1484\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1892 - out1_loss: 0.2096 - out2_loss: 0.1417 - val_loss: 0.2001 - val_out1_loss: 0.2228 - val_out2_loss: 0.1469\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1865 - out1_loss: 0.2066 - out2_loss: 0.1394 - val_loss: 0.2036 - val_out1_loss: 0.2266 - val_out2_loss: 0.1500\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1842 - out1_loss: 0.2038 - out2_loss: 0.1383 - val_loss: 0.2038 - val_out1_loss: 0.2243 - val_out2_loss: 0.1559\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1831 - out1_loss: 0.2025 - out2_loss: 0.1378 - val_loss: 0.1976 - val_out1_loss: 0.2195 - val_out2_loss: 0.1464\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1823 - out1_loss: 0.2012 - out2_loss: 0.1382 - val_loss: 0.2061 - val_out1_loss: 0.2280 - val_out2_loss: 0.1549\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1805 - out1_loss: 0.1993 - out2_loss: 0.1365 - val_loss: 0.1975 - val_out1_loss: 0.2199 - val_out2_loss: 0.1450\n",
      "Epoch 29/120\n",
      "53/53 - 5s - loss: 0.1753 - out1_loss: 0.1936 - out2_loss: 0.1326 - val_loss: 0.1974 - val_out1_loss: 0.2204 - val_out2_loss: 0.1438\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1725 - out1_loss: 0.1905 - out2_loss: 0.1304 - val_loss: 0.1959 - val_out1_loss: 0.2182 - val_out2_loss: 0.1439\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1716 - out1_loss: 0.1893 - out2_loss: 0.1303 - val_loss: 0.1972 - val_out1_loss: 0.2190 - val_out2_loss: 0.1463\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1697 - out1_loss: 0.1872 - out2_loss: 0.1287 - val_loss: 0.1941 - val_out1_loss: 0.2156 - val_out2_loss: 0.1438\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1680 - out1_loss: 0.1849 - out2_loss: 0.1283 - val_loss: 0.1972 - val_out1_loss: 0.2191 - val_out2_loss: 0.1460\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1661 - out1_loss: 0.1830 - out2_loss: 0.1268 - val_loss: 0.1969 - val_out1_loss: 0.2195 - val_out2_loss: 0.1442\n",
      "Epoch 35/120\n",
      "53/53 - 5s - loss: 0.1654 - out1_loss: 0.1819 - out2_loss: 0.1270 - val_loss: 0.1949 - val_out1_loss: 0.2172 - val_out2_loss: 0.1426\n",
      "Epoch 36/120\n",
      "53/53 - 5s - loss: 0.1649 - out1_loss: 0.1813 - out2_loss: 0.1265 - val_loss: 0.1949 - val_out1_loss: 0.2162 - val_out2_loss: 0.1450\n",
      "Epoch 37/120\n",
      "53/53 - 5s - loss: 0.1626 - out1_loss: 0.1787 - out2_loss: 0.1250 - val_loss: 0.1918 - val_out1_loss: 0.2138 - val_out2_loss: 0.1403\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1588 - out1_loss: 0.1746 - out2_loss: 0.1219 - val_loss: 0.1949 - val_out1_loss: 0.2168 - val_out2_loss: 0.1438\n",
      "Epoch 39/120\n",
      "53/53 - 5s - loss: 0.1579 - out1_loss: 0.1735 - out2_loss: 0.1215 - val_loss: 0.1931 - val_out1_loss: 0.2154 - val_out2_loss: 0.1411\n",
      "Epoch 40/120\n",
      "53/53 - 5s - loss: 0.1572 - out1_loss: 0.1728 - out2_loss: 0.1209 - val_loss: 0.1935 - val_out1_loss: 0.2144 - val_out2_loss: 0.1449\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1564 - out1_loss: 0.1718 - out2_loss: 0.1204 - val_loss: 0.1949 - val_out1_loss: 0.2170 - val_out2_loss: 0.1435\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1551 - out1_loss: 0.1704 - out2_loss: 0.1195 - val_loss: 0.1925 - val_out1_loss: 0.2143 - val_out2_loss: 0.1414\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1528 - out1_loss: 0.1675 - out2_loss: 0.1186 - val_loss: 0.1917 - val_out1_loss: 0.2136 - val_out2_loss: 0.1405\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1511 - out1_loss: 0.1657 - out2_loss: 0.1170 - val_loss: 0.1903 - val_out1_loss: 0.2119 - val_out2_loss: 0.1400\n",
      "Epoch 45/120\n",
      "53/53 - 5s - loss: 0.1510 - out1_loss: 0.1654 - out2_loss: 0.1174 - val_loss: 0.1926 - val_out1_loss: 0.2136 - val_out2_loss: 0.1436\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1490 - out1_loss: 0.1632 - out2_loss: 0.1159 - val_loss: 0.1921 - val_out1_loss: 0.2138 - val_out2_loss: 0.1415\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1478 - out1_loss: 0.1618 - out2_loss: 0.1151 - val_loss: 0.1920 - val_out1_loss: 0.2128 - val_out2_loss: 0.1433\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1463 - out1_loss: 0.1601 - out2_loss: 0.1141 - val_loss: 0.1913 - val_out1_loss: 0.2130 - val_out2_loss: 0.1409\n",
      "Epoch 49/120\n",
      "53/53 - 5s - loss: 0.1466 - out1_loss: 0.1600 - out2_loss: 0.1151 - val_loss: 0.1928 - val_out1_loss: 0.2129 - val_out2_loss: 0.1460\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1451 - out1_loss: 0.1580 - out2_loss: 0.1152 - val_loss: 0.1909 - val_out1_loss: 0.2126 - val_out2_loss: 0.1402\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1433 - out1_loss: 0.1565 - out2_loss: 0.1124 - val_loss: 0.1928 - val_out1_loss: 0.2150 - val_out2_loss: 0.1410\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1428 - out1_loss: 0.1562 - out2_loss: 0.1114 - val_loss: 0.1898 - val_out1_loss: 0.2115 - val_out2_loss: 0.1392\n",
      "Epoch 53/120\n",
      "53/53 - 5s - loss: 0.1413 - out1_loss: 0.1545 - out2_loss: 0.1104 - val_loss: 0.1903 - val_out1_loss: 0.2119 - val_out2_loss: 0.1400\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1406 - out1_loss: 0.1538 - out2_loss: 0.1099 - val_loss: 0.1912 - val_out1_loss: 0.2132 - val_out2_loss: 0.1399\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1397 - out1_loss: 0.1526 - out2_loss: 0.1097 - val_loss: 0.1901 - val_out1_loss: 0.2116 - val_out2_loss: 0.1401\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1393 - out1_loss: 0.1520 - out2_loss: 0.1096 - val_loss: 0.1898 - val_out1_loss: 0.2119 - val_out2_loss: 0.1385\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1383 - out1_loss: 0.1509 - out2_loss: 0.1087 - val_loss: 0.1926 - val_out1_loss: 0.2127 - val_out2_loss: 0.1458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1375 - out1_loss: 0.1498 - out2_loss: 0.1088 - val_loss: 0.1911 - val_out1_loss: 0.2123 - val_out2_loss: 0.1415\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1362 - out1_loss: 0.1486 - out2_loss: 0.1071 - val_loss: 0.1912 - val_out1_loss: 0.2129 - val_out2_loss: 0.1404\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1358 - out1_loss: 0.1479 - out2_loss: 0.1074 - val_loss: 0.1901 - val_out1_loss: 0.2117 - val_out2_loss: 0.1398\n",
      "Epoch 61/120\n",
      "53/53 - 5s - loss: 0.1356 - out1_loss: 0.1478 - out2_loss: 0.1073 - val_loss: 0.1907 - val_out1_loss: 0.2127 - val_out2_loss: 0.1394\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1346 - out1_loss: 0.1461 - out2_loss: 0.1076 - val_loss: 0.1914 - val_out1_loss: 0.2130 - val_out2_loss: 0.1409\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1284 - out1_loss: 0.1398 - out2_loss: 0.1018 - val_loss: 0.1866 - val_out1_loss: 0.2079 - val_out2_loss: 0.1368\n",
      "Epoch 64/120\n",
      "53/53 - 5s - loss: 0.1259 - out1_loss: 0.1370 - out2_loss: 0.1000 - val_loss: 0.1861 - val_out1_loss: 0.2074 - val_out2_loss: 0.1364\n",
      "Epoch 65/120\n",
      "53/53 - 5s - loss: 0.1248 - out1_loss: 0.1358 - out2_loss: 0.0993 - val_loss: 0.1862 - val_out1_loss: 0.2075 - val_out2_loss: 0.1365\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1241 - out1_loss: 0.1350 - out2_loss: 0.0988 - val_loss: 0.1861 - val_out1_loss: 0.2074 - val_out2_loss: 0.1364\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1237 - out1_loss: 0.1344 - out2_loss: 0.0985 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1362\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1232 - out1_loss: 0.1339 - out2_loss: 0.0982 - val_loss: 0.1860 - val_out1_loss: 0.2073 - val_out2_loss: 0.1363\n",
      "Epoch 69/120\n",
      "53/53 - 5s - loss: 0.1230 - out1_loss: 0.1336 - out2_loss: 0.0981 - val_loss: 0.1861 - val_out1_loss: 0.2073 - val_out2_loss: 0.1364\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1227 - out1_loss: 0.1333 - out2_loss: 0.0978 - val_loss: 0.1857 - val_out1_loss: 0.2070 - val_out2_loss: 0.1361\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1224 - out1_loss: 0.1329 - out2_loss: 0.0977 - val_loss: 0.1860 - val_out1_loss: 0.2074 - val_out2_loss: 0.1363\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1221 - out1_loss: 0.1327 - out2_loss: 0.0975 - val_loss: 0.1860 - val_out1_loss: 0.2073 - val_out2_loss: 0.1363\n",
      "Epoch 73/120\n",
      "53/53 - 5s - loss: 0.1218 - out1_loss: 0.1324 - out2_loss: 0.0972 - val_loss: 0.1860 - val_out1_loss: 0.2073 - val_out2_loss: 0.1362\n",
      "Epoch 74/120\n",
      "53/53 - 5s - loss: 0.1216 - out1_loss: 0.1321 - out2_loss: 0.0971 - val_loss: 0.1858 - val_out1_loss: 0.2072 - val_out2_loss: 0.1361\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1214 - out1_loss: 0.1318 - out2_loss: 0.0969 - val_loss: 0.1855 - val_out1_loss: 0.2068 - val_out2_loss: 0.1359\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1212 - out1_loss: 0.1317 - out2_loss: 0.0969 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1360\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1210 - out1_loss: 0.1314 - out2_loss: 0.0967 - val_loss: 0.1860 - val_out1_loss: 0.2073 - val_out2_loss: 0.1362\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1206 - out1_loss: 0.1310 - out2_loss: 0.0964 - val_loss: 0.1859 - val_out1_loss: 0.2073 - val_out2_loss: 0.1361\n",
      "Epoch 79/120\n",
      "53/53 - 5s - loss: 0.1207 - out1_loss: 0.1310 - out2_loss: 0.0965 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1360\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1203 - out1_loss: 0.1307 - out2_loss: 0.0963 - val_loss: 0.1858 - val_out1_loss: 0.2072 - val_out2_loss: 0.1360\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.1200 - out1_loss: 0.1302 - out2_loss: 0.0960 - val_loss: 0.1860 - val_out1_loss: 0.2074 - val_out2_loss: 0.1362\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1203 - out1_loss: 0.1306 - out2_loss: 0.0961 - val_loss: 0.1858 - val_out1_loss: 0.2072 - val_out2_loss: 0.1361\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1197 - out1_loss: 0.1299 - out2_loss: 0.0959 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1360\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1196 - out1_loss: 0.1299 - out2_loss: 0.0958 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1361\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.1194 - out1_loss: 0.1296 - out2_loss: 0.0957 - val_loss: 0.1859 - val_out1_loss: 0.2072 - val_out2_loss: 0.1360\n",
      "Epoch 86/120\n",
      "53/53 - 5s - loss: 0.1188 - out1_loss: 0.1290 - out2_loss: 0.0952 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1360\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1187 - out1_loss: 0.1288 - out2_loss: 0.0952 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1188 - out1_loss: 0.1289 - out2_loss: 0.0951 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 89/120\n",
      "53/53 - 5s - loss: 0.1186 - out1_loss: 0.1286 - out2_loss: 0.0952 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 90/120\n",
      "53/53 - 5s - loss: 0.1186 - out1_loss: 0.1286 - out2_loss: 0.0951 - val_loss: 0.1858 - val_out1_loss: 0.2072 - val_out2_loss: 0.1360\n",
      "Epoch 91/120\n",
      "53/53 - 5s - loss: 0.1185 - out1_loss: 0.1285 - out2_loss: 0.0950 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.1186 - out1_loss: 0.1286 - out2_loss: 0.0951 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 93/120\n",
      "53/53 - 5s - loss: 0.1185 - out1_loss: 0.1286 - out2_loss: 0.0950 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 94/120\n",
      "53/53 - 5s - loss: 0.1186 - out1_loss: 0.1287 - out2_loss: 0.0950 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1186 - out1_loss: 0.1287 - out2_loss: 0.0951 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1360\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1185 - out1_loss: 0.1285 - out2_loss: 0.0950 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1185 - out1_loss: 0.1285 - out2_loss: 0.0949 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 98/120\n",
      "53/53 - 5s - loss: 0.1185 - out1_loss: 0.1285 - out2_loss: 0.0950 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1185 - out1_loss: 0.1286 - out2_loss: 0.0949 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1185 - out1_loss: 0.1285 - out2_loss: 0.0949 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1184 - out1_loss: 0.1284 - out2_loss: 0.0950 - val_loss: 0.1858 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1185 - out1_loss: 0.1286 - out2_loss: 0.0950 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 103/120\n",
      "53/53 - 5s - loss: 0.1183 - out1_loss: 0.1284 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1183 - out1_loss: 0.1284 - out2_loss: 0.0948 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1184 - out1_loss: 0.1285 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1182 - out1_loss: 0.1282 - out2_loss: 0.0948 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1182 - out1_loss: 0.1283 - out2_loss: 0.0948 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1183 - out1_loss: 0.1283 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1183 - out1_loss: 0.1284 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1183 - out1_loss: 0.1284 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1184 - out1_loss: 0.1285 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1182 - out1_loss: 0.1283 - out2_loss: 0.0948 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1184 - out1_loss: 0.1284 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 114/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 5s - loss: 0.1183 - out1_loss: 0.1283 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1186 - out1_loss: 0.1287 - out2_loss: 0.0950 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1186 - out1_loss: 0.1287 - out2_loss: 0.0950 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1183 - out1_loss: 0.1283 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 118/120\n",
      "53/53 - 5s - loss: 0.1183 - out1_loss: 0.1284 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 119/120\n",
      "53/53 - 5s - loss: 0.1184 - out1_loss: 0.1284 - out2_loss: 0.0949 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1185 - out1_loss: 0.1286 - out2_loss: 0.0951 - val_loss: 0.1857 - val_out1_loss: 0.2071 - val_out2_loss: 0.1359\n",
      "#################### 0.35866764805590207\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_24 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_25 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_26 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 107, 128)     512         tf_op_layer_strided_slice_24[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_25[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_26[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 107, 128)     0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 107, 128)     0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 107, 128)     0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_12 (TensorFl [(None, 107, 384)]   0           spatial_dropout1d_24[0][0]       \n",
      "                                                                 spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 107, 384)     0           tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 107, 128)     256         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_13 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_27[0][0]       \n",
      "                                                                 dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_6 (Transforme (None, 107, 512)     1577984     tf_op_layer_concat_13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 107, 768)     2068992     transformer_block_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 107, 768)     2658816     bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 107, 768)     2658816     bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_27 (T [(None, 68, 768)]    0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_27[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_27[0][0\n",
      "==================================================================================================\n",
      "Total params: 8,974,346\n",
      "Trainable params: 8,974,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 6s - loss: 0.7682 - out1_loss: 0.8251 - out2_loss: 0.6355 - val_loss: 0.3652 - val_out1_loss: 0.4000 - val_out2_loss: 0.2840\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3569 - out1_loss: 0.3955 - out2_loss: 0.2668 - val_loss: 0.3459 - val_out1_loss: 0.3821 - val_out2_loss: 0.2613\n",
      "Epoch 3/120\n",
      "53/53 - 5s - loss: 0.3394 - out1_loss: 0.3767 - out2_loss: 0.2524 - val_loss: 0.3272 - val_out1_loss: 0.3601 - val_out2_loss: 0.2503\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3174 - out1_loss: 0.3522 - out2_loss: 0.2360 - val_loss: 0.3044 - val_out1_loss: 0.3396 - val_out2_loss: 0.2221\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3002 - out1_loss: 0.3341 - out2_loss: 0.2212 - val_loss: 0.2968 - val_out1_loss: 0.3322 - val_out2_loss: 0.2142\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2889 - out1_loss: 0.3213 - out2_loss: 0.2133 - val_loss: 0.2814 - val_out1_loss: 0.3149 - val_out2_loss: 0.2032\n",
      "Epoch 7/120\n",
      "53/53 - 5s - loss: 0.2771 - out1_loss: 0.3089 - out2_loss: 0.2031 - val_loss: 0.2722 - val_out1_loss: 0.3045 - val_out2_loss: 0.1968\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2714 - out1_loss: 0.3028 - out2_loss: 0.1981 - val_loss: 0.2681 - val_out1_loss: 0.2953 - val_out2_loss: 0.2047\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2621 - out1_loss: 0.2919 - out2_loss: 0.1927 - val_loss: 0.2506 - val_out1_loss: 0.2792 - val_out2_loss: 0.1840\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2545 - out1_loss: 0.2832 - out2_loss: 0.1876 - val_loss: 0.2492 - val_out1_loss: 0.2769 - val_out2_loss: 0.1844\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2473 - out1_loss: 0.2751 - out2_loss: 0.1823 - val_loss: 0.2407 - val_out1_loss: 0.2687 - val_out2_loss: 0.1753\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2412 - out1_loss: 0.2686 - out2_loss: 0.1773 - val_loss: 0.2372 - val_out1_loss: 0.2647 - val_out2_loss: 0.1728\n",
      "Epoch 13/120\n",
      "53/53 - 5s - loss: 0.2338 - out1_loss: 0.2602 - out2_loss: 0.1723 - val_loss: 0.2311 - val_out1_loss: 0.2575 - val_out2_loss: 0.1695\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2309 - out1_loss: 0.2569 - out2_loss: 0.1703 - val_loss: 0.2289 - val_out1_loss: 0.2564 - val_out2_loss: 0.1648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2237 - out1_loss: 0.2488 - out2_loss: 0.1650 - val_loss: 0.2234 - val_out1_loss: 0.2470 - val_out2_loss: 0.1683\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2199 - out1_loss: 0.2438 - out2_loss: 0.1642 - val_loss: 0.2204 - val_out1_loss: 0.2444 - val_out2_loss: 0.1645\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2136 - out1_loss: 0.2365 - out2_loss: 0.1602 - val_loss: 0.2130 - val_out1_loss: 0.2372 - val_out2_loss: 0.1565\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2099 - out1_loss: 0.2325 - out2_loss: 0.1571 - val_loss: 0.2116 - val_out1_loss: 0.2348 - val_out2_loss: 0.1573\n",
      "Epoch 19/120\n",
      "53/53 - 5s - loss: 0.2054 - out1_loss: 0.2278 - out2_loss: 0.1530 - val_loss: 0.2100 - val_out1_loss: 0.2339 - val_out2_loss: 0.1542\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.2036 - out1_loss: 0.2254 - out2_loss: 0.1528 - val_loss: 0.2115 - val_out1_loss: 0.2345 - val_out2_loss: 0.1579\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.2009 - out1_loss: 0.2225 - out2_loss: 0.1504 - val_loss: 0.2103 - val_out1_loss: 0.2327 - val_out2_loss: 0.1579\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1991 - out1_loss: 0.2207 - out2_loss: 0.1487 - val_loss: 0.2194 - val_out1_loss: 0.2408 - val_out2_loss: 0.1696\n",
      "Epoch 23/120\n",
      "53/53 - 5s - loss: 0.1975 - out1_loss: 0.2181 - out2_loss: 0.1494 - val_loss: 0.2055 - val_out1_loss: 0.2279 - val_out2_loss: 0.1532\n",
      "Epoch 24/120\n",
      "53/53 - 5s - loss: 0.1914 - out1_loss: 0.2119 - out2_loss: 0.1435 - val_loss: 0.2074 - val_out1_loss: 0.2293 - val_out2_loss: 0.1565\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1885 - out1_loss: 0.2088 - out2_loss: 0.1413 - val_loss: 0.2041 - val_out1_loss: 0.2271 - val_out2_loss: 0.1506\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1857 - out1_loss: 0.2056 - out2_loss: 0.1393 - val_loss: 0.2017 - val_out1_loss: 0.2244 - val_out2_loss: 0.1487\n",
      "Epoch 27/120\n",
      "53/53 - 5s - loss: 0.1837 - out1_loss: 0.2032 - out2_loss: 0.1383 - val_loss: 0.2011 - val_out1_loss: 0.2242 - val_out2_loss: 0.1470\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1820 - out1_loss: 0.2010 - out2_loss: 0.1375 - val_loss: 0.2007 - val_out1_loss: 0.2230 - val_out2_loss: 0.1488\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1790 - out1_loss: 0.1978 - out2_loss: 0.1353 - val_loss: 0.2004 - val_out1_loss: 0.2236 - val_out2_loss: 0.1464\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1773 - out1_loss: 0.1959 - out2_loss: 0.1338 - val_loss: 0.2000 - val_out1_loss: 0.2227 - val_out2_loss: 0.1470\n",
      "Epoch 31/120\n",
      "53/53 - 5s - loss: 0.1761 - out1_loss: 0.1941 - out2_loss: 0.1340 - val_loss: 0.2015 - val_out1_loss: 0.2241 - val_out2_loss: 0.1488\n",
      "Epoch 32/120\n",
      "53/53 - 5s - loss: 0.1728 - out1_loss: 0.1906 - out2_loss: 0.1313 - val_loss: 0.2012 - val_out1_loss: 0.2226 - val_out2_loss: 0.1513\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1721 - out1_loss: 0.1896 - out2_loss: 0.1311 - val_loss: 0.2012 - val_out1_loss: 0.2231 - val_out2_loss: 0.1500\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1689 - out1_loss: 0.1863 - out2_loss: 0.1285 - val_loss: 0.1972 - val_out1_loss: 0.2196 - val_out2_loss: 0.1449\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1665 - out1_loss: 0.1833 - out2_loss: 0.1271 - val_loss: 0.1997 - val_out1_loss: 0.2224 - val_out2_loss: 0.1468\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1649 - out1_loss: 0.1817 - out2_loss: 0.1258 - val_loss: 0.1992 - val_out1_loss: 0.2226 - val_out2_loss: 0.1446\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1636 - out1_loss: 0.1799 - out2_loss: 0.1255 - val_loss: 0.1973 - val_out1_loss: 0.2199 - val_out2_loss: 0.1445\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1629 - out1_loss: 0.1790 - out2_loss: 0.1253 - val_loss: 0.1983 - val_out1_loss: 0.2199 - val_out2_loss: 0.1480\n",
      "Epoch 39/120\n",
      "53/53 - 5s - loss: 0.1606 - out1_loss: 0.1763 - out2_loss: 0.1239 - val_loss: 0.1959 - val_out1_loss: 0.2181 - val_out2_loss: 0.1439\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1585 - out1_loss: 0.1742 - out2_loss: 0.1219 - val_loss: 0.1965 - val_out1_loss: 0.2191 - val_out2_loss: 0.1438\n",
      "Epoch 41/120\n",
      "53/53 - 5s - loss: 0.1579 - out1_loss: 0.1736 - out2_loss: 0.1214 - val_loss: 0.1972 - val_out1_loss: 0.2191 - val_out2_loss: 0.1463\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1562 - out1_loss: 0.1717 - out2_loss: 0.1199 - val_loss: 0.1968 - val_out1_loss: 0.2196 - val_out2_loss: 0.1437\n",
      "Epoch 43/120\n",
      "53/53 - 5s - loss: 0.1549 - out1_loss: 0.1699 - out2_loss: 0.1199 - val_loss: 0.1957 - val_out1_loss: 0.2185 - val_out2_loss: 0.1426\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1543 - out1_loss: 0.1693 - out2_loss: 0.1193 - val_loss: 0.2018 - val_out1_loss: 0.2247 - val_out2_loss: 0.1484\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1534 - out1_loss: 0.1682 - out2_loss: 0.1188 - val_loss: 0.2002 - val_out1_loss: 0.2232 - val_out2_loss: 0.1465\n",
      "Epoch 46/120\n",
      "53/53 - 5s - loss: 0.1547 - out1_loss: 0.1686 - out2_loss: 0.1223 - val_loss: 0.1962 - val_out1_loss: 0.2187 - val_out2_loss: 0.1436\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1492 - out1_loss: 0.1636 - out2_loss: 0.1157 - val_loss: 0.1958 - val_out1_loss: 0.2180 - val_out2_loss: 0.1439\n",
      "Epoch 48/120\n",
      "53/53 - 5s - loss: 0.1504 - out1_loss: 0.1646 - out2_loss: 0.1172 - val_loss: 0.1958 - val_out1_loss: 0.2186 - val_out2_loss: 0.1426\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1483 - out1_loss: 0.1622 - out2_loss: 0.1158 - val_loss: 0.1988 - val_out1_loss: 0.2215 - val_out2_loss: 0.1460\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1465 - out1_loss: 0.1604 - out2_loss: 0.1142 - val_loss: 0.1956 - val_out1_loss: 0.2171 - val_out2_loss: 0.1457\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1468 - out1_loss: 0.1604 - out2_loss: 0.1150 - val_loss: 0.1953 - val_out1_loss: 0.2178 - val_out2_loss: 0.1429\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1462 - out1_loss: 0.1601 - out2_loss: 0.1139 - val_loss: 0.1963 - val_out1_loss: 0.2186 - val_out2_loss: 0.1442\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1433 - out1_loss: 0.1567 - out2_loss: 0.1120 - val_loss: 0.1967 - val_out1_loss: 0.2194 - val_out2_loss: 0.1437\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1426 - out1_loss: 0.1560 - out2_loss: 0.1114 - val_loss: 0.1950 - val_out1_loss: 0.2166 - val_out2_loss: 0.1447\n",
      "Epoch 55/120\n",
      "53/53 - 5s - loss: 0.1417 - out1_loss: 0.1547 - out2_loss: 0.1114 - val_loss: 0.1968 - val_out1_loss: 0.2196 - val_out2_loss: 0.1436\n",
      "Epoch 56/120\n",
      "53/53 - 5s - loss: 0.1416 - out1_loss: 0.1547 - out2_loss: 0.1110 - val_loss: 0.1966 - val_out1_loss: 0.2184 - val_out2_loss: 0.1455\n",
      "Epoch 57/120\n",
      "53/53 - 5s - loss: 0.1414 - out1_loss: 0.1544 - out2_loss: 0.1108 - val_loss: 0.1967 - val_out1_loss: 0.2192 - val_out2_loss: 0.1441\n",
      "Epoch 58/120\n",
      "53/53 - 5s - loss: 0.1397 - out1_loss: 0.1526 - out2_loss: 0.1097 - val_loss: 0.1943 - val_out1_loss: 0.2164 - val_out2_loss: 0.1427\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1380 - out1_loss: 0.1507 - out2_loss: 0.1086 - val_loss: 0.1964 - val_out1_loss: 0.2191 - val_out2_loss: 0.1433\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1377 - out1_loss: 0.1501 - out2_loss: 0.1088 - val_loss: 0.1954 - val_out1_loss: 0.2179 - val_out2_loss: 0.1429\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1367 - out1_loss: 0.1491 - out2_loss: 0.1076 - val_loss: 0.1929 - val_out1_loss: 0.2152 - val_out2_loss: 0.1408\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1364 - out1_loss: 0.1486 - out2_loss: 0.1079 - val_loss: 0.1952 - val_out1_loss: 0.2179 - val_out2_loss: 0.1423\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1356 - out1_loss: 0.1477 - out2_loss: 0.1073 - val_loss: 0.1941 - val_out1_loss: 0.2164 - val_out2_loss: 0.1422\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1352 - out1_loss: 0.1472 - out2_loss: 0.1072 - val_loss: 0.2003 - val_out1_loss: 0.2222 - val_out2_loss: 0.1492\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1353 - out1_loss: 0.1474 - out2_loss: 0.1073 - val_loss: 0.1967 - val_out1_loss: 0.2188 - val_out2_loss: 0.1450\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1336 - out1_loss: 0.1455 - out2_loss: 0.1059 - val_loss: 0.1952 - val_out1_loss: 0.2181 - val_out2_loss: 0.1417\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1330 - out1_loss: 0.1447 - out2_loss: 0.1056 - val_loss: 0.1962 - val_out1_loss: 0.2189 - val_out2_loss: 0.1431\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1318 - out1_loss: 0.1435 - out2_loss: 0.1045 - val_loss: 0.1943 - val_out1_loss: 0.2163 - val_out2_loss: 0.1429\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.1316 - out1_loss: 0.1431 - out2_loss: 0.1046 - val_loss: 0.1947 - val_out1_loss: 0.2169 - val_out2_loss: 0.1430\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1307 - out1_loss: 0.1423 - out2_loss: 0.1036 - val_loss: 0.1940 - val_out1_loss: 0.2165 - val_out2_loss: 0.1414\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1304 - out1_loss: 0.1419 - out2_loss: 0.1036 - val_loss: 0.1939 - val_out1_loss: 0.2165 - val_out2_loss: 0.1412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1247 - out1_loss: 0.1356 - out2_loss: 0.0992 - val_loss: 0.1918 - val_out1_loss: 0.2141 - val_out2_loss: 0.1397\n",
      "Epoch 73/120\n",
      "53/53 - 5s - loss: 0.1222 - out1_loss: 0.1328 - out2_loss: 0.0976 - val_loss: 0.1913 - val_out1_loss: 0.2136 - val_out2_loss: 0.1394\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1209 - out1_loss: 0.1313 - out2_loss: 0.0968 - val_loss: 0.1911 - val_out1_loss: 0.2134 - val_out2_loss: 0.1391\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1203 - out1_loss: 0.1306 - out2_loss: 0.0964 - val_loss: 0.1910 - val_out1_loss: 0.2132 - val_out2_loss: 0.1391\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1198 - out1_loss: 0.1300 - out2_loss: 0.0961 - val_loss: 0.1910 - val_out1_loss: 0.2132 - val_out2_loss: 0.1390\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1192 - out1_loss: 0.1293 - out2_loss: 0.0956 - val_loss: 0.1908 - val_out1_loss: 0.2131 - val_out2_loss: 0.1390\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1190 - out1_loss: 0.1290 - out2_loss: 0.0955 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1389\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1187 - out1_loss: 0.1288 - out2_loss: 0.0953 - val_loss: 0.1909 - val_out1_loss: 0.2132 - val_out2_loss: 0.1389\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1184 - out1_loss: 0.1284 - out2_loss: 0.0950 - val_loss: 0.1909 - val_out1_loss: 0.2131 - val_out2_loss: 0.1390\n",
      "Epoch 81/120\n",
      "53/53 - 5s - loss: 0.1182 - out1_loss: 0.1282 - out2_loss: 0.0948 - val_loss: 0.1909 - val_out1_loss: 0.2132 - val_out2_loss: 0.1390\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1176 - out1_loss: 0.1275 - out2_loss: 0.0945 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1388\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1176 - out1_loss: 0.1275 - out2_loss: 0.0944 - val_loss: 0.1909 - val_out1_loss: 0.2132 - val_out2_loss: 0.1389\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1172 - out1_loss: 0.1271 - out2_loss: 0.0942 - val_loss: 0.1909 - val_out1_loss: 0.2132 - val_out2_loss: 0.1389\n",
      "Epoch 85/120\n",
      "53/53 - 5s - loss: 0.1173 - out1_loss: 0.1271 - out2_loss: 0.0942 - val_loss: 0.1911 - val_out1_loss: 0.2134 - val_out2_loss: 0.1390\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1170 - out1_loss: 0.1268 - out2_loss: 0.0942 - val_loss: 0.1911 - val_out1_loss: 0.2134 - val_out2_loss: 0.1390\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1166 - out1_loss: 0.1264 - out2_loss: 0.0938 - val_loss: 0.1909 - val_out1_loss: 0.2132 - val_out2_loss: 0.1389\n",
      "Epoch 88/120\n",
      "53/53 - 5s - loss: 0.1164 - out1_loss: 0.1262 - out2_loss: 0.0936 - val_loss: 0.1908 - val_out1_loss: 0.2131 - val_out2_loss: 0.1388\n",
      "Epoch 89/120\n",
      "53/53 - 5s - loss: 0.1163 - out1_loss: 0.1260 - out2_loss: 0.0936 - val_loss: 0.1908 - val_out1_loss: 0.2131 - val_out2_loss: 0.1388\n",
      "Epoch 90/120\n",
      "53/53 - 5s - loss: 0.1161 - out1_loss: 0.1259 - out2_loss: 0.0935 - val_loss: 0.1908 - val_out1_loss: 0.2131 - val_out2_loss: 0.1388\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.1162 - out1_loss: 0.1259 - out2_loss: 0.0935 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1388\n",
      "Epoch 92/120\n",
      "53/53 - 5s - loss: 0.1161 - out1_loss: 0.1258 - out2_loss: 0.0935 - val_loss: 0.1908 - val_out1_loss: 0.2131 - val_out2_loss: 0.1388\n",
      "Epoch 93/120\n",
      "53/53 - 5s - loss: 0.1160 - out1_loss: 0.1257 - out2_loss: 0.0933 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 94/120\n",
      "53/53 - 5s - loss: 0.1161 - out1_loss: 0.1258 - out2_loss: 0.0934 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 95/120\n",
      "53/53 - 5s - loss: 0.1159 - out1_loss: 0.1256 - out2_loss: 0.0934 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1159 - out1_loss: 0.1255 - out2_loss: 0.0933 - val_loss: 0.1908 - val_out1_loss: 0.2131 - val_out2_loss: 0.1387\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1158 - out1_loss: 0.1255 - out2_loss: 0.0933 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 98/120\n",
      "53/53 - 5s - loss: 0.1158 - out1_loss: 0.1255 - out2_loss: 0.0933 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1158 - out1_loss: 0.1255 - out2_loss: 0.0932 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1157 - out1_loss: 0.1254 - out2_loss: 0.0931 - val_loss: 0.1908 - val_out1_loss: 0.2131 - val_out2_loss: 0.1388\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1159 - out1_loss: 0.1256 - out2_loss: 0.0934 - val_loss: 0.1908 - val_out1_loss: 0.2131 - val_out2_loss: 0.1388\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1156 - out1_loss: 0.1253 - out2_loss: 0.0931 - val_loss: 0.1908 - val_out1_loss: 0.2131 - val_out2_loss: 0.1388\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1156 - out1_loss: 0.1253 - out2_loss: 0.0931 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 104/120\n",
      "53/53 - 5s - loss: 0.1158 - out1_loss: 0.1254 - out2_loss: 0.0932 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1157 - out1_loss: 0.1254 - out2_loss: 0.0932 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 106/120\n",
      "53/53 - 5s - loss: 0.1155 - out1_loss: 0.1251 - out2_loss: 0.0931 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 107/120\n",
      "53/53 - 5s - loss: 0.1157 - out1_loss: 0.1253 - out2_loss: 0.0932 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1157 - out1_loss: 0.1253 - out2_loss: 0.0932 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1158 - out1_loss: 0.1255 - out2_loss: 0.0933 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1157 - out1_loss: 0.1253 - out2_loss: 0.0932 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 111/120\n",
      "53/53 - 5s - loss: 0.1155 - out1_loss: 0.1252 - out2_loss: 0.0931 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1157 - out1_loss: 0.1253 - out2_loss: 0.0932 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 113/120\n",
      "53/53 - 5s - loss: 0.1158 - out1_loss: 0.1254 - out2_loss: 0.0932 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.1157 - out1_loss: 0.1253 - out2_loss: 0.0931 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1157 - out1_loss: 0.1254 - out2_loss: 0.0932 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1156 - out1_loss: 0.1253 - out2_loss: 0.0931 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1155 - out1_loss: 0.1251 - out2_loss: 0.0931 - val_loss: 0.1908 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 118/120\n",
      "53/53 - 5s - loss: 0.1156 - out1_loss: 0.1252 - out2_loss: 0.0931 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.1155 - out1_loss: 0.1252 - out2_loss: 0.0931 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1156 - out1_loss: 0.1252 - out2_loss: 0.0931 - val_loss: 0.1907 - val_out1_loss: 0.2130 - val_out2_loss: 0.1387\n",
      "#################### 0.3715716160446143\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_36 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_37 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_38 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 107, 128)     512         tf_op_layer_strided_slice_36[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_37[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_38[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_36 (SpatialDr (None, 107, 128)     0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_37 (SpatialDr (None, 107, 128)     0           embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_38 (SpatialDr (None, 107, 128)     0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_18 (TensorFl [(None, 107, 384)]   0           spatial_dropout1d_36[0][0]       \n",
      "                                                                 spatial_dropout1d_37[0][0]       \n",
      "                                                                 spatial_dropout1d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_39 (SpatialDr (None, 107, 384)     0           tf_op_layer_concat_18[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 107, 128)     256         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_19 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_39[0][0]       \n",
      "                                                                 dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_9 (Transforme (None, 107, 512)     1577984     tf_op_layer_concat_19[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_27 (Bidirectional (None, 107, 768)     2068992     transformer_block_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_28 (Bidirectional (None, 107, 768)     2658816     bidirectional_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_29 (Bidirectional (None, 107, 768)     2658816     bidirectional_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_39 (T [(None, 68, 768)]    0           bidirectional_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_39[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_39[0][0\n",
      "==================================================================================================\n",
      "Total params: 8,974,346\n",
      "Trainable params: 8,974,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 6s - loss: 0.6952 - out1_loss: 0.7546 - out2_loss: 0.5567 - val_loss: 0.3678 - val_out1_loss: 0.4070 - val_out2_loss: 0.2763\n",
      "Epoch 2/120\n",
      "53/53 - 5s - loss: 0.3558 - out1_loss: 0.3935 - out2_loss: 0.2676 - val_loss: 0.3393 - val_out1_loss: 0.3771 - val_out2_loss: 0.2509\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3278 - out1_loss: 0.3642 - out2_loss: 0.2428 - val_loss: 0.3024 - val_out1_loss: 0.3372 - val_out2_loss: 0.2212\n",
      "Epoch 4/120\n",
      "53/53 - 5s - loss: 0.3009 - out1_loss: 0.3345 - out2_loss: 0.2224 - val_loss: 0.2904 - val_out1_loss: 0.3254 - val_out2_loss: 0.2085\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.2883 - out1_loss: 0.3211 - out2_loss: 0.2117 - val_loss: 0.2761 - val_out1_loss: 0.3096 - val_out2_loss: 0.1980\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2762 - out1_loss: 0.3068 - out2_loss: 0.2049 - val_loss: 0.2753 - val_out1_loss: 0.3059 - val_out2_loss: 0.2039\n",
      "Epoch 7/120\n",
      "53/53 - 5s - loss: 0.2675 - out1_loss: 0.2971 - out2_loss: 0.1985 - val_loss: 0.2580 - val_out1_loss: 0.2868 - val_out2_loss: 0.1907\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2573 - out1_loss: 0.2859 - out2_loss: 0.1906 - val_loss: 0.2512 - val_out1_loss: 0.2803 - val_out2_loss: 0.1832\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2500 - out1_loss: 0.2783 - out2_loss: 0.1841 - val_loss: 0.2489 - val_out1_loss: 0.2791 - val_out2_loss: 0.1783\n",
      "Epoch 10/120\n",
      "53/53 - 5s - loss: 0.2413 - out1_loss: 0.2684 - out2_loss: 0.1780 - val_loss: 0.2443 - val_out1_loss: 0.2728 - val_out2_loss: 0.1777\n",
      "Epoch 11/120\n",
      "53/53 - 5s - loss: 0.2361 - out1_loss: 0.2619 - out2_loss: 0.1761 - val_loss: 0.2313 - val_out1_loss: 0.2582 - val_out2_loss: 0.1684\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2299 - out1_loss: 0.2548 - out2_loss: 0.1719 - val_loss: 0.2363 - val_out1_loss: 0.2655 - val_out2_loss: 0.1683\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2245 - out1_loss: 0.2491 - out2_loss: 0.1672 - val_loss: 0.2253 - val_out1_loss: 0.2509 - val_out2_loss: 0.1654\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2185 - out1_loss: 0.2422 - out2_loss: 0.1631 - val_loss: 0.2202 - val_out1_loss: 0.2459 - val_out2_loss: 0.1602\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2141 - out1_loss: 0.2372 - out2_loss: 0.1604 - val_loss: 0.2250 - val_out1_loss: 0.2492 - val_out2_loss: 0.1686\n",
      "Epoch 16/120\n",
      "53/53 - 5s - loss: 0.2095 - out1_loss: 0.2322 - out2_loss: 0.1566 - val_loss: 0.2131 - val_out1_loss: 0.2385 - val_out2_loss: 0.1540\n",
      "Epoch 17/120\n",
      "53/53 - 5s - loss: 0.2095 - out1_loss: 0.2322 - out2_loss: 0.1565 - val_loss: 0.2138 - val_out1_loss: 0.2386 - val_out2_loss: 0.1559\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2046 - out1_loss: 0.2266 - out2_loss: 0.1534 - val_loss: 0.2117 - val_out1_loss: 0.2362 - val_out2_loss: 0.1547\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.2026 - out1_loss: 0.2243 - out2_loss: 0.1519 - val_loss: 0.2110 - val_out1_loss: 0.2367 - val_out2_loss: 0.1512\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.1963 - out1_loss: 0.2176 - out2_loss: 0.1466 - val_loss: 0.2106 - val_out1_loss: 0.2343 - val_out2_loss: 0.1552\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.1941 - out1_loss: 0.2151 - out2_loss: 0.1452 - val_loss: 0.2090 - val_out1_loss: 0.2321 - val_out2_loss: 0.1551\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1907 - out1_loss: 0.2112 - out2_loss: 0.1430 - val_loss: 0.2051 - val_out1_loss: 0.2294 - val_out2_loss: 0.1485\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1890 - out1_loss: 0.2094 - out2_loss: 0.1414 - val_loss: 0.2040 - val_out1_loss: 0.2265 - val_out2_loss: 0.1514\n",
      "Epoch 24/120\n",
      "53/53 - 5s - loss: 0.1856 - out1_loss: 0.2054 - out2_loss: 0.1393 - val_loss: 0.2075 - val_out1_loss: 0.2306 - val_out2_loss: 0.1535\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1841 - out1_loss: 0.2036 - out2_loss: 0.1385 - val_loss: 0.2080 - val_out1_loss: 0.2331 - val_out2_loss: 0.1492\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1816 - out1_loss: 0.2006 - out2_loss: 0.1372 - val_loss: 0.2038 - val_out1_loss: 0.2272 - val_out2_loss: 0.1493\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1779 - out1_loss: 0.1966 - out2_loss: 0.1343 - val_loss: 0.2011 - val_out1_loss: 0.2251 - val_out2_loss: 0.1451\n",
      "Epoch 28/120\n",
      "53/53 - 5s - loss: 0.1756 - out1_loss: 0.1937 - out2_loss: 0.1333 - val_loss: 0.2017 - val_out1_loss: 0.2258 - val_out2_loss: 0.1453\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1754 - out1_loss: 0.1936 - out2_loss: 0.1330 - val_loss: 0.2025 - val_out1_loss: 0.2259 - val_out2_loss: 0.1477\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1731 - out1_loss: 0.1908 - out2_loss: 0.1320 - val_loss: 0.1994 - val_out1_loss: 0.2224 - val_out2_loss: 0.1458\n",
      "Epoch 31/120\n",
      "53/53 - 5s - loss: 0.1695 - out1_loss: 0.1868 - out2_loss: 0.1291 - val_loss: 0.1984 - val_out1_loss: 0.2218 - val_out2_loss: 0.1439\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1683 - out1_loss: 0.1855 - out2_loss: 0.1283 - val_loss: 0.1987 - val_out1_loss: 0.2217 - val_out2_loss: 0.1451\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1666 - out1_loss: 0.1834 - out2_loss: 0.1275 - val_loss: 0.1983 - val_out1_loss: 0.2207 - val_out2_loss: 0.1458\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1646 - out1_loss: 0.1811 - out2_loss: 0.1262 - val_loss: 0.2027 - val_out1_loss: 0.2257 - val_out2_loss: 0.1490\n",
      "Epoch 35/120\n",
      "53/53 - 5s - loss: 0.1654 - out1_loss: 0.1820 - out2_loss: 0.1268 - val_loss: 0.1990 - val_out1_loss: 0.2225 - val_out2_loss: 0.1441\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1608 - out1_loss: 0.1769 - out2_loss: 0.1232 - val_loss: 0.1973 - val_out1_loss: 0.2203 - val_out2_loss: 0.1436\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1606 - out1_loss: 0.1765 - out2_loss: 0.1237 - val_loss: 0.2002 - val_out1_loss: 0.2238 - val_out2_loss: 0.1451\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1576 - out1_loss: 0.1732 - out2_loss: 0.1213 - val_loss: 0.2002 - val_out1_loss: 0.2238 - val_out2_loss: 0.1450\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1576 - out1_loss: 0.1732 - out2_loss: 0.1212 - val_loss: 0.1979 - val_out1_loss: 0.2210 - val_out2_loss: 0.1439\n",
      "Epoch 40/120\n",
      "53/53 - 5s - loss: 0.1565 - out1_loss: 0.1713 - out2_loss: 0.1219 - val_loss: 0.1994 - val_out1_loss: 0.2218 - val_out2_loss: 0.1470\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1559 - out1_loss: 0.1709 - out2_loss: 0.1208 - val_loss: 0.2000 - val_out1_loss: 0.2221 - val_out2_loss: 0.1486\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1535 - out1_loss: 0.1683 - out2_loss: 0.1190 - val_loss: 0.1987 - val_out1_loss: 0.2220 - val_out2_loss: 0.1443\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1516 - out1_loss: 0.1662 - out2_loss: 0.1175 - val_loss: 0.1952 - val_out1_loss: 0.2183 - val_out2_loss: 0.1413\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1511 - out1_loss: 0.1655 - out2_loss: 0.1175 - val_loss: 0.2008 - val_out1_loss: 0.2247 - val_out2_loss: 0.1449\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1520 - out1_loss: 0.1667 - out2_loss: 0.1178 - val_loss: 0.1963 - val_out1_loss: 0.2191 - val_out2_loss: 0.1432\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1500 - out1_loss: 0.1641 - out2_loss: 0.1172 - val_loss: 0.1982 - val_out1_loss: 0.2205 - val_out2_loss: 0.1461\n",
      "Epoch 47/120\n",
      "53/53 - 5s - loss: 0.1477 - out1_loss: 0.1617 - out2_loss: 0.1148 - val_loss: 0.1953 - val_out1_loss: 0.2186 - val_out2_loss: 0.1409\n",
      "Epoch 48/120\n",
      "53/53 - 5s - loss: 0.1460 - out1_loss: 0.1598 - out2_loss: 0.1140 - val_loss: 0.1958 - val_out1_loss: 0.2187 - val_out2_loss: 0.1423\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1445 - out1_loss: 0.1581 - out2_loss: 0.1128 - val_loss: 0.1957 - val_out1_loss: 0.2186 - val_out2_loss: 0.1423\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1436 - out1_loss: 0.1572 - out2_loss: 0.1121 - val_loss: 0.1989 - val_out1_loss: 0.2217 - val_out2_loss: 0.1455\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1434 - out1_loss: 0.1566 - out2_loss: 0.1124 - val_loss: 0.1958 - val_out1_loss: 0.2182 - val_out2_loss: 0.1434\n",
      "Epoch 52/120\n",
      "53/53 - 5s - loss: 0.1429 - out1_loss: 0.1560 - out2_loss: 0.1121 - val_loss: 0.1964 - val_out1_loss: 0.2177 - val_out2_loss: 0.1468\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1407 - out1_loss: 0.1533 - out2_loss: 0.1112 - val_loss: 0.1941 - val_out1_loss: 0.2163 - val_out2_loss: 0.1425\n",
      "Epoch 54/120\n",
      "53/53 - 5s - loss: 0.1397 - out1_loss: 0.1520 - out2_loss: 0.1111 - val_loss: 0.1944 - val_out1_loss: 0.2172 - val_out2_loss: 0.1410\n",
      "Epoch 55/120\n",
      "53/53 - 5s - loss: 0.1404 - out1_loss: 0.1533 - out2_loss: 0.1105 - val_loss: 0.1960 - val_out1_loss: 0.2183 - val_out2_loss: 0.1439\n",
      "Epoch 56/120\n",
      "53/53 - 5s - loss: 0.1408 - out1_loss: 0.1535 - out2_loss: 0.1114 - val_loss: 0.1952 - val_out1_loss: 0.2174 - val_out2_loss: 0.1434\n",
      "Epoch 57/120\n",
      "53/53 - 5s - loss: 0.1377 - out1_loss: 0.1503 - out2_loss: 0.1082 - val_loss: 0.1966 - val_out1_loss: 0.2194 - val_out2_loss: 0.1435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1370 - out1_loss: 0.1492 - out2_loss: 0.1087 - val_loss: 0.1957 - val_out1_loss: 0.2190 - val_out2_loss: 0.1414\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1367 - out1_loss: 0.1488 - out2_loss: 0.1083 - val_loss: 0.1956 - val_out1_loss: 0.2186 - val_out2_loss: 0.1419\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1353 - out1_loss: 0.1474 - out2_loss: 0.1073 - val_loss: 0.1940 - val_out1_loss: 0.2170 - val_out2_loss: 0.1405\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1368 - out1_loss: 0.1489 - out2_loss: 0.1086 - val_loss: 0.2011 - val_out1_loss: 0.2241 - val_out2_loss: 0.1474\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1351 - out1_loss: 0.1470 - out2_loss: 0.1072 - val_loss: 0.1940 - val_out1_loss: 0.2169 - val_out2_loss: 0.1406\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1321 - out1_loss: 0.1438 - out2_loss: 0.1049 - val_loss: 0.1970 - val_out1_loss: 0.2205 - val_out2_loss: 0.1420\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1329 - out1_loss: 0.1446 - out2_loss: 0.1054 - val_loss: 0.1941 - val_out1_loss: 0.2171 - val_out2_loss: 0.1406\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1324 - out1_loss: 0.1442 - out2_loss: 0.1048 - val_loss: 0.1957 - val_out1_loss: 0.2191 - val_out2_loss: 0.1410\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1325 - out1_loss: 0.1440 - out2_loss: 0.1055 - val_loss: 0.1962 - val_out1_loss: 0.2192 - val_out2_loss: 0.1424\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1303 - out1_loss: 0.1417 - out2_loss: 0.1036 - val_loss: 0.1951 - val_out1_loss: 0.2179 - val_out2_loss: 0.1419\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1307 - out1_loss: 0.1422 - out2_loss: 0.1040 - val_loss: 0.1969 - val_out1_loss: 0.2198 - val_out2_loss: 0.1437\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.1291 - out1_loss: 0.1403 - out2_loss: 0.1030 - val_loss: 0.1951 - val_out1_loss: 0.2168 - val_out2_loss: 0.1446\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1291 - out1_loss: 0.1401 - out2_loss: 0.1034 - val_loss: 0.1935 - val_out1_loss: 0.2168 - val_out2_loss: 0.1394\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1287 - out1_loss: 0.1398 - out2_loss: 0.1027 - val_loss: 0.1938 - val_out1_loss: 0.2166 - val_out2_loss: 0.1405\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1267 - out1_loss: 0.1377 - out2_loss: 0.1009 - val_loss: 0.1956 - val_out1_loss: 0.2180 - val_out2_loss: 0.1435\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1264 - out1_loss: 0.1371 - out2_loss: 0.1014 - val_loss: 0.1962 - val_out1_loss: 0.2186 - val_out2_loss: 0.1437\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1262 - out1_loss: 0.1370 - out2_loss: 0.1010 - val_loss: 0.1946 - val_out1_loss: 0.2177 - val_out2_loss: 0.1408\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1250 - out1_loss: 0.1356 - out2_loss: 0.1003 - val_loss: 0.1941 - val_out1_loss: 0.2168 - val_out2_loss: 0.1412\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1246 - out1_loss: 0.1353 - out2_loss: 0.0996 - val_loss: 0.1945 - val_out1_loss: 0.2172 - val_out2_loss: 0.1415\n",
      "Epoch 77/120\n",
      "53/53 - 5s - loss: 0.1250 - out1_loss: 0.1354 - out2_loss: 0.1005 - val_loss: 0.1944 - val_out1_loss: 0.2173 - val_out2_loss: 0.1409\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1231 - out1_loss: 0.1336 - out2_loss: 0.0987 - val_loss: 0.1942 - val_out1_loss: 0.2173 - val_out2_loss: 0.1404\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1243 - out1_loss: 0.1346 - out2_loss: 0.1003 - val_loss: 0.1961 - val_out1_loss: 0.2186 - val_out2_loss: 0.1436\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1244 - out1_loss: 0.1347 - out2_loss: 0.1003 - val_loss: 0.1944 - val_out1_loss: 0.2168 - val_out2_loss: 0.1421\n",
      "Epoch 81/120\n",
      "53/53 - 5s - loss: 0.1179 - out1_loss: 0.1277 - out2_loss: 0.0950 - val_loss: 0.1919 - val_out1_loss: 0.2146 - val_out2_loss: 0.1389\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1153 - out1_loss: 0.1248 - out2_loss: 0.0932 - val_loss: 0.1916 - val_out1_loss: 0.2143 - val_out2_loss: 0.1387\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1141 - out1_loss: 0.1235 - out2_loss: 0.0922 - val_loss: 0.1916 - val_out1_loss: 0.2143 - val_out2_loss: 0.1386\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1134 - out1_loss: 0.1227 - out2_loss: 0.0918 - val_loss: 0.1914 - val_out1_loss: 0.2141 - val_out2_loss: 0.1384\n",
      "Epoch 85/120\n",
      "53/53 - 5s - loss: 0.1127 - out1_loss: 0.1219 - out2_loss: 0.0914 - val_loss: 0.1912 - val_out1_loss: 0.2139 - val_out2_loss: 0.1383\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1126 - out1_loss: 0.1218 - out2_loss: 0.0912 - val_loss: 0.1913 - val_out1_loss: 0.2140 - val_out2_loss: 0.1384\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1119 - out1_loss: 0.1210 - out2_loss: 0.0908 - val_loss: 0.1913 - val_out1_loss: 0.2140 - val_out2_loss: 0.1384\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1115 - out1_loss: 0.1205 - out2_loss: 0.0906 - val_loss: 0.1911 - val_out1_loss: 0.2138 - val_out2_loss: 0.1382\n",
      "Epoch 89/120\n",
      "53/53 - 5s - loss: 0.1113 - out1_loss: 0.1203 - out2_loss: 0.0903 - val_loss: 0.1911 - val_out1_loss: 0.2139 - val_out2_loss: 0.1381\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1111 - out1_loss: 0.1200 - out2_loss: 0.0903 - val_loss: 0.1912 - val_out1_loss: 0.2139 - val_out2_loss: 0.1383\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.1108 - out1_loss: 0.1197 - out2_loss: 0.0901 - val_loss: 0.1911 - val_out1_loss: 0.2138 - val_out2_loss: 0.1382\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.1105 - out1_loss: 0.1194 - out2_loss: 0.0898 - val_loss: 0.1911 - val_out1_loss: 0.2139 - val_out2_loss: 0.1381\n",
      "Epoch 93/120\n",
      "53/53 - 5s - loss: 0.1102 - out1_loss: 0.1190 - out2_loss: 0.0897 - val_loss: 0.1911 - val_out1_loss: 0.2138 - val_out2_loss: 0.1381\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1102 - out1_loss: 0.1190 - out2_loss: 0.0895 - val_loss: 0.1912 - val_out1_loss: 0.2139 - val_out2_loss: 0.1382\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1101 - out1_loss: 0.1189 - out2_loss: 0.0895 - val_loss: 0.1911 - val_out1_loss: 0.2139 - val_out2_loss: 0.1381\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1097 - out1_loss: 0.1184 - out2_loss: 0.0893 - val_loss: 0.1912 - val_out1_loss: 0.2139 - val_out2_loss: 0.1381\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1094 - out1_loss: 0.1181 - out2_loss: 0.0891 - val_loss: 0.1909 - val_out1_loss: 0.2136 - val_out2_loss: 0.1380\n",
      "Epoch 98/120\n",
      "53/53 - 5s - loss: 0.1094 - out1_loss: 0.1181 - out2_loss: 0.0891 - val_loss: 0.1911 - val_out1_loss: 0.2138 - val_out2_loss: 0.1382\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1093 - out1_loss: 0.1180 - out2_loss: 0.0890 - val_loss: 0.1911 - val_out1_loss: 0.2138 - val_out2_loss: 0.1383\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1091 - out1_loss: 0.1177 - out2_loss: 0.0888 - val_loss: 0.1910 - val_out1_loss: 0.2137 - val_out2_loss: 0.1380\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1089 - out1_loss: 0.1176 - out2_loss: 0.0888 - val_loss: 0.1910 - val_out1_loss: 0.2136 - val_out2_loss: 0.1381\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1088 - out1_loss: 0.1175 - out2_loss: 0.0887 - val_loss: 0.1910 - val_out1_loss: 0.2137 - val_out2_loss: 0.1381\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1087 - out1_loss: 0.1173 - out2_loss: 0.0887 - val_loss: 0.1910 - val_out1_loss: 0.2137 - val_out2_loss: 0.1380\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1084 - out1_loss: 0.1170 - out2_loss: 0.0884 - val_loss: 0.1909 - val_out1_loss: 0.2136 - val_out2_loss: 0.1380\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1083 - out1_loss: 0.1169 - out2_loss: 0.0883 - val_loss: 0.1910 - val_out1_loss: 0.2137 - val_out2_loss: 0.1381\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1083 - out1_loss: 0.1168 - out2_loss: 0.0883 - val_loss: 0.1910 - val_out1_loss: 0.2136 - val_out2_loss: 0.1381\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1082 - out1_loss: 0.1168 - out2_loss: 0.0882 - val_loss: 0.1911 - val_out1_loss: 0.2138 - val_out2_loss: 0.1381\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1076 - out1_loss: 0.1160 - out2_loss: 0.0879 - val_loss: 0.1911 - val_out1_loss: 0.2138 - val_out2_loss: 0.1380\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1076 - out1_loss: 0.1161 - out2_loss: 0.0878 - val_loss: 0.1910 - val_out1_loss: 0.2138 - val_out2_loss: 0.1380\n",
      "Epoch 110/120\n",
      "53/53 - 5s - loss: 0.1074 - out1_loss: 0.1158 - out2_loss: 0.0878 - val_loss: 0.1910 - val_out1_loss: 0.2137 - val_out2_loss: 0.1380\n",
      "Epoch 111/120\n",
      "53/53 - 5s - loss: 0.1076 - out1_loss: 0.1160 - out2_loss: 0.0878 - val_loss: 0.1909 - val_out1_loss: 0.2136 - val_out2_loss: 0.1379\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1073 - out1_loss: 0.1157 - out2_loss: 0.0877 - val_loss: 0.1910 - val_out1_loss: 0.2137 - val_out2_loss: 0.1380\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1072 - out1_loss: 0.1157 - out2_loss: 0.0876 - val_loss: 0.1909 - val_out1_loss: 0.2136 - val_out2_loss: 0.1379\n",
      "Epoch 114/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 4s - loss: 0.1074 - out1_loss: 0.1159 - out2_loss: 0.0878 - val_loss: 0.1909 - val_out1_loss: 0.2136 - val_out2_loss: 0.1380\n",
      "Epoch 115/120\n",
      "53/53 - 5s - loss: 0.1074 - out1_loss: 0.1158 - out2_loss: 0.0877 - val_loss: 0.1909 - val_out1_loss: 0.2136 - val_out2_loss: 0.1380\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1073 - out1_loss: 0.1158 - out2_loss: 0.0876 - val_loss: 0.1910 - val_out1_loss: 0.2137 - val_out2_loss: 0.1379\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1073 - out1_loss: 0.1157 - out2_loss: 0.0876 - val_loss: 0.1909 - val_out1_loss: 0.2136 - val_out2_loss: 0.1380\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1072 - out1_loss: 0.1156 - out2_loss: 0.0875 - val_loss: 0.1909 - val_out1_loss: 0.2136 - val_out2_loss: 0.1379\n",
      "Epoch 119/120\n",
      "53/53 - 5s - loss: 0.1071 - out1_loss: 0.1156 - out2_loss: 0.0875 - val_loss: 0.1909 - val_out1_loss: 0.2136 - val_out2_loss: 0.1379\n",
      "Epoch 120/120\n",
      "53/53 - 5s - loss: 0.1073 - out1_loss: 0.1157 - out2_loss: 0.0876 - val_loss: 0.1909 - val_out1_loss: 0.2136 - val_out2_loss: 0.1379\n",
      "#################### 0.35697475411525814\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_48 (T [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_49 (T [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_50 (T [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_36 (Embedding)        (None, 107, 128)     512         tf_op_layer_strided_slice_48[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_49[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_38 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_50[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_48 (SpatialDr (None, 107, 128)     0           embedding_36[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_49 (SpatialDr (None, 107, 128)     0           embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_50 (SpatialDr (None, 107, 128)     0           embedding_38[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_24 (TensorFl [(None, 107, 384)]   0           spatial_dropout1d_48[0][0]       \n",
      "                                                                 spatial_dropout1d_49[0][0]       \n",
      "                                                                 spatial_dropout1d_50[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_51 (SpatialDr (None, 107, 384)     0           tf_op_layer_concat_24[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 107, 128)     256         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_25 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_51[0][0]       \n",
      "                                                                 dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_12 (Transform (None, 107, 512)     1577984     tf_op_layer_concat_25[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 107, 768)     2068992     transformer_block_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 107, 768)     2658816     bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_38 (Bidirectional (None, 107, 768)     2658816     bidirectional_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_51 (T [(None, 68, 768)]    0           bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_51[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_51[0][0\n",
      "==================================================================================================\n",
      "Total params: 8,974,346\n",
      "Trainable params: 8,974,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 6s - loss: 0.7635 - out1_loss: 0.8203 - out2_loss: 0.6310 - val_loss: 0.3727 - val_out1_loss: 0.4093 - val_out2_loss: 0.2874\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3563 - out1_loss: 0.3949 - out2_loss: 0.2661 - val_loss: 0.3453 - val_out1_loss: 0.3845 - val_out2_loss: 0.2537\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3381 - out1_loss: 0.3755 - out2_loss: 0.2509 - val_loss: 0.3277 - val_out1_loss: 0.3648 - val_out2_loss: 0.2412\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3145 - out1_loss: 0.3489 - out2_loss: 0.2340 - val_loss: 0.3041 - val_out1_loss: 0.3386 - val_out2_loss: 0.2235\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.2976 - out1_loss: 0.3313 - out2_loss: 0.2190 - val_loss: 0.2911 - val_out1_loss: 0.3259 - val_out2_loss: 0.2099\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2862 - out1_loss: 0.3189 - out2_loss: 0.2098 - val_loss: 0.2805 - val_out1_loss: 0.3135 - val_out2_loss: 0.2036\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2771 - out1_loss: 0.3086 - out2_loss: 0.2035 - val_loss: 0.2709 - val_out1_loss: 0.3029 - val_out2_loss: 0.1962\n",
      "Epoch 8/120\n",
      "53/53 - 5s - loss: 0.2659 - out1_loss: 0.2954 - out2_loss: 0.1973 - val_loss: 0.2614 - val_out1_loss: 0.2919 - val_out2_loss: 0.1900\n",
      "Epoch 9/120\n",
      "53/53 - 5s - loss: 0.2570 - out1_loss: 0.2861 - out2_loss: 0.1890 - val_loss: 0.2532 - val_out1_loss: 0.2830 - val_out2_loss: 0.1836\n",
      "Epoch 10/120\n",
      "53/53 - 5s - loss: 0.2514 - out1_loss: 0.2798 - out2_loss: 0.1852 - val_loss: 0.2527 - val_out1_loss: 0.2816 - val_out2_loss: 0.1854\n",
      "Epoch 11/120\n",
      "53/53 - 5s - loss: 0.2454 - out1_loss: 0.2728 - out2_loss: 0.1814 - val_loss: 0.2409 - val_out1_loss: 0.2681 - val_out2_loss: 0.1773\n",
      "Epoch 12/120\n",
      "53/53 - 5s - loss: 0.2384 - out1_loss: 0.2649 - out2_loss: 0.1765 - val_loss: 0.2365 - val_out1_loss: 0.2650 - val_out2_loss: 0.1699\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2314 - out1_loss: 0.2572 - out2_loss: 0.1712 - val_loss: 0.2294 - val_out1_loss: 0.2561 - val_out2_loss: 0.1673\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2285 - out1_loss: 0.2536 - out2_loss: 0.1700 - val_loss: 0.2327 - val_out1_loss: 0.2603 - val_out2_loss: 0.1683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/120\n",
      "53/53 - 5s - loss: 0.2220 - out1_loss: 0.2463 - out2_loss: 0.1653 - val_loss: 0.2233 - val_out1_loss: 0.2494 - val_out2_loss: 0.1622\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2185 - out1_loss: 0.2422 - out2_loss: 0.1633 - val_loss: 0.2219 - val_out1_loss: 0.2454 - val_out2_loss: 0.1672\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2104 - out1_loss: 0.2329 - out2_loss: 0.1577 - val_loss: 0.2143 - val_out1_loss: 0.2395 - val_out2_loss: 0.1554\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2087 - out1_loss: 0.2313 - out2_loss: 0.1560 - val_loss: 0.2181 - val_out1_loss: 0.2452 - val_out2_loss: 0.1547\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.2059 - out1_loss: 0.2281 - out2_loss: 0.1543 - val_loss: 0.2137 - val_out1_loss: 0.2382 - val_out2_loss: 0.1564\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.2014 - out1_loss: 0.2233 - out2_loss: 0.1502 - val_loss: 0.2085 - val_out1_loss: 0.2323 - val_out2_loss: 0.1531\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.1982 - out1_loss: 0.2196 - out2_loss: 0.1484 - val_loss: 0.2092 - val_out1_loss: 0.2310 - val_out2_loss: 0.1584\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1943 - out1_loss: 0.2152 - out2_loss: 0.1453 - val_loss: 0.2099 - val_out1_loss: 0.2345 - val_out2_loss: 0.1526\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1929 - out1_loss: 0.2137 - out2_loss: 0.1444 - val_loss: 0.2065 - val_out1_loss: 0.2297 - val_out2_loss: 0.1523\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1904 - out1_loss: 0.2110 - out2_loss: 0.1424 - val_loss: 0.2075 - val_out1_loss: 0.2321 - val_out2_loss: 0.1501\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1879 - out1_loss: 0.2078 - out2_loss: 0.1414 - val_loss: 0.2073 - val_out1_loss: 0.2314 - val_out2_loss: 0.1511\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1858 - out1_loss: 0.2055 - out2_loss: 0.1399 - val_loss: 0.2091 - val_out1_loss: 0.2340 - val_out2_loss: 0.1510\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1838 - out1_loss: 0.2032 - out2_loss: 0.1386 - val_loss: 0.2045 - val_out1_loss: 0.2275 - val_out2_loss: 0.1508\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1812 - out1_loss: 0.2001 - out2_loss: 0.1370 - val_loss: 0.2028 - val_out1_loss: 0.2267 - val_out2_loss: 0.1470\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1804 - out1_loss: 0.1991 - out2_loss: 0.1367 - val_loss: 0.2065 - val_out1_loss: 0.2303 - val_out2_loss: 0.1510\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1768 - out1_loss: 0.1953 - out2_loss: 0.1336 - val_loss: 0.2022 - val_out1_loss: 0.2260 - val_out2_loss: 0.1469\n",
      "Epoch 31/120\n",
      "53/53 - 5s - loss: 0.1736 - out1_loss: 0.1913 - out2_loss: 0.1321 - val_loss: 0.2002 - val_out1_loss: 0.2228 - val_out2_loss: 0.1476\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1717 - out1_loss: 0.1894 - out2_loss: 0.1304 - val_loss: 0.2010 - val_out1_loss: 0.2244 - val_out2_loss: 0.1463\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1728 - out1_loss: 0.1904 - out2_loss: 0.1318 - val_loss: 0.2010 - val_out1_loss: 0.2246 - val_out2_loss: 0.1459\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1688 - out1_loss: 0.1859 - out2_loss: 0.1289 - val_loss: 0.2041 - val_out1_loss: 0.2279 - val_out2_loss: 0.1485\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1669 - out1_loss: 0.1831 - out2_loss: 0.1289 - val_loss: 0.2020 - val_out1_loss: 0.2247 - val_out2_loss: 0.1490\n",
      "Epoch 36/120\n",
      "53/53 - 5s - loss: 0.1654 - out1_loss: 0.1822 - out2_loss: 0.1263 - val_loss: 0.2001 - val_out1_loss: 0.2239 - val_out2_loss: 0.1444\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1640 - out1_loss: 0.1807 - out2_loss: 0.1253 - val_loss: 0.1998 - val_out1_loss: 0.2232 - val_out2_loss: 0.1453\n",
      "Epoch 38/120\n",
      "53/53 - 5s - loss: 0.1620 - out1_loss: 0.1781 - out2_loss: 0.1242 - val_loss: 0.1977 - val_out1_loss: 0.2207 - val_out2_loss: 0.1438\n",
      "Epoch 39/120\n",
      "53/53 - 5s - loss: 0.1596 - out1_loss: 0.1754 - out2_loss: 0.1229 - val_loss: 0.1979 - val_out1_loss: 0.2205 - val_out2_loss: 0.1452\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1583 - out1_loss: 0.1739 - out2_loss: 0.1218 - val_loss: 0.1981 - val_out1_loss: 0.2213 - val_out2_loss: 0.1440\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1617 - out1_loss: 0.1771 - out2_loss: 0.1255 - val_loss: 0.2055 - val_out1_loss: 0.2277 - val_out2_loss: 0.1537\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1572 - out1_loss: 0.1723 - out2_loss: 0.1220 - val_loss: 0.1986 - val_out1_loss: 0.2217 - val_out2_loss: 0.1449\n",
      "Epoch 43/120\n",
      "53/53 - 5s - loss: 0.1542 - out1_loss: 0.1692 - out2_loss: 0.1192 - val_loss: 0.1981 - val_out1_loss: 0.2217 - val_out2_loss: 0.1430\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1545 - out1_loss: 0.1692 - out2_loss: 0.1202 - val_loss: 0.1983 - val_out1_loss: 0.2224 - val_out2_loss: 0.1421\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1534 - out1_loss: 0.1681 - out2_loss: 0.1191 - val_loss: 0.1958 - val_out1_loss: 0.2187 - val_out2_loss: 0.1424\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1508 - out1_loss: 0.1655 - out2_loss: 0.1165 - val_loss: 0.1967 - val_out1_loss: 0.2200 - val_out2_loss: 0.1423\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1491 - out1_loss: 0.1634 - out2_loss: 0.1157 - val_loss: 0.1970 - val_out1_loss: 0.2205 - val_out2_loss: 0.1422\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1482 - out1_loss: 0.1624 - out2_loss: 0.1150 - val_loss: 0.1969 - val_out1_loss: 0.2202 - val_out2_loss: 0.1425\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1488 - out1_loss: 0.1629 - out2_loss: 0.1160 - val_loss: 0.1964 - val_out1_loss: 0.2201 - val_out2_loss: 0.1410\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1482 - out1_loss: 0.1622 - out2_loss: 0.1155 - val_loss: 0.1964 - val_out1_loss: 0.2192 - val_out2_loss: 0.1432\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1455 - out1_loss: 0.1591 - out2_loss: 0.1136 - val_loss: 0.2006 - val_out1_loss: 0.2235 - val_out2_loss: 0.1471\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1452 - out1_loss: 0.1586 - out2_loss: 0.1139 - val_loss: 0.1961 - val_out1_loss: 0.2196 - val_out2_loss: 0.1412\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1449 - out1_loss: 0.1580 - out2_loss: 0.1142 - val_loss: 0.1983 - val_out1_loss: 0.2214 - val_out2_loss: 0.1445\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1431 - out1_loss: 0.1562 - out2_loss: 0.1126 - val_loss: 0.1974 - val_out1_loss: 0.2208 - val_out2_loss: 0.1427\n",
      "Epoch 55/120\n",
      "53/53 - 5s - loss: 0.1427 - out1_loss: 0.1560 - out2_loss: 0.1116 - val_loss: 0.1964 - val_out1_loss: 0.2198 - val_out2_loss: 0.1419\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1360 - out1_loss: 0.1485 - out2_loss: 0.1068 - val_loss: 0.1927 - val_out1_loss: 0.2158 - val_out2_loss: 0.1390\n",
      "Epoch 57/120\n",
      "53/53 - 5s - loss: 0.1336 - out1_loss: 0.1458 - out2_loss: 0.1051 - val_loss: 0.1925 - val_out1_loss: 0.2154 - val_out2_loss: 0.1391\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1325 - out1_loss: 0.1446 - out2_loss: 0.1044 - val_loss: 0.1922 - val_out1_loss: 0.2151 - val_out2_loss: 0.1387\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1320 - out1_loss: 0.1439 - out2_loss: 0.1040 - val_loss: 0.1921 - val_out1_loss: 0.2150 - val_out2_loss: 0.1386\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1312 - out1_loss: 0.1431 - out2_loss: 0.1035 - val_loss: 0.1921 - val_out1_loss: 0.2150 - val_out2_loss: 0.1386\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1307 - out1_loss: 0.1426 - out2_loss: 0.1031 - val_loss: 0.1919 - val_out1_loss: 0.2148 - val_out2_loss: 0.1385\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1305 - out1_loss: 0.1422 - out2_loss: 0.1031 - val_loss: 0.1923 - val_out1_loss: 0.2152 - val_out2_loss: 0.1388\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1302 - out1_loss: 0.1419 - out2_loss: 0.1029 - val_loss: 0.1920 - val_out1_loss: 0.2149 - val_out2_loss: 0.1385\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1298 - out1_loss: 0.1414 - out2_loss: 0.1025 - val_loss: 0.1919 - val_out1_loss: 0.2148 - val_out2_loss: 0.1385\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1296 - out1_loss: 0.1412 - out2_loss: 0.1025 - val_loss: 0.1919 - val_out1_loss: 0.2148 - val_out2_loss: 0.1386\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1293 - out1_loss: 0.1409 - out2_loss: 0.1023 - val_loss: 0.1918 - val_out1_loss: 0.2147 - val_out2_loss: 0.1385\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1291 - out1_loss: 0.1406 - out2_loss: 0.1021 - val_loss: 0.1919 - val_out1_loss: 0.2148 - val_out2_loss: 0.1384\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1288 - out1_loss: 0.1403 - out2_loss: 0.1019 - val_loss: 0.1918 - val_out1_loss: 0.2147 - val_out2_loss: 0.1385\n",
      "Epoch 69/120\n",
      "53/53 - 5s - loss: 0.1286 - out1_loss: 0.1401 - out2_loss: 0.1018 - val_loss: 0.1917 - val_out1_loss: 0.2146 - val_out2_loss: 0.1383\n",
      "Epoch 70/120\n",
      "53/53 - 5s - loss: 0.1282 - out1_loss: 0.1396 - out2_loss: 0.1016 - val_loss: 0.1919 - val_out1_loss: 0.2148 - val_out2_loss: 0.1384\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1282 - out1_loss: 0.1396 - out2_loss: 0.1015 - val_loss: 0.1917 - val_out1_loss: 0.2145 - val_out2_loss: 0.1384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1282 - out1_loss: 0.1397 - out2_loss: 0.1015 - val_loss: 0.1917 - val_out1_loss: 0.2145 - val_out2_loss: 0.1383\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1277 - out1_loss: 0.1391 - out2_loss: 0.1013 - val_loss: 0.1917 - val_out1_loss: 0.2146 - val_out2_loss: 0.1382\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1275 - out1_loss: 0.1388 - out2_loss: 0.1012 - val_loss: 0.1921 - val_out1_loss: 0.2150 - val_out2_loss: 0.1386\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1275 - out1_loss: 0.1388 - out2_loss: 0.1011 - val_loss: 0.1919 - val_out1_loss: 0.2149 - val_out2_loss: 0.1384\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1274 - out1_loss: 0.1387 - out2_loss: 0.1010 - val_loss: 0.1919 - val_out1_loss: 0.2148 - val_out2_loss: 0.1385\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1270 - out1_loss: 0.1383 - out2_loss: 0.1006 - val_loss: 0.1918 - val_out1_loss: 0.2148 - val_out2_loss: 0.1383\n",
      "Epoch 78/120\n",
      "53/53 - 5s - loss: 0.1269 - out1_loss: 0.1381 - out2_loss: 0.1006 - val_loss: 0.1918 - val_out1_loss: 0.2146 - val_out2_loss: 0.1384\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1268 - out1_loss: 0.1380 - out2_loss: 0.1005 - val_loss: 0.1917 - val_out1_loss: 0.2146 - val_out2_loss: 0.1383\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1260 - out1_loss: 0.1372 - out2_loss: 0.1000 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.1260 - out1_loss: 0.1371 - out2_loss: 0.1001 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1382\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1260 - out1_loss: 0.1370 - out2_loss: 0.1001 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 83/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0999 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 84/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0999 - val_loss: 0.1916 - val_out1_loss: 0.2144 - val_out2_loss: 0.1382\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0998 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 86/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1368 - out2_loss: 0.0999 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1382\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1366 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 88/120\n",
      "53/53 - 5s - loss: 0.1257 - out1_loss: 0.1368 - out2_loss: 0.0998 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.1256 - out1_loss: 0.1367 - out2_loss: 0.0998 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1366 - out2_loss: 0.0996 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 91/120\n",
      "53/53 - 5s - loss: 0.1254 - out1_loss: 0.1364 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 92/120\n",
      "53/53 - 5s - loss: 0.1256 - out1_loss: 0.1366 - out2_loss: 0.0998 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1366 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 94/120\n",
      "53/53 - 5s - loss: 0.1255 - out1_loss: 0.1366 - out2_loss: 0.0997 - val_loss: 0.1914 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1256 - out1_loss: 0.1367 - out2_loss: 0.0999 - val_loss: 0.1914 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1366 - out2_loss: 0.0997 - val_loss: 0.1914 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1254 - out1_loss: 0.1364 - out2_loss: 0.0996 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1253 - out1_loss: 0.1364 - out2_loss: 0.0996 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1366 - out2_loss: 0.0996 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 100/120\n",
      "53/53 - 5s - loss: 0.1255 - out1_loss: 0.1365 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1256 - out1_loss: 0.1366 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1256 - out1_loss: 0.1367 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1366 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 104/120\n",
      "53/53 - 5s - loss: 0.1254 - out1_loss: 0.1364 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1366 - out2_loss: 0.0996 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1253 - out1_loss: 0.1364 - out2_loss: 0.0996 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1365 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 108/120\n",
      "53/53 - 5s - loss: 0.1256 - out1_loss: 0.1367 - out2_loss: 0.0998 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1254 - out1_loss: 0.1364 - out2_loss: 0.0996 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1256 - out1_loss: 0.1367 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1256 - out1_loss: 0.1367 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2144 - val_out2_loss: 0.1381\n",
      "Epoch 112/120\n",
      "53/53 - 5s - loss: 0.1257 - out1_loss: 0.1367 - out2_loss: 0.0998 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 113/120\n",
      "53/53 - 5s - loss: 0.1254 - out1_loss: 0.1365 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.1253 - out1_loss: 0.1363 - out2_loss: 0.0995 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1365 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 116/120\n",
      "53/53 - 5s - loss: 0.1253 - out1_loss: 0.1364 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1365 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1366 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 119/120\n",
      "53/53 - 5s - loss: 0.1254 - out1_loss: 0.1364 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1366 - out2_loss: 0.0997 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1381\n",
      "#################### 0.3775206452188218\n",
      "(629, 107, 5) (3005, 130, 5)\n"
     ]
    }
   ],
   "source": [
    "FOLDS = KFold(n_splits=5, random_state=815, shuffle=True)\n",
    "\n",
    "oofs_pred = np.zeros_like(train_labels)\n",
    "public_preds_array = []\n",
    "public_preds_array = []\n",
    "\n",
    "for i, (trn_idx, vld_idx) in enumerate(FOLDS.split(train_inputs)):\n",
    "    trn_inputs = train_inputs[trn_idx]\n",
    "    vld_inputs = train_inputs[vld_idx]\n",
    "    \n",
    "    trn_inputs_bpps = train_bpps[trn_idx]\n",
    "    vld_inputs_bpps = train_bpps[vld_idx]\n",
    "\n",
    "    trn_labels = train_labels[trn_idx]\n",
    "    vld_labels = train_labels[vld_idx]\n",
    "\n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        [trn_inputs, trn_inputs_bpps], trn_labels, \n",
    "        validation_data=([vld_inputs, vld_inputs_bpps], vld_labels),\n",
    "        batch_size=32,\n",
    "        epochs=120,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "            tf.keras.callbacks.ModelCheckpoint('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_815.h5')\n",
    "        ],\n",
    "        verbose=2,\n",
    "    )\n",
    "    model.load_weights('./tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_815.h5')\n",
    "    outputs, outputs2 = model.predict([vld_inputs, vld_inputs_bpps])\n",
    "    oofs_pred[vld_idx] = outputs\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    errors = []\n",
    "    for idx in range(5):\n",
    "         errors.append(np.sqrt(mean_squared_error(vld_labels[:, idx], outputs[:, idx])))\n",
    "    final_error = np.mean(errors)\n",
    "    print('#'*20, final_error)\n",
    "\n",
    "    public_df = test.query(\"seq_length == 107\").copy()\n",
    "    private_df = test.query(\"seq_length == 130\").copy()\n",
    "    \n",
    "    public_df['sequence'] = public_df['sequence'].apply(lambda x: [token2int0[ele] for ele in x])\n",
    "    public_df['structure'] = public_df['structure'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    public_df['predicted_loop_type'] = public_df['predicted_loop_type'].apply(lambda x: [token2int2[ele] for ele in x])\n",
    "    public_inputs = np.transpose(np.array(public_df[['sequence', 'structure', 'predicted_loop_type']].values.tolist()), (0, 2, 1))\n",
    "\n",
    "    private_df['sequence'] = private_df['sequence'].apply(lambda x: [token2int0[ele] for ele in x])\n",
    "    private_df['structure'] = private_df['structure'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    private_df['predicted_loop_type'] = private_df['predicted_loop_type'].apply(lambda x: [token2int2[ele] for ele in x])\n",
    "    private_inputs = np.transpose(np.array(private_df[['sequence', 'structure', 'predicted_loop_type']].values.tolist()), (0, 2, 1))\n",
    "\n",
    "    public_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in public_df['id']])\n",
    "    public_bpps = public_bpps[:, :, np.newaxis]\n",
    "    \n",
    "    private_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in private_df['id']])\n",
    "    private_bpps = private_bpps[:, :, np.newaxis] \n",
    "\n",
    "    # Caveat: The prediction format requires the output to be the same length as the input,\n",
    "    # although it's not the case for the training data.\n",
    "    model_short = build_model(seq_len=107, pred_len=107)\n",
    "    model_long = build_model(seq_len=130, pred_len=130)\n",
    "\n",
    "    model_short.load_weights('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_815.h5')\n",
    "    model_long.load_weights('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_815.h5')\n",
    "\n",
    "    public_preds, outputs2 = model_short.predict([public_inputs, public_bpps])\n",
    "    private_preds, outputs2 = model_long.predict([private_inputs,private_bpps])\n",
    "    \n",
    "    public_preds_array.append(public_preds)\n",
    "    public_preds_array.append(private_preds)\n",
    "\n",
    "    print(public_preds.shape, private_preds.shape)\n",
    "\n",
    "    preds_ls = []\n",
    "\n",
    "    for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
    "        for idx, uid in enumerate(df.id):\n",
    "            single_pred = preds[idx]\n",
    "\n",
    "            single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "            preds_ls.append(single_df)\n",
    "\n",
    "    preds_df = pd.concat(preds_ls)\n",
    "\n",
    "    submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "    submission.to_csv(f'submission_tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_815_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, uid in enumerate(train.id):\n",
    "#     single_pred = oofs_pred[i]\n",
    "\n",
    "#     oof_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "#     oof_df['id_seqpos'] = [f'{uid}_{x}' for x in range(oof_df.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gru 가 들어가면 좋은게 long term corelation 이 있는 것 아닐까...꼬이고 하니까\n",
    "- Positional encoding 넣으면 확 뛸거 같은디"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyh",
   "language": "python",
   "name": "lyh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 161.997015,
   "end_time": "2020-09-12T05:49:46.470488",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-12T05:47:04.473473",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
