{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:08.823964Z",
     "iopub.status.busy": "2020-09-12T05:47:08.823205Z",
     "iopub.status.idle": "2020-09-12T05:47:15.758339Z",
     "shell.execute_reply": "2020-09-12T05:47:15.757303Z"
    },
    "papermill": {
     "duration": 6.954489,
     "end_time": "2020-09-12T05:47:15.758481",
     "exception": false,
     "start_time": "2020-09-12T05:47:08.803992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01294,
     "end_time": "2020-09-12T05:47:15.784990",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.772050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define helper functions and useful vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.817688Z",
     "iopub.status.busy": "2020-09-12T05:47:15.815907Z",
     "iopub.status.idle": "2020-09-12T05:47:15.818497Z",
     "shell.execute_reply": "2020-09-12T05:47:15.818980Z"
    },
    "papermill": {
     "duration": 0.020522,
     "end_time": "2020-09-12T05:47:15.819094",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.798572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will tell us the columns we are predicting\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.856138Z",
     "iopub.status.busy": "2020-09-12T05:47:15.855349Z",
     "iopub.status.idle": "2020-09-12T05:47:15.859535Z",
     "shell.execute_reply": "2020-09-12T05:47:15.859055Z"
    },
    "papermill": {
     "duration": 0.027513,
     "end_time": "2020-09-12T05:47:15.859623",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.832110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.GRU(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.LSTM(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]   \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "\n",
    "def build_model(gru=False,seq_len=107, pred_len=68, dropout=0.25,\n",
    "                embed_dim=128, hidden_dim=384):\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n",
    "    inputs_bpps = tf.keras.layers.Input(shape=(seq_len, 1))\n",
    "    \n",
    "    pos_encoding = positional_encoding(seq_len, hidden_dim)\n",
    "    \n",
    "\n",
    "    embed0 = tf.keras.layers.Embedding(input_dim=len(token2int0), output_dim=embed_dim)(inputs[:, :, 0])\n",
    "    embed1 = tf.keras.layers.Embedding(input_dim=len(token2int1), output_dim=embed_dim)(inputs[:, :, 1])\n",
    "    embed2 = tf.keras.layers.Embedding(input_dim=len(token2int2), output_dim=embed_dim)(inputs[:, :, 2])\n",
    "    \n",
    "    \n",
    "    embed0 = tf.keras.layers.SpatialDropout1D(.2)(embed0)\n",
    "    embed1 = tf.keras.layers.SpatialDropout1D(.2)(embed1)\n",
    "    embed2 = tf.keras.layers.SpatialDropout1D(.2)(embed2)\n",
    "    \n",
    "    embed = tf.concat([embed0, embed1, embed2], axis=2)\n",
    "    embed += pos_encoding\n",
    "    \n",
    "    #reshaped = tf.reshape(\n",
    "    #    embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n",
    "    \n",
    "    embed = tf.keras.layers.SpatialDropout1D(.2)(embed)\n",
    "    bpps = tf.keras.layers.Dense(embed_dim, activation='linear')(inputs_bpps)\n",
    "    \n",
    "    embed = tf.concat([embed, bpps], axis=2)\n",
    "    \n",
    "    transformer_block = TransformerBlock(512, 8, 512)\n",
    "    embed = transformer_block(embed)\n",
    "    \n",
    "    hidden = gru_layer(hidden_dim, dropout)(embed)\n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "\n",
    "    \n",
    "    #only making predictions on the first part of each sequence\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    \n",
    "    out1 = tf.keras.layers.Dense(5, activation='linear', name='out1')(truncated)\n",
    "    out2 = tf.keras.layers.Dense(5, activation='linear', name='out2')(truncated)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs, inputs_bpps], outputs=[out1, out2])\n",
    "\n",
    "    #some optimizers\n",
    "    adam = tf.optimizers.Adam()\n",
    "    def MCRMSE(y_true, y_pred):\n",
    "        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
    "    \n",
    "    model.compile(optimizer = adam, loss={'out1': MCRMSE, 'out2': 'mae'}, loss_weights={'out1': 0.7, 'out2': 0.3})\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.894673Z",
     "iopub.status.busy": "2020-09-12T05:47:15.893039Z",
     "iopub.status.idle": "2020-09-12T05:47:15.895372Z",
     "shell.execute_reply": "2020-09-12T05:47:15.895926Z"
    },
    "papermill": {
     "duration": 0.023046,
     "end_time": "2020-09-12T05:47:15.896053",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.873007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    return np.transpose(\n",
    "        np.array(\n",
    "            df[cols]\n",
    "            .applymap(lambda seq: [token2int[x] for x in seq])\n",
    "            .values\n",
    "            .tolist()\n",
    "        ),\n",
    "        (0, 2, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013134,
     "end_time": "2020-09-12T05:47:15.922732",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.909598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.957048Z",
     "iopub.status.busy": "2020-09-12T05:47:15.956359Z",
     "iopub.status.idle": "2020-09-12T05:47:16.951033Z",
     "shell.execute_reply": "2020-09-12T05:47:16.950138Z"
    },
    "papermill": {
     "duration": 1.012628,
     "end_time": "2020-09-12T05:47:16.951150",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.938522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('../input//train.json', lines=True)\n",
    "test = pd.read_json('../input//test.json', lines=True)\n",
    "sample_df = pd.read_csv('../input//sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target columns\n",
    "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2int0 = {'G': 0, 'A': 1, 'C': 2, 'U': 3}\n",
    "token2int1 = {'.': 0,  '(': 1, ')': 2}\n",
    "token2int2 = {'E': 0, 'S': 1, 'H': 2, 'B': 3, 'X': 4, 'I': 5, 'M': 6}\n",
    "\n",
    "def convert_seq(x, tmp_dict):\n",
    "    return [tmp_dict[ele] for ele in x]\n",
    "\n",
    "train['sequence'] = train['sequence'].apply(lambda x: [token2int0[ele] for ele in x])\n",
    "train['structure'] = train['structure'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "train['predicted_loop_type'] = train['predicted_loop_type'].apply(lambda x: [token2int2[ele] for ele in x])\n",
    "train_inputs = np.transpose(np.array(train[['sequence', 'structure', 'predicted_loop_type']].values.tolist()), (0, 2, 1))\n",
    "\n",
    "train_inputs = train_inputs[train.signal_to_noise > 1]\n",
    "train_labels = np.array(train[train.signal_to_noise > 1][target_cols].values.tolist()).transpose((0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in train['id']])\n",
    "train_bpps = train_bpps[train.signal_to_noise > 1][:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output\n",
    "    \n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        return config\n",
    "    \n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like(train_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 107, 128)     512         tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 107, 128)     384         tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 107, 128)     896         tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 107, 128)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 107, 128)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 107, 128)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 107, 384)]   0           spatial_dropout1d[0][0]          \n",
      "                                                                 spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 107, 384)]   0           tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 107, 384)     0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 107, 128)     256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_3[0][0]        \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block (TransformerB (None, 107, 512)     1577984     tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 107, 768)     2068992     transformer_block[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 107, 768)     2658816     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 107, 768)     2658816     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 68, 768)]    0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_3[0][0]\n",
      "==================================================================================================\n",
      "Total params: 8,974,346\n",
      "Trainable params: 8,974,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 6s - loss: 0.7140 - out1_loss: 0.7564 - out2_loss: 0.6149 - val_loss: 0.4018 - val_out1_loss: 0.4378 - val_out2_loss: 0.3178\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3931 - out1_loss: 0.4328 - out2_loss: 0.3005 - val_loss: 0.3642 - val_out1_loss: 0.4028 - val_out2_loss: 0.2741\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3585 - out1_loss: 0.3974 - out2_loss: 0.2676 - val_loss: 0.3413 - val_out1_loss: 0.3732 - val_out2_loss: 0.2669\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3407 - out1_loss: 0.3769 - out2_loss: 0.2562 - val_loss: 0.3249 - val_out1_loss: 0.3601 - val_out2_loss: 0.2427\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3283 - out1_loss: 0.3646 - out2_loss: 0.2435 - val_loss: 0.3130 - val_out1_loss: 0.3439 - val_out2_loss: 0.2411\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.3090 - out1_loss: 0.3442 - out2_loss: 0.2269 - val_loss: 0.3029 - val_out1_loss: 0.3362 - val_out2_loss: 0.2252\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.3003 - out1_loss: 0.3350 - out2_loss: 0.2193 - val_loss: 0.2892 - val_out1_loss: 0.3214 - val_out2_loss: 0.2142\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2871 - out1_loss: 0.3203 - out2_loss: 0.2097 - val_loss: 0.2758 - val_out1_loss: 0.3059 - val_out2_loss: 0.2054\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2773 - out1_loss: 0.3093 - out2_loss: 0.2025 - val_loss: 0.2693 - val_out1_loss: 0.2996 - val_out2_loss: 0.1987\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2680 - out1_loss: 0.2986 - out2_loss: 0.1966 - val_loss: 0.2597 - val_out1_loss: 0.2883 - val_out2_loss: 0.1928\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2621 - out1_loss: 0.2919 - out2_loss: 0.1925 - val_loss: 0.2551 - val_out1_loss: 0.2835 - val_out2_loss: 0.1887\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2546 - out1_loss: 0.2833 - out2_loss: 0.1875 - val_loss: 0.2477 - val_out1_loss: 0.2758 - val_out2_loss: 0.1822\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2481 - out1_loss: 0.2762 - out2_loss: 0.1824 - val_loss: 0.2417 - val_out1_loss: 0.2676 - val_out2_loss: 0.1813\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2422 - out1_loss: 0.2691 - out2_loss: 0.1794 - val_loss: 0.2520 - val_out1_loss: 0.2755 - val_out2_loss: 0.1972\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2382 - out1_loss: 0.2642 - out2_loss: 0.1778 - val_loss: 0.2349 - val_out1_loss: 0.2593 - val_out2_loss: 0.1779\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2323 - out1_loss: 0.2578 - out2_loss: 0.1728 - val_loss: 0.2268 - val_out1_loss: 0.2512 - val_out2_loss: 0.1697\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2269 - out1_loss: 0.2518 - out2_loss: 0.1689 - val_loss: 0.2221 - val_out1_loss: 0.2458 - val_out2_loss: 0.1667\n",
      "Epoch 18/120\n",
      "53/53 - 5s - loss: 0.2206 - out1_loss: 0.2449 - out2_loss: 0.1638 - val_loss: 0.2209 - val_out1_loss: 0.2454 - val_out2_loss: 0.1638\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.2175 - out1_loss: 0.2415 - out2_loss: 0.1616 - val_loss: 0.2212 - val_out1_loss: 0.2468 - val_out2_loss: 0.1613\n",
      "Epoch 20/120\n",
      "53/53 - 5s - loss: 0.2135 - out1_loss: 0.2373 - out2_loss: 0.1580 - val_loss: 0.2169 - val_out1_loss: 0.2413 - val_out2_loss: 0.1600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/120\n",
      "53/53 - 5s - loss: 0.2077 - out1_loss: 0.2305 - out2_loss: 0.1546 - val_loss: 0.2126 - val_out1_loss: 0.2355 - val_out2_loss: 0.1591\n",
      "Epoch 22/120\n",
      "53/53 - 5s - loss: 0.2051 - out1_loss: 0.2275 - out2_loss: 0.1528 - val_loss: 0.2118 - val_out1_loss: 0.2353 - val_out2_loss: 0.1570\n",
      "Epoch 23/120\n",
      "53/53 - 5s - loss: 0.2029 - out1_loss: 0.2252 - out2_loss: 0.1510 - val_loss: 0.2110 - val_out1_loss: 0.2342 - val_out2_loss: 0.1568\n",
      "Epoch 24/120\n",
      "53/53 - 5s - loss: 0.1981 - out1_loss: 0.2196 - out2_loss: 0.1479 - val_loss: 0.2131 - val_out1_loss: 0.2362 - val_out2_loss: 0.1591\n",
      "Epoch 25/120\n",
      "53/53 - 5s - loss: 0.1967 - out1_loss: 0.2182 - out2_loss: 0.1464 - val_loss: 0.2072 - val_out1_loss: 0.2302 - val_out2_loss: 0.1535\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1940 - out1_loss: 0.2146 - out2_loss: 0.1457 - val_loss: 0.2098 - val_out1_loss: 0.2314 - val_out2_loss: 0.1595\n",
      "Epoch 27/120\n",
      "53/53 - 5s - loss: 0.1900 - out1_loss: 0.2101 - out2_loss: 0.1428 - val_loss: 0.2049 - val_out1_loss: 0.2262 - val_out2_loss: 0.1550\n",
      "Epoch 28/120\n",
      "53/53 - 5s - loss: 0.1861 - out1_loss: 0.2061 - out2_loss: 0.1396 - val_loss: 0.2042 - val_out1_loss: 0.2273 - val_out2_loss: 0.1502\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1852 - out1_loss: 0.2051 - out2_loss: 0.1387 - val_loss: 0.2159 - val_out1_loss: 0.2383 - val_out2_loss: 0.1634\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1843 - out1_loss: 0.2037 - out2_loss: 0.1389 - val_loss: 0.2039 - val_out1_loss: 0.2262 - val_out2_loss: 0.1519\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1797 - out1_loss: 0.1987 - out2_loss: 0.1352 - val_loss: 0.2044 - val_out1_loss: 0.2259 - val_out2_loss: 0.1541\n",
      "Epoch 32/120\n",
      "53/53 - 5s - loss: 0.1780 - out1_loss: 0.1966 - out2_loss: 0.1345 - val_loss: 0.2029 - val_out1_loss: 0.2251 - val_out2_loss: 0.1512\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1753 - out1_loss: 0.1936 - out2_loss: 0.1326 - val_loss: 0.2034 - val_out1_loss: 0.2253 - val_out2_loss: 0.1523\n",
      "Epoch 34/120\n",
      "53/53 - 5s - loss: 0.1728 - out1_loss: 0.1908 - out2_loss: 0.1309 - val_loss: 0.2016 - val_out1_loss: 0.2242 - val_out2_loss: 0.1488\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1715 - out1_loss: 0.1895 - out2_loss: 0.1295 - val_loss: 0.1985 - val_out1_loss: 0.2205 - val_out2_loss: 0.1470\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1701 - out1_loss: 0.1875 - out2_loss: 0.1296 - val_loss: 0.1994 - val_out1_loss: 0.2216 - val_out2_loss: 0.1475\n",
      "Epoch 37/120\n",
      "53/53 - 5s - loss: 0.1679 - out1_loss: 0.1851 - out2_loss: 0.1277 - val_loss: 0.1978 - val_out1_loss: 0.2200 - val_out2_loss: 0.1462\n",
      "Epoch 38/120\n",
      "53/53 - 5s - loss: 0.1668 - out1_loss: 0.1837 - out2_loss: 0.1274 - val_loss: 0.1996 - val_out1_loss: 0.2207 - val_out2_loss: 0.1501\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1652 - out1_loss: 0.1821 - out2_loss: 0.1255 - val_loss: 0.2001 - val_out1_loss: 0.2223 - val_out2_loss: 0.1482\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1629 - out1_loss: 0.1794 - out2_loss: 0.1245 - val_loss: 0.1976 - val_out1_loss: 0.2191 - val_out2_loss: 0.1474\n",
      "Epoch 41/120\n",
      "53/53 - 5s - loss: 0.1606 - out1_loss: 0.1766 - out2_loss: 0.1233 - val_loss: 0.1968 - val_out1_loss: 0.2185 - val_out2_loss: 0.1461\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1600 - out1_loss: 0.1759 - out2_loss: 0.1231 - val_loss: 0.2000 - val_out1_loss: 0.2225 - val_out2_loss: 0.1474\n",
      "Epoch 43/120\n",
      "53/53 - 5s - loss: 0.1582 - out1_loss: 0.1737 - out2_loss: 0.1218 - val_loss: 0.1967 - val_out1_loss: 0.2175 - val_out2_loss: 0.1482\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1585 - out1_loss: 0.1745 - out2_loss: 0.1210 - val_loss: 0.1989 - val_out1_loss: 0.2216 - val_out2_loss: 0.1459\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1553 - out1_loss: 0.1704 - out2_loss: 0.1201 - val_loss: 0.1986 - val_out1_loss: 0.2207 - val_out2_loss: 0.1469\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1559 - out1_loss: 0.1713 - out2_loss: 0.1201 - val_loss: 0.1979 - val_out1_loss: 0.2194 - val_out2_loss: 0.1477\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1550 - out1_loss: 0.1701 - out2_loss: 0.1196 - val_loss: 0.1975 - val_out1_loss: 0.2183 - val_out2_loss: 0.1490\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1518 - out1_loss: 0.1665 - out2_loss: 0.1174 - val_loss: 0.1969 - val_out1_loss: 0.2177 - val_out2_loss: 0.1483\n",
      "Epoch 49/120\n",
      "53/53 - 5s - loss: 0.1509 - out1_loss: 0.1652 - out2_loss: 0.1175 - val_loss: 0.1956 - val_out1_loss: 0.2173 - val_out2_loss: 0.1450\n",
      "Epoch 50/120\n",
      "53/53 - 5s - loss: 0.1488 - out1_loss: 0.1631 - out2_loss: 0.1156 - val_loss: 0.1988 - val_out1_loss: 0.2197 - val_out2_loss: 0.1500\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1490 - out1_loss: 0.1631 - out2_loss: 0.1160 - val_loss: 0.1977 - val_out1_loss: 0.2195 - val_out2_loss: 0.1467\n",
      "Epoch 52/120\n",
      "53/53 - 5s - loss: 0.1482 - out1_loss: 0.1622 - out2_loss: 0.1154 - val_loss: 0.1945 - val_out1_loss: 0.2159 - val_out2_loss: 0.1447\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1469 - out1_loss: 0.1606 - out2_loss: 0.1149 - val_loss: 0.1959 - val_out1_loss: 0.2167 - val_out2_loss: 0.1472\n",
      "Epoch 54/120\n",
      "53/53 - 5s - loss: 0.1458 - out1_loss: 0.1596 - out2_loss: 0.1136 - val_loss: 0.1934 - val_out1_loss: 0.2150 - val_out2_loss: 0.1430\n",
      "Epoch 55/120\n",
      "53/53 - 5s - loss: 0.1436 - out1_loss: 0.1571 - out2_loss: 0.1120 - val_loss: 0.1960 - val_out1_loss: 0.2180 - val_out2_loss: 0.1446\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1429 - out1_loss: 0.1561 - out2_loss: 0.1119 - val_loss: 0.1944 - val_out1_loss: 0.2155 - val_out2_loss: 0.1451\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1423 - out1_loss: 0.1557 - out2_loss: 0.1112 - val_loss: 0.1938 - val_out1_loss: 0.2150 - val_out2_loss: 0.1442\n",
      "Epoch 58/120\n",
      "53/53 - 5s - loss: 0.1415 - out1_loss: 0.1547 - out2_loss: 0.1106 - val_loss: 0.1951 - val_out1_loss: 0.2169 - val_out2_loss: 0.1442\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1409 - out1_loss: 0.1541 - out2_loss: 0.1100 - val_loss: 0.1944 - val_out1_loss: 0.2160 - val_out2_loss: 0.1441\n",
      "Epoch 60/120\n",
      "53/53 - 5s - loss: 0.1389 - out1_loss: 0.1516 - out2_loss: 0.1092 - val_loss: 0.1948 - val_out1_loss: 0.2163 - val_out2_loss: 0.1447\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1404 - out1_loss: 0.1532 - out2_loss: 0.1105 - val_loss: 0.1980 - val_out1_loss: 0.2196 - val_out2_loss: 0.1475\n",
      "Epoch 62/120\n",
      "53/53 - 5s - loss: 0.1385 - out1_loss: 0.1512 - out2_loss: 0.1086 - val_loss: 0.1966 - val_out1_loss: 0.2177 - val_out2_loss: 0.1473\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1377 - out1_loss: 0.1501 - out2_loss: 0.1085 - val_loss: 0.1950 - val_out1_loss: 0.2163 - val_out2_loss: 0.1454\n",
      "Epoch 64/120\n",
      "53/53 - 5s - loss: 0.1377 - out1_loss: 0.1500 - out2_loss: 0.1090 - val_loss: 0.1952 - val_out1_loss: 0.2163 - val_out2_loss: 0.1461\n",
      "Epoch 65/120\n",
      "53/53 - 5s - loss: 0.1309 - out1_loss: 0.1427 - out2_loss: 0.1034 - val_loss: 0.1918 - val_out1_loss: 0.2132 - val_out2_loss: 0.1418\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1284 - out1_loss: 0.1400 - out2_loss: 0.1014 - val_loss: 0.1913 - val_out1_loss: 0.2127 - val_out2_loss: 0.1415\n",
      "Epoch 67/120\n",
      "53/53 - 5s - loss: 0.1274 - out1_loss: 0.1387 - out2_loss: 0.1008 - val_loss: 0.1908 - val_out1_loss: 0.2122 - val_out2_loss: 0.1410\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1268 - out1_loss: 0.1381 - out2_loss: 0.1003 - val_loss: 0.1908 - val_out1_loss: 0.2121 - val_out2_loss: 0.1410\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.1263 - out1_loss: 0.1375 - out2_loss: 0.1000 - val_loss: 0.1909 - val_out1_loss: 0.2122 - val_out2_loss: 0.1412\n",
      "Epoch 70/120\n",
      "53/53 - 5s - loss: 0.1256 - out1_loss: 0.1367 - out2_loss: 0.0996 - val_loss: 0.1911 - val_out1_loss: 0.2124 - val_out2_loss: 0.1411\n",
      "Epoch 71/120\n",
      "53/53 - 5s - loss: 0.1252 - out1_loss: 0.1363 - out2_loss: 0.0992 - val_loss: 0.1909 - val_out1_loss: 0.2122 - val_out2_loss: 0.1410\n",
      "Epoch 72/120\n",
      "53/53 - 5s - loss: 0.1248 - out1_loss: 0.1358 - out2_loss: 0.0990 - val_loss: 0.1910 - val_out1_loss: 0.2124 - val_out2_loss: 0.1410\n",
      "Epoch 73/120\n",
      "53/53 - 5s - loss: 0.1247 - out1_loss: 0.1357 - out2_loss: 0.0990 - val_loss: 0.1911 - val_out1_loss: 0.2125 - val_out2_loss: 0.1412\n",
      "Epoch 74/120\n",
      "53/53 - 5s - loss: 0.1240 - out1_loss: 0.1349 - out2_loss: 0.0986 - val_loss: 0.1910 - val_out1_loss: 0.2124 - val_out2_loss: 0.1411\n",
      "Epoch 75/120\n",
      "53/53 - 5s - loss: 0.1239 - out1_loss: 0.1348 - out2_loss: 0.0985 - val_loss: 0.1909 - val_out1_loss: 0.2123 - val_out2_loss: 0.1411\n",
      "Epoch 76/120\n",
      "53/53 - 5s - loss: 0.1237 - out1_loss: 0.1346 - out2_loss: 0.0984 - val_loss: 0.1910 - val_out1_loss: 0.2124 - val_out2_loss: 0.1411\n",
      "Epoch 77/120\n",
      "53/53 - 5s - loss: 0.1234 - out1_loss: 0.1342 - out2_loss: 0.0981 - val_loss: 0.1910 - val_out1_loss: 0.2124 - val_out2_loss: 0.1412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/120\n",
      "53/53 - 5s - loss: 0.1229 - out1_loss: 0.1337 - out2_loss: 0.0977 - val_loss: 0.1908 - val_out1_loss: 0.2121 - val_out2_loss: 0.1409\n",
      "Epoch 79/120\n",
      "53/53 - 5s - loss: 0.1228 - out1_loss: 0.1336 - out2_loss: 0.0977 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1409\n",
      "Epoch 80/120\n",
      "53/53 - 5s - loss: 0.1229 - out1_loss: 0.1336 - out2_loss: 0.0978 - val_loss: 0.1908 - val_out1_loss: 0.2121 - val_out2_loss: 0.1409\n",
      "Epoch 81/120\n",
      "53/53 - 5s - loss: 0.1226 - out1_loss: 0.1334 - out2_loss: 0.0976 - val_loss: 0.1907 - val_out1_loss: 0.2120 - val_out2_loss: 0.1408\n",
      "Epoch 82/120\n",
      "53/53 - 5s - loss: 0.1227 - out1_loss: 0.1334 - out2_loss: 0.0977 - val_loss: 0.1908 - val_out1_loss: 0.2122 - val_out2_loss: 0.1409\n",
      "Epoch 83/120\n",
      "53/53 - 5s - loss: 0.1225 - out1_loss: 0.1333 - out2_loss: 0.0975 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1224 - out1_loss: 0.1331 - out2_loss: 0.0975 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1409\n",
      "Epoch 85/120\n",
      "53/53 - 5s - loss: 0.1225 - out1_loss: 0.1333 - out2_loss: 0.0975 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1409\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1226 - out1_loss: 0.1333 - out2_loss: 0.0976 - val_loss: 0.1907 - val_out1_loss: 0.2120 - val_out2_loss: 0.1408\n",
      "Epoch 87/120\n",
      "53/53 - 5s - loss: 0.1224 - out1_loss: 0.1331 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2120 - val_out2_loss: 0.1408\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1224 - out1_loss: 0.1331 - out2_loss: 0.0975 - val_loss: 0.1907 - val_out1_loss: 0.2120 - val_out2_loss: 0.1408\n",
      "Epoch 89/120\n",
      "53/53 - 5s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0974 - val_loss: 0.1908 - val_out1_loss: 0.2121 - val_out2_loss: 0.1409\n",
      "Epoch 90/120\n",
      "53/53 - 5s - loss: 0.1224 - out1_loss: 0.1331 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 92/120\n",
      "53/53 - 5s - loss: 0.1222 - out1_loss: 0.1328 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1222 - out1_loss: 0.1329 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 94/120\n",
      "53/53 - 5s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 95/120\n",
      "53/53 - 5s - loss: 0.1222 - out1_loss: 0.1329 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1223 - out1_loss: 0.1329 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 98/120\n",
      "53/53 - 5s - loss: 0.1222 - out1_loss: 0.1328 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 99/120\n",
      "53/53 - 5s - loss: 0.1224 - out1_loss: 0.1331 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1224 - out1_loss: 0.1331 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1222 - out1_loss: 0.1328 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 102/120\n",
      "53/53 - 5s - loss: 0.1224 - out1_loss: 0.1330 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 103/120\n",
      "53/53 - 5s - loss: 0.1221 - out1_loss: 0.1327 - out2_loss: 0.0972 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 104/120\n",
      "53/53 - 5s - loss: 0.1222 - out1_loss: 0.1329 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 105/120\n",
      "53/53 - 5s - loss: 0.1222 - out1_loss: 0.1329 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 106/120\n",
      "53/53 - 5s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1222 - out1_loss: 0.1330 - out2_loss: 0.0972 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1220 - out1_loss: 0.1327 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1221 - out1_loss: 0.1328 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1222 - out1_loss: 0.1328 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 114/120\n",
      "53/53 - 5s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1223 - out1_loss: 0.1329 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 116/120\n",
      "53/53 - 5s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 117/120\n",
      "53/53 - 5s - loss: 0.1223 - out1_loss: 0.1329 - out2_loss: 0.0975 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 118/120\n",
      "53/53 - 5s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 119/120\n",
      "53/53 - 5s - loss: 0.1221 - out1_loss: 0.1328 - out2_loss: 0.0973 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1223 - out1_loss: 0.1330 - out2_loss: 0.0974 - val_loss: 0.1907 - val_out1_loss: 0.2121 - val_out2_loss: 0.1408\n",
      "#################### 0.3689263863151517\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 107, 128)     512         tf_op_layer_strided_slice_12[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_13[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_14[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 107, 128)     0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 107, 128)     0           embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_14 (SpatialDr (None, 107, 128)     0           embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo [(None, 107, 384)]   0           spatial_dropout1d_12[0][0]       \n",
      "                                                                 spatial_dropout1d_13[0][0]       \n",
      "                                                                 spatial_dropout1d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_3 (TensorFlow [(None, 107, 384)]   0           tf_op_layer_concat_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_15 (SpatialDr (None, 107, 384)     0           tf_op_layer_AddV2_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 107, 128)     256         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_7 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_15[0][0]       \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_3 (Transforme (None, 107, 512)     1577984     tf_op_layer_concat_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 107, 768)     2068992     transformer_block_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 107, 768)     2658816     bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 107, 768)     2658816     bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_15 (T [(None, 68, 768)]    0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_15[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_15[0][0\n",
      "==================================================================================================\n",
      "Total params: 8,974,346\n",
      "Trainable params: 8,974,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 7s - loss: 0.6950 - out1_loss: 0.7698 - out2_loss: 0.5204 - val_loss: 0.4030 - val_out1_loss: 0.4370 - val_out2_loss: 0.3239\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3928 - out1_loss: 0.4316 - out2_loss: 0.3022 - val_loss: 0.3675 - val_out1_loss: 0.4066 - val_out2_loss: 0.2762\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3531 - out1_loss: 0.3922 - out2_loss: 0.2616 - val_loss: 0.3474 - val_out1_loss: 0.3862 - val_out2_loss: 0.2570\n",
      "Epoch 4/120\n",
      "53/53 - 5s - loss: 0.3386 - out1_loss: 0.3751 - out2_loss: 0.2534 - val_loss: 0.3397 - val_out1_loss: 0.3766 - val_out2_loss: 0.2536\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3263 - out1_loss: 0.3628 - out2_loss: 0.2411 - val_loss: 0.3151 - val_out1_loss: 0.3517 - val_out2_loss: 0.2297\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.3112 - out1_loss: 0.3473 - out2_loss: 0.2268 - val_loss: 0.2963 - val_out1_loss: 0.3303 - val_out2_loss: 0.2169\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2973 - out1_loss: 0.3309 - out2_loss: 0.2190 - val_loss: 0.2793 - val_out1_loss: 0.3112 - val_out2_loss: 0.2046\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2834 - out1_loss: 0.3154 - out2_loss: 0.2087 - val_loss: 0.2718 - val_out1_loss: 0.3031 - val_out2_loss: 0.1985\n",
      "Epoch 9/120\n",
      "53/53 - 5s - loss: 0.2751 - out1_loss: 0.3066 - out2_loss: 0.2015 - val_loss: 0.2616 - val_out1_loss: 0.2916 - val_out2_loss: 0.1917\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2668 - out1_loss: 0.2973 - out2_loss: 0.1956 - val_loss: 0.2552 - val_out1_loss: 0.2846 - val_out2_loss: 0.1868\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2598 - out1_loss: 0.2893 - out2_loss: 0.1909 - val_loss: 0.2491 - val_out1_loss: 0.2776 - val_out2_loss: 0.1825\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2552 - out1_loss: 0.2842 - out2_loss: 0.1874 - val_loss: 0.2494 - val_out1_loss: 0.2784 - val_out2_loss: 0.1816\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2490 - out1_loss: 0.2771 - out2_loss: 0.1834 - val_loss: 0.2388 - val_out1_loss: 0.2663 - val_out2_loss: 0.1745\n",
      "Epoch 14/120\n",
      "53/53 - 5s - loss: 0.2459 - out1_loss: 0.2731 - out2_loss: 0.1826 - val_loss: 0.2363 - val_out1_loss: 0.2627 - val_out2_loss: 0.1745\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2364 - out1_loss: 0.2623 - out2_loss: 0.1758 - val_loss: 0.2303 - val_out1_loss: 0.2552 - val_out2_loss: 0.1722\n",
      "Epoch 16/120\n",
      "53/53 - 5s - loss: 0.2320 - out1_loss: 0.2569 - out2_loss: 0.1740 - val_loss: 0.2229 - val_out1_loss: 0.2485 - val_out2_loss: 0.1632\n",
      "Epoch 17/120\n",
      "53/53 - 5s - loss: 0.2242 - out1_loss: 0.2488 - out2_loss: 0.1667 - val_loss: 0.2267 - val_out1_loss: 0.2512 - val_out2_loss: 0.1697\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2201 - out1_loss: 0.2440 - out2_loss: 0.1643 - val_loss: 0.2190 - val_out1_loss: 0.2433 - val_out2_loss: 0.1623\n",
      "Epoch 19/120\n",
      "53/53 - 5s - loss: 0.2169 - out1_loss: 0.2406 - out2_loss: 0.1615 - val_loss: 0.2195 - val_out1_loss: 0.2449 - val_out2_loss: 0.1603\n",
      "Epoch 20/120\n",
      "53/53 - 5s - loss: 0.2137 - out1_loss: 0.2367 - out2_loss: 0.1600 - val_loss: 0.2133 - val_out1_loss: 0.2369 - val_out2_loss: 0.1581\n",
      "Epoch 21/120\n",
      "53/53 - 5s - loss: 0.2084 - out1_loss: 0.2313 - out2_loss: 0.1550 - val_loss: 0.2078 - val_out1_loss: 0.2316 - val_out2_loss: 0.1523\n",
      "Epoch 22/120\n",
      "53/53 - 5s - loss: 0.2042 - out1_loss: 0.2264 - out2_loss: 0.1525 - val_loss: 0.2064 - val_out1_loss: 0.2298 - val_out2_loss: 0.1518\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.2002 - out1_loss: 0.2220 - out2_loss: 0.1494 - val_loss: 0.2069 - val_out1_loss: 0.2288 - val_out2_loss: 0.1557\n",
      "Epoch 24/120\n",
      "53/53 - 5s - loss: 0.1998 - out1_loss: 0.2211 - out2_loss: 0.1502 - val_loss: 0.2088 - val_out1_loss: 0.2317 - val_out2_loss: 0.1555\n",
      "Epoch 25/120\n",
      "53/53 - 5s - loss: 0.1956 - out1_loss: 0.2169 - out2_loss: 0.1459 - val_loss: 0.2090 - val_out1_loss: 0.2324 - val_out2_loss: 0.1545\n",
      "Epoch 26/120\n",
      "53/53 - 5s - loss: 0.1924 - out1_loss: 0.2132 - out2_loss: 0.1439 - val_loss: 0.2037 - val_out1_loss: 0.2255 - val_out2_loss: 0.1527\n",
      "Epoch 27/120\n",
      "53/53 - 5s - loss: 0.1909 - out1_loss: 0.2113 - out2_loss: 0.1431 - val_loss: 0.2023 - val_out1_loss: 0.2248 - val_out2_loss: 0.1497\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1919 - out1_loss: 0.2118 - out2_loss: 0.1456 - val_loss: 0.2036 - val_out1_loss: 0.2258 - val_out2_loss: 0.1517\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1845 - out1_loss: 0.2038 - out2_loss: 0.1394 - val_loss: 0.2027 - val_out1_loss: 0.2250 - val_out2_loss: 0.1507\n",
      "Epoch 30/120\n",
      "53/53 - 5s - loss: 0.1814 - out1_loss: 0.2003 - out2_loss: 0.1374 - val_loss: 0.2023 - val_out1_loss: 0.2245 - val_out2_loss: 0.1506\n",
      "Epoch 31/120\n",
      "53/53 - 5s - loss: 0.1790 - out1_loss: 0.1977 - out2_loss: 0.1354 - val_loss: 0.1986 - val_out1_loss: 0.2210 - val_out2_loss: 0.1461\n",
      "Epoch 32/120\n",
      "53/53 - 5s - loss: 0.1773 - out1_loss: 0.1955 - out2_loss: 0.1349 - val_loss: 0.1966 - val_out1_loss: 0.2189 - val_out2_loss: 0.1445\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1749 - out1_loss: 0.1931 - out2_loss: 0.1325 - val_loss: 0.1982 - val_out1_loss: 0.2211 - val_out2_loss: 0.1450\n",
      "Epoch 34/120\n",
      "53/53 - 5s - loss: 0.1726 - out1_loss: 0.1903 - out2_loss: 0.1315 - val_loss: 0.1955 - val_out1_loss: 0.2176 - val_out2_loss: 0.1438\n",
      "Epoch 35/120\n",
      "53/53 - 5s - loss: 0.1712 - out1_loss: 0.1887 - out2_loss: 0.1305 - val_loss: 0.1962 - val_out1_loss: 0.2181 - val_out2_loss: 0.1450\n",
      "Epoch 36/120\n",
      "53/53 - 5s - loss: 0.1696 - out1_loss: 0.1869 - out2_loss: 0.1292 - val_loss: 0.1942 - val_out1_loss: 0.2161 - val_out2_loss: 0.1432\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1676 - out1_loss: 0.1844 - out2_loss: 0.1284 - val_loss: 0.1958 - val_out1_loss: 0.2176 - val_out2_loss: 0.1450\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1646 - out1_loss: 0.1811 - out2_loss: 0.1261 - val_loss: 0.1939 - val_out1_loss: 0.2155 - val_out2_loss: 0.1435\n",
      "Epoch 39/120\n",
      "53/53 - 5s - loss: 0.1639 - out1_loss: 0.1800 - out2_loss: 0.1264 - val_loss: 0.1960 - val_out1_loss: 0.2180 - val_out2_loss: 0.1445\n",
      "Epoch 40/120\n",
      "53/53 - 5s - loss: 0.1632 - out1_loss: 0.1796 - out2_loss: 0.1252 - val_loss: 0.2028 - val_out1_loss: 0.2253 - val_out2_loss: 0.1502\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1628 - out1_loss: 0.1790 - out2_loss: 0.1252 - val_loss: 0.1986 - val_out1_loss: 0.2203 - val_out2_loss: 0.1479\n",
      "Epoch 42/120\n",
      "53/53 - 5s - loss: 0.1589 - out1_loss: 0.1746 - out2_loss: 0.1224 - val_loss: 0.1945 - val_out1_loss: 0.2162 - val_out2_loss: 0.1440\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1580 - out1_loss: 0.1736 - out2_loss: 0.1217 - val_loss: 0.1959 - val_out1_loss: 0.2174 - val_out2_loss: 0.1456\n",
      "Epoch 44/120\n",
      "53/53 - 5s - loss: 0.1573 - out1_loss: 0.1725 - out2_loss: 0.1217 - val_loss: 0.1935 - val_out1_loss: 0.2155 - val_out2_loss: 0.1423\n",
      "Epoch 45/120\n",
      "53/53 - 5s - loss: 0.1540 - out1_loss: 0.1688 - out2_loss: 0.1195 - val_loss: 0.1956 - val_out1_loss: 0.2178 - val_out2_loss: 0.1439\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1527 - out1_loss: 0.1674 - out2_loss: 0.1184 - val_loss: 0.1940 - val_out1_loss: 0.2158 - val_out2_loss: 0.1431\n",
      "Epoch 47/120\n",
      "53/53 - 5s - loss: 0.1530 - out1_loss: 0.1674 - out2_loss: 0.1192 - val_loss: 0.1923 - val_out1_loss: 0.2139 - val_out2_loss: 0.1420\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1514 - out1_loss: 0.1658 - out2_loss: 0.1177 - val_loss: 0.1946 - val_out1_loss: 0.2170 - val_out2_loss: 0.1425\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1497 - out1_loss: 0.1642 - out2_loss: 0.1158 - val_loss: 0.1924 - val_out1_loss: 0.2145 - val_out2_loss: 0.1406\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1485 - out1_loss: 0.1625 - out2_loss: 0.1159 - val_loss: 0.1933 - val_out1_loss: 0.2154 - val_out2_loss: 0.1417\n",
      "Epoch 51/120\n",
      "53/53 - 5s - loss: 0.1479 - out1_loss: 0.1618 - out2_loss: 0.1154 - val_loss: 0.1943 - val_out1_loss: 0.2150 - val_out2_loss: 0.1461\n",
      "Epoch 52/120\n",
      "53/53 - 5s - loss: 0.1475 - out1_loss: 0.1614 - out2_loss: 0.1153 - val_loss: 0.1924 - val_out1_loss: 0.2143 - val_out2_loss: 0.1412\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1459 - out1_loss: 0.1598 - out2_loss: 0.1135 - val_loss: 0.1927 - val_out1_loss: 0.2147 - val_out2_loss: 0.1413\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1445 - out1_loss: 0.1580 - out2_loss: 0.1129 - val_loss: 0.1942 - val_out1_loss: 0.2162 - val_out2_loss: 0.1427\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1431 - out1_loss: 0.1563 - out2_loss: 0.1122 - val_loss: 0.1934 - val_out1_loss: 0.2150 - val_out2_loss: 0.1428\n",
      "Epoch 56/120\n",
      "53/53 - 5s - loss: 0.1447 - out1_loss: 0.1575 - out2_loss: 0.1148 - val_loss: 0.1932 - val_out1_loss: 0.2143 - val_out2_loss: 0.1442\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1416 - out1_loss: 0.1540 - out2_loss: 0.1125 - val_loss: 0.1949 - val_out1_loss: 0.2176 - val_out2_loss: 0.1419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1358 - out1_loss: 0.1483 - out2_loss: 0.1066 - val_loss: 0.1889 - val_out1_loss: 0.2106 - val_out2_loss: 0.1384\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1329 - out1_loss: 0.1450 - out2_loss: 0.1047 - val_loss: 0.1886 - val_out1_loss: 0.2102 - val_out2_loss: 0.1381\n",
      "Epoch 60/120\n",
      "53/53 - 5s - loss: 0.1320 - out1_loss: 0.1439 - out2_loss: 0.1041 - val_loss: 0.1885 - val_out1_loss: 0.2101 - val_out2_loss: 0.1379\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1312 - out1_loss: 0.1430 - out2_loss: 0.1036 - val_loss: 0.1883 - val_out1_loss: 0.2099 - val_out2_loss: 0.1379\n",
      "Epoch 62/120\n",
      "53/53 - 5s - loss: 0.1306 - out1_loss: 0.1424 - out2_loss: 0.1033 - val_loss: 0.1882 - val_out1_loss: 0.2098 - val_out2_loss: 0.1377\n",
      "Epoch 63/120\n",
      "53/53 - 5s - loss: 0.1302 - out1_loss: 0.1419 - out2_loss: 0.1029 - val_loss: 0.1881 - val_out1_loss: 0.2097 - val_out2_loss: 0.1376\n",
      "Epoch 64/120\n",
      "53/53 - 5s - loss: 0.1298 - out1_loss: 0.1414 - out2_loss: 0.1027 - val_loss: 0.1880 - val_out1_loss: 0.2096 - val_out2_loss: 0.1377\n",
      "Epoch 65/120\n",
      "53/53 - 5s - loss: 0.1295 - out1_loss: 0.1411 - out2_loss: 0.1024 - val_loss: 0.1882 - val_out1_loss: 0.2099 - val_out2_loss: 0.1377\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1291 - out1_loss: 0.1407 - out2_loss: 0.1021 - val_loss: 0.1879 - val_out1_loss: 0.2095 - val_out2_loss: 0.1375\n",
      "Epoch 67/120\n",
      "53/53 - 5s - loss: 0.1288 - out1_loss: 0.1403 - out2_loss: 0.1020 - val_loss: 0.1878 - val_out1_loss: 0.2094 - val_out2_loss: 0.1375\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1285 - out1_loss: 0.1400 - out2_loss: 0.1018 - val_loss: 0.1878 - val_out1_loss: 0.2094 - val_out2_loss: 0.1375\n",
      "Epoch 69/120\n",
      "53/53 - 5s - loss: 0.1283 - out1_loss: 0.1397 - out2_loss: 0.1016 - val_loss: 0.1876 - val_out1_loss: 0.2092 - val_out2_loss: 0.1373\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1281 - out1_loss: 0.1395 - out2_loss: 0.1015 - val_loss: 0.1878 - val_out1_loss: 0.2093 - val_out2_loss: 0.1374\n",
      "Epoch 71/120\n",
      "53/53 - 5s - loss: 0.1277 - out1_loss: 0.1390 - out2_loss: 0.1013 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 72/120\n",
      "53/53 - 5s - loss: 0.1274 - out1_loss: 0.1387 - out2_loss: 0.1010 - val_loss: 0.1877 - val_out1_loss: 0.2093 - val_out2_loss: 0.1374\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1272 - out1_loss: 0.1385 - out2_loss: 0.1009 - val_loss: 0.1876 - val_out1_loss: 0.2092 - val_out2_loss: 0.1371\n",
      "Epoch 74/120\n",
      "53/53 - 5s - loss: 0.1272 - out1_loss: 0.1384 - out2_loss: 0.1009 - val_loss: 0.1879 - val_out1_loss: 0.2095 - val_out2_loss: 0.1373\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1268 - out1_loss: 0.1381 - out2_loss: 0.1007 - val_loss: 0.1877 - val_out1_loss: 0.2093 - val_out2_loss: 0.1373\n",
      "Epoch 76/120\n",
      "53/53 - 5s - loss: 0.1269 - out1_loss: 0.1381 - out2_loss: 0.1007 - val_loss: 0.1879 - val_out1_loss: 0.2095 - val_out2_loss: 0.1375\n",
      "Epoch 77/120\n",
      "53/53 - 5s - loss: 0.1264 - out1_loss: 0.1376 - out2_loss: 0.1003 - val_loss: 0.1877 - val_out1_loss: 0.2094 - val_out2_loss: 0.1373\n",
      "Epoch 78/120\n",
      "53/53 - 5s - loss: 0.1264 - out1_loss: 0.1376 - out2_loss: 0.1004 - val_loss: 0.1877 - val_out1_loss: 0.2093 - val_out2_loss: 0.1373\n",
      "Epoch 79/120\n",
      "53/53 - 5s - loss: 0.1261 - out1_loss: 0.1372 - out2_loss: 0.1003 - val_loss: 0.1879 - val_out1_loss: 0.2096 - val_out2_loss: 0.1374\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0999 - val_loss: 0.1877 - val_out1_loss: 0.2094 - val_out2_loss: 0.1372\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.1000 - val_loss: 0.1878 - val_out1_loss: 0.2094 - val_out2_loss: 0.1374\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1253 - out1_loss: 0.1364 - out2_loss: 0.0996 - val_loss: 0.1875 - val_out1_loss: 0.2091 - val_out2_loss: 0.1371\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1250 - out1_loss: 0.1360 - out2_loss: 0.0995 - val_loss: 0.1875 - val_out1_loss: 0.2091 - val_out2_loss: 0.1371\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1250 - out1_loss: 0.1360 - out2_loss: 0.0993 - val_loss: 0.1875 - val_out1_loss: 0.2091 - val_out2_loss: 0.1371\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.1249 - out1_loss: 0.1359 - out2_loss: 0.0993 - val_loss: 0.1875 - val_out1_loss: 0.2091 - val_out2_loss: 0.1371\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1248 - out1_loss: 0.1357 - out2_loss: 0.0993 - val_loss: 0.1875 - val_out1_loss: 0.2091 - val_out2_loss: 0.1371\n",
      "Epoch 87/120\n",
      "53/53 - 5s - loss: 0.1249 - out1_loss: 0.1359 - out2_loss: 0.0993 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1247 - out1_loss: 0.1357 - out2_loss: 0.0992 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.1249 - out1_loss: 0.1358 - out2_loss: 0.0993 - val_loss: 0.1875 - val_out1_loss: 0.2091 - val_out2_loss: 0.1370\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1248 - out1_loss: 0.1357 - out2_loss: 0.0992 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 91/120\n",
      "53/53 - 5s - loss: 0.1247 - out1_loss: 0.1357 - out2_loss: 0.0992 - val_loss: 0.1875 - val_out1_loss: 0.2091 - val_out2_loss: 0.1371\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.1247 - out1_loss: 0.1356 - out2_loss: 0.0991 - val_loss: 0.1875 - val_out1_loss: 0.2091 - val_out2_loss: 0.1370\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1246 - out1_loss: 0.1355 - out2_loss: 0.0990 - val_loss: 0.1875 - val_out1_loss: 0.2091 - val_out2_loss: 0.1370\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1245 - out1_loss: 0.1355 - out2_loss: 0.0990 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1246 - out1_loss: 0.1355 - out2_loss: 0.0992 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1245 - out1_loss: 0.1354 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 97/120\n",
      "53/53 - 5s - loss: 0.1247 - out1_loss: 0.1356 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1244 - out1_loss: 0.1352 - out2_loss: 0.0990 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 99/120\n",
      "53/53 - 5s - loss: 0.1244 - out1_loss: 0.1353 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1247 - out1_loss: 0.1356 - out2_loss: 0.0992 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 101/120\n",
      "53/53 - 5s - loss: 0.1244 - out1_loss: 0.1353 - out2_loss: 0.0990 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1243 - out1_loss: 0.1351 - out2_loss: 0.0989 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1245 - out1_loss: 0.1354 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 104/120\n",
      "53/53 - 5s - loss: 0.1245 - out1_loss: 0.1354 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1245 - out1_loss: 0.1354 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1246 - out1_loss: 0.1356 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 107/120\n",
      "53/53 - 5s - loss: 0.1246 - out1_loss: 0.1355 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1246 - out1_loss: 0.1355 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 109/120\n",
      "53/53 - 5s - loss: 0.1247 - out1_loss: 0.1355 - out2_loss: 0.0993 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1246 - out1_loss: 0.1355 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1246 - out1_loss: 0.1355 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1245 - out1_loss: 0.1354 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1244 - out1_loss: 0.1353 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 114/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 5s - loss: 0.1246 - out1_loss: 0.1355 - out2_loss: 0.0992 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1244 - out1_loss: 0.1353 - out2_loss: 0.0990 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 116/120\n",
      "53/53 - 5s - loss: 0.1244 - out1_loss: 0.1353 - out2_loss: 0.0990 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1246 - out1_loss: 0.1355 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1246 - out1_loss: 0.1355 - out2_loss: 0.0991 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.1245 - out1_loss: 0.1354 - out2_loss: 0.0990 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1247 - out1_loss: 0.1357 - out2_loss: 0.0990 - val_loss: 0.1874 - val_out1_loss: 0.2090 - val_out2_loss: 0.1370\n",
      "#################### 0.35791143103107187\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_24 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_25 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_26 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 107, 128)     512         tf_op_layer_strided_slice_24[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_25[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_20 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_26[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 107, 128)     0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 107, 128)     0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 107, 128)     0           embedding_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_12 (TensorFl [(None, 107, 384)]   0           spatial_dropout1d_24[0][0]       \n",
      "                                                                 spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_6 (TensorFlow [(None, 107, 384)]   0           tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 107, 384)     0           tf_op_layer_AddV2_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 107, 128)     256         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_13 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_27[0][0]       \n",
      "                                                                 dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_6 (Transforme (None, 107, 512)     1577984     tf_op_layer_concat_13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 107, 768)     2068992     transformer_block_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 107, 768)     2658816     bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 107, 768)     2658816     bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_27 (T [(None, 68, 768)]    0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_27[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_27[0][0\n",
      "==================================================================================================\n",
      "Total params: 8,974,346\n",
      "Trainable params: 8,974,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 6s - loss: 0.6788 - out1_loss: 0.7165 - out2_loss: 0.5908 - val_loss: 0.4100 - val_out1_loss: 0.4484 - val_out2_loss: 0.3204\n",
      "Epoch 2/120\n",
      "53/53 - 5s - loss: 0.3873 - out1_loss: 0.4275 - out2_loss: 0.2937 - val_loss: 0.3811 - val_out1_loss: 0.4221 - val_out2_loss: 0.2854\n",
      "Epoch 3/120\n",
      "53/53 - 5s - loss: 0.3546 - out1_loss: 0.3942 - out2_loss: 0.2623 - val_loss: 0.3430 - val_out1_loss: 0.3835 - val_out2_loss: 0.2487\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3372 - out1_loss: 0.3751 - out2_loss: 0.2489 - val_loss: 0.3342 - val_out1_loss: 0.3724 - val_out2_loss: 0.2451\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3273 - out1_loss: 0.3644 - out2_loss: 0.2407 - val_loss: 0.3096 - val_out1_loss: 0.3455 - val_out2_loss: 0.2257\n",
      "Epoch 6/120\n",
      "53/53 - 5s - loss: 0.3085 - out1_loss: 0.3442 - out2_loss: 0.2252 - val_loss: 0.3021 - val_out1_loss: 0.3363 - val_out2_loss: 0.2224\n",
      "Epoch 7/120\n",
      "53/53 - 5s - loss: 0.2994 - out1_loss: 0.3339 - out2_loss: 0.2189 - val_loss: 0.2907 - val_out1_loss: 0.3248 - val_out2_loss: 0.2111\n",
      "Epoch 8/120\n",
      "53/53 - 5s - loss: 0.2899 - out1_loss: 0.3234 - out2_loss: 0.2118 - val_loss: 0.2794 - val_out1_loss: 0.3135 - val_out2_loss: 0.1998\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2782 - out1_loss: 0.3100 - out2_loss: 0.2039 - val_loss: 0.2828 - val_out1_loss: 0.3131 - val_out2_loss: 0.2122\n",
      "Epoch 10/120\n",
      "53/53 - 5s - loss: 0.2724 - out1_loss: 0.3025 - out2_loss: 0.2024 - val_loss: 0.2613 - val_out1_loss: 0.2902 - val_out2_loss: 0.1937\n",
      "Epoch 11/120\n",
      "53/53 - 5s - loss: 0.2608 - out1_loss: 0.2901 - out2_loss: 0.1924 - val_loss: 0.2567 - val_out1_loss: 0.2850 - val_out2_loss: 0.1905\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2553 - out1_loss: 0.2844 - out2_loss: 0.1873 - val_loss: 0.2546 - val_out1_loss: 0.2824 - val_out2_loss: 0.1899\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2518 - out1_loss: 0.2802 - out2_loss: 0.1854 - val_loss: 0.2469 - val_out1_loss: 0.2732 - val_out2_loss: 0.1853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/120\n",
      "53/53 - 5s - loss: 0.2451 - out1_loss: 0.2725 - out2_loss: 0.1812 - val_loss: 0.2386 - val_out1_loss: 0.2655 - val_out2_loss: 0.1757\n",
      "Epoch 15/120\n",
      "53/53 - 5s - loss: 0.2373 - out1_loss: 0.2635 - out2_loss: 0.1761 - val_loss: 0.2322 - val_out1_loss: 0.2588 - val_out2_loss: 0.1702\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2333 - out1_loss: 0.2586 - out2_loss: 0.1744 - val_loss: 0.2290 - val_out1_loss: 0.2550 - val_out2_loss: 0.1684\n",
      "Epoch 17/120\n",
      "53/53 - 5s - loss: 0.2267 - out1_loss: 0.2516 - out2_loss: 0.1686 - val_loss: 0.2246 - val_out1_loss: 0.2505 - val_out2_loss: 0.1641\n",
      "Epoch 18/120\n",
      "53/53 - 5s - loss: 0.2205 - out1_loss: 0.2447 - out2_loss: 0.1643 - val_loss: 0.2214 - val_out1_loss: 0.2463 - val_out2_loss: 0.1633\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.2160 - out1_loss: 0.2398 - out2_loss: 0.1605 - val_loss: 0.2212 - val_out1_loss: 0.2464 - val_out2_loss: 0.1624\n",
      "Epoch 20/120\n",
      "53/53 - 5s - loss: 0.2130 - out1_loss: 0.2362 - out2_loss: 0.1587 - val_loss: 0.2151 - val_out1_loss: 0.2398 - val_out2_loss: 0.1575\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.2123 - out1_loss: 0.2354 - out2_loss: 0.1585 - val_loss: 0.2198 - val_out1_loss: 0.2433 - val_out2_loss: 0.1650\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.2049 - out1_loss: 0.2270 - out2_loss: 0.1533 - val_loss: 0.2116 - val_out1_loss: 0.2363 - val_out2_loss: 0.1540\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.2016 - out1_loss: 0.2233 - out2_loss: 0.1511 - val_loss: 0.2115 - val_out1_loss: 0.2354 - val_out2_loss: 0.1558\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1993 - out1_loss: 0.2206 - out2_loss: 0.1496 - val_loss: 0.2075 - val_out1_loss: 0.2314 - val_out2_loss: 0.1518\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1965 - out1_loss: 0.2176 - out2_loss: 0.1474 - val_loss: 0.2101 - val_out1_loss: 0.2336 - val_out2_loss: 0.1554\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1936 - out1_loss: 0.2139 - out2_loss: 0.1460 - val_loss: 0.2109 - val_out1_loss: 0.2335 - val_out2_loss: 0.1583\n",
      "Epoch 27/120\n",
      "53/53 - 5s - loss: 0.1900 - out1_loss: 0.2100 - out2_loss: 0.1432 - val_loss: 0.2104 - val_out1_loss: 0.2344 - val_out2_loss: 0.1544\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1888 - out1_loss: 0.2084 - out2_loss: 0.1431 - val_loss: 0.2053 - val_out1_loss: 0.2279 - val_out2_loss: 0.1526\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1834 - out1_loss: 0.2026 - out2_loss: 0.1383 - val_loss: 0.2075 - val_out1_loss: 0.2306 - val_out2_loss: 0.1534\n",
      "Epoch 30/120\n",
      "53/53 - 5s - loss: 0.1840 - out1_loss: 0.2032 - out2_loss: 0.1393 - val_loss: 0.2037 - val_out1_loss: 0.2269 - val_out2_loss: 0.1496\n",
      "Epoch 31/120\n",
      "53/53 - 5s - loss: 0.1779 - out1_loss: 0.1967 - out2_loss: 0.1342 - val_loss: 0.2031 - val_out1_loss: 0.2262 - val_out2_loss: 0.1492\n",
      "Epoch 32/120\n",
      "53/53 - 5s - loss: 0.1762 - out1_loss: 0.1943 - out2_loss: 0.1340 - val_loss: 0.2084 - val_out1_loss: 0.2296 - val_out2_loss: 0.1588\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1766 - out1_loss: 0.1944 - out2_loss: 0.1349 - val_loss: 0.2096 - val_out1_loss: 0.2328 - val_out2_loss: 0.1554\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1752 - out1_loss: 0.1931 - out2_loss: 0.1336 - val_loss: 0.2036 - val_out1_loss: 0.2265 - val_out2_loss: 0.1504\n",
      "Epoch 35/120\n",
      "53/53 - 5s - loss: 0.1699 - out1_loss: 0.1873 - out2_loss: 0.1294 - val_loss: 0.2003 - val_out1_loss: 0.2230 - val_out2_loss: 0.1472\n",
      "Epoch 36/120\n",
      "53/53 - 5s - loss: 0.1689 - out1_loss: 0.1859 - out2_loss: 0.1292 - val_loss: 0.2031 - val_out1_loss: 0.2250 - val_out2_loss: 0.1519\n",
      "Epoch 37/120\n",
      "53/53 - 5s - loss: 0.1680 - out1_loss: 0.1847 - out2_loss: 0.1290 - val_loss: 0.1984 - val_out1_loss: 0.2211 - val_out2_loss: 0.1457\n",
      "Epoch 38/120\n",
      "53/53 - 5s - loss: 0.1647 - out1_loss: 0.1812 - out2_loss: 0.1262 - val_loss: 0.2018 - val_out1_loss: 0.2252 - val_out2_loss: 0.1471\n",
      "Epoch 39/120\n",
      "53/53 - 5s - loss: 0.1631 - out1_loss: 0.1793 - out2_loss: 0.1251 - val_loss: 0.1988 - val_out1_loss: 0.2214 - val_out2_loss: 0.1461\n",
      "Epoch 40/120\n",
      "53/53 - 5s - loss: 0.1607 - out1_loss: 0.1766 - out2_loss: 0.1236 - val_loss: 0.2001 - val_out1_loss: 0.2224 - val_out2_loss: 0.1481\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1596 - out1_loss: 0.1753 - out2_loss: 0.1232 - val_loss: 0.1984 - val_out1_loss: 0.2197 - val_out2_loss: 0.1486\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1588 - out1_loss: 0.1745 - out2_loss: 0.1223 - val_loss: 0.2024 - val_out1_loss: 0.2250 - val_out2_loss: 0.1498\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1564 - out1_loss: 0.1719 - out2_loss: 0.1204 - val_loss: 0.1976 - val_out1_loss: 0.2202 - val_out2_loss: 0.1449\n",
      "Epoch 44/120\n",
      "53/53 - 5s - loss: 0.1556 - out1_loss: 0.1707 - out2_loss: 0.1202 - val_loss: 0.2011 - val_out1_loss: 0.2224 - val_out2_loss: 0.1515\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1551 - out1_loss: 0.1700 - out2_loss: 0.1203 - val_loss: 0.1968 - val_out1_loss: 0.2190 - val_out2_loss: 0.1450\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1526 - out1_loss: 0.1674 - out2_loss: 0.1181 - val_loss: 0.1971 - val_out1_loss: 0.2196 - val_out2_loss: 0.1446\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1515 - out1_loss: 0.1660 - out2_loss: 0.1175 - val_loss: 0.1972 - val_out1_loss: 0.2194 - val_out2_loss: 0.1453\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1505 - out1_loss: 0.1650 - out2_loss: 0.1167 - val_loss: 0.1975 - val_out1_loss: 0.2199 - val_out2_loss: 0.1454\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1509 - out1_loss: 0.1652 - out2_loss: 0.1175 - val_loss: 0.1973 - val_out1_loss: 0.2196 - val_out2_loss: 0.1454\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1488 - out1_loss: 0.1629 - out2_loss: 0.1159 - val_loss: 0.1982 - val_out1_loss: 0.2204 - val_out2_loss: 0.1464\n",
      "Epoch 51/120\n",
      "53/53 - 5s - loss: 0.1482 - out1_loss: 0.1622 - out2_loss: 0.1156 - val_loss: 0.1988 - val_out1_loss: 0.2216 - val_out2_loss: 0.1455\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1463 - out1_loss: 0.1602 - out2_loss: 0.1140 - val_loss: 0.1982 - val_out1_loss: 0.2207 - val_out2_loss: 0.1459\n",
      "Epoch 53/120\n",
      "53/53 - 5s - loss: 0.1453 - out1_loss: 0.1590 - out2_loss: 0.1134 - val_loss: 0.1980 - val_out1_loss: 0.2208 - val_out2_loss: 0.1449\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1437 - out1_loss: 0.1572 - out2_loss: 0.1121 - val_loss: 0.1989 - val_out1_loss: 0.2211 - val_out2_loss: 0.1469\n",
      "Epoch 55/120\n",
      "53/53 - 5s - loss: 0.1441 - out1_loss: 0.1573 - out2_loss: 0.1131 - val_loss: 0.1978 - val_out1_loss: 0.2207 - val_out2_loss: 0.1444\n",
      "Epoch 56/120\n",
      "53/53 - 5s - loss: 0.1376 - out1_loss: 0.1504 - out2_loss: 0.1076 - val_loss: 0.1940 - val_out1_loss: 0.2165 - val_out2_loss: 0.1417\n",
      "Epoch 57/120\n",
      "53/53 - 5s - loss: 0.1345 - out1_loss: 0.1469 - out2_loss: 0.1056 - val_loss: 0.1937 - val_out1_loss: 0.2161 - val_out2_loss: 0.1414\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1338 - out1_loss: 0.1461 - out2_loss: 0.1051 - val_loss: 0.1935 - val_out1_loss: 0.2159 - val_out2_loss: 0.1413\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1330 - out1_loss: 0.1451 - out2_loss: 0.1046 - val_loss: 0.1932 - val_out1_loss: 0.2155 - val_out2_loss: 0.1410\n",
      "Epoch 60/120\n",
      "53/53 - 5s - loss: 0.1323 - out1_loss: 0.1444 - out2_loss: 0.1041 - val_loss: 0.1935 - val_out1_loss: 0.2158 - val_out2_loss: 0.1413\n",
      "Epoch 61/120\n",
      "53/53 - 5s - loss: 0.1320 - out1_loss: 0.1440 - out2_loss: 0.1040 - val_loss: 0.1933 - val_out1_loss: 0.2157 - val_out2_loss: 0.1411\n",
      "Epoch 62/120\n",
      "53/53 - 5s - loss: 0.1314 - out1_loss: 0.1434 - out2_loss: 0.1037 - val_loss: 0.1930 - val_out1_loss: 0.2154 - val_out2_loss: 0.1410\n",
      "Epoch 63/120\n",
      "53/53 - 5s - loss: 0.1309 - out1_loss: 0.1428 - out2_loss: 0.1033 - val_loss: 0.1933 - val_out1_loss: 0.2156 - val_out2_loss: 0.1411\n",
      "Epoch 64/120\n",
      "53/53 - 5s - loss: 0.1308 - out1_loss: 0.1426 - out2_loss: 0.1032 - val_loss: 0.1934 - val_out1_loss: 0.2158 - val_out2_loss: 0.1411\n",
      "Epoch 65/120\n",
      "53/53 - 5s - loss: 0.1303 - out1_loss: 0.1421 - out2_loss: 0.1030 - val_loss: 0.1933 - val_out1_loss: 0.2157 - val_out2_loss: 0.1411\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1301 - out1_loss: 0.1418 - out2_loss: 0.1028 - val_loss: 0.1933 - val_out1_loss: 0.2156 - val_out2_loss: 0.1411\n",
      "Epoch 67/120\n",
      "53/53 - 5s - loss: 0.1301 - out1_loss: 0.1418 - out2_loss: 0.1027 - val_loss: 0.1932 - val_out1_loss: 0.2156 - val_out2_loss: 0.1410\n",
      "Epoch 68/120\n",
      "53/53 - 5s - loss: 0.1298 - out1_loss: 0.1415 - out2_loss: 0.1025 - val_loss: 0.1931 - val_out1_loss: 0.2155 - val_out2_loss: 0.1410\n",
      "Epoch 69/120\n",
      "53/53 - 5s - loss: 0.1296 - out1_loss: 0.1412 - out2_loss: 0.1024 - val_loss: 0.1929 - val_out1_loss: 0.2153 - val_out2_loss: 0.1408\n",
      "Epoch 70/120\n",
      "53/53 - 5s - loss: 0.1292 - out1_loss: 0.1409 - out2_loss: 0.1021 - val_loss: 0.1931 - val_out1_loss: 0.2154 - val_out2_loss: 0.1409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/120\n",
      "53/53 - 5s - loss: 0.1292 - out1_loss: 0.1408 - out2_loss: 0.1021 - val_loss: 0.1928 - val_out1_loss: 0.2151 - val_out2_loss: 0.1407\n",
      "Epoch 72/120\n",
      "53/53 - 5s - loss: 0.1289 - out1_loss: 0.1404 - out2_loss: 0.1019 - val_loss: 0.1930 - val_out1_loss: 0.2154 - val_out2_loss: 0.1409\n",
      "Epoch 73/120\n",
      "53/53 - 5s - loss: 0.1285 - out1_loss: 0.1400 - out2_loss: 0.1018 - val_loss: 0.1931 - val_out1_loss: 0.2154 - val_out2_loss: 0.1410\n",
      "Epoch 74/120\n",
      "53/53 - 5s - loss: 0.1285 - out1_loss: 0.1400 - out2_loss: 0.1016 - val_loss: 0.1930 - val_out1_loss: 0.2154 - val_out2_loss: 0.1408\n",
      "Epoch 75/120\n",
      "53/53 - 5s - loss: 0.1282 - out1_loss: 0.1396 - out2_loss: 0.1015 - val_loss: 0.1929 - val_out1_loss: 0.2152 - val_out2_loss: 0.1407\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1279 - out1_loss: 0.1393 - out2_loss: 0.1013 - val_loss: 0.1930 - val_out1_loss: 0.2153 - val_out2_loss: 0.1409\n",
      "Epoch 77/120\n",
      "53/53 - 5s - loss: 0.1278 - out1_loss: 0.1392 - out2_loss: 0.1012 - val_loss: 0.1927 - val_out1_loss: 0.2150 - val_out2_loss: 0.1407\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1275 - out1_loss: 0.1389 - out2_loss: 0.1010 - val_loss: 0.1928 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1272 - out1_loss: 0.1385 - out2_loss: 0.1008 - val_loss: 0.1929 - val_out1_loss: 0.2152 - val_out2_loss: 0.1408\n",
      "Epoch 80/120\n",
      "53/53 - 5s - loss: 0.1272 - out1_loss: 0.1385 - out2_loss: 0.1008 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 81/120\n",
      "53/53 - 5s - loss: 0.1270 - out1_loss: 0.1382 - out2_loss: 0.1007 - val_loss: 0.1931 - val_out1_loss: 0.2154 - val_out2_loss: 0.1411\n",
      "Epoch 82/120\n",
      "53/53 - 5s - loss: 0.1266 - out1_loss: 0.1378 - out2_loss: 0.1004 - val_loss: 0.1928 - val_out1_loss: 0.2152 - val_out2_loss: 0.1406\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1262 - out1_loss: 0.1375 - out2_loss: 0.1001 - val_loss: 0.1928 - val_out1_loss: 0.2152 - val_out2_loss: 0.1406\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1263 - out1_loss: 0.1375 - out2_loss: 0.1002 - val_loss: 0.1928 - val_out1_loss: 0.2152 - val_out2_loss: 0.1406\n",
      "Epoch 85/120\n",
      "53/53 - 5s - loss: 0.1260 - out1_loss: 0.1371 - out2_loss: 0.1001 - val_loss: 0.1928 - val_out1_loss: 0.2152 - val_out2_loss: 0.1406\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1263 - out1_loss: 0.1375 - out2_loss: 0.1001 - val_loss: 0.1928 - val_out1_loss: 0.2152 - val_out2_loss: 0.1406\n",
      "Epoch 87/120\n",
      "53/53 - 5s - loss: 0.1260 - out1_loss: 0.1372 - out2_loss: 0.1000 - val_loss: 0.1928 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1260 - out1_loss: 0.1372 - out2_loss: 0.1000 - val_loss: 0.1928 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 89/120\n",
      "53/53 - 5s - loss: 0.1259 - out1_loss: 0.1370 - out2_loss: 0.0999 - val_loss: 0.1928 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 90/120\n",
      "53/53 - 5s - loss: 0.1260 - out1_loss: 0.1371 - out2_loss: 0.0999 - val_loss: 0.1928 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.1260 - out1_loss: 0.1372 - out2_loss: 0.1000 - val_loss: 0.1928 - val_out1_loss: 0.2151 - val_out2_loss: 0.1407\n",
      "Epoch 92/120\n",
      "53/53 - 5s - loss: 0.1259 - out1_loss: 0.1371 - out2_loss: 0.0999 - val_loss: 0.1928 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1259 - out1_loss: 0.1371 - out2_loss: 0.0999 - val_loss: 0.1928 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 94/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1259 - out1_loss: 0.1371 - out2_loss: 0.0998 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 96/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0998 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 97/120\n",
      "53/53 - 5s - loss: 0.1259 - out1_loss: 0.1370 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1260 - out1_loss: 0.1371 - out2_loss: 0.1000 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 99/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1370 - out2_loss: 0.0998 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1257 - out1_loss: 0.1368 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1259 - out1_loss: 0.1371 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 103/120\n",
      "53/53 - 5s - loss: 0.1259 - out1_loss: 0.1371 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1256 - out1_loss: 0.1367 - out2_loss: 0.0998 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1257 - out1_loss: 0.1369 - out2_loss: 0.0998 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0998 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 108/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.1000 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 109/120\n",
      "53/53 - 5s - loss: 0.1260 - out1_loss: 0.1371 - out2_loss: 0.1000 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1257 - out1_loss: 0.1368 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 111/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0998 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1257 - out1_loss: 0.1368 - out2_loss: 0.0998 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 113/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 114/120\n",
      "53/53 - 5s - loss: 0.1260 - out1_loss: 0.1371 - out2_loss: 0.1000 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0998 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 116/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 117/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 118/120\n",
      "53/53 - 5s - loss: 0.1257 - out1_loss: 0.1369 - out2_loss: 0.0998 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.1259 - out1_loss: 0.1370 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1258 - out1_loss: 0.1370 - out2_loss: 0.0999 - val_loss: 0.1927 - val_out1_loss: 0.2151 - val_out2_loss: 0.1406\n",
      "#################### 0.3731882206998958\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_36 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_37 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_38 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 107, 128)     512         tf_op_layer_strided_slice_36[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_28 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_37[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_29 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_38[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_36 (SpatialDr (None, 107, 128)     0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_37 (SpatialDr (None, 107, 128)     0           embedding_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_38 (SpatialDr (None, 107, 128)     0           embedding_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_18 (TensorFl [(None, 107, 384)]   0           spatial_dropout1d_36[0][0]       \n",
      "                                                                 spatial_dropout1d_37[0][0]       \n",
      "                                                                 spatial_dropout1d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_9 (TensorFlow [(None, 107, 384)]   0           tf_op_layer_concat_18[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_39 (SpatialDr (None, 107, 384)     0           tf_op_layer_AddV2_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 107, 128)     256         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_19 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_39[0][0]       \n",
      "                                                                 dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_9 (Transforme (None, 107, 512)     1577984     tf_op_layer_concat_19[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_27 (Bidirectional (None, 107, 768)     2068992     transformer_block_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_28 (Bidirectional (None, 107, 768)     2658816     bidirectional_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_29 (Bidirectional (None, 107, 768)     2658816     bidirectional_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_39 (T [(None, 68, 768)]    0           bidirectional_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_39[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_39[0][0\n",
      "==================================================================================================\n",
      "Total params: 8,974,346\n",
      "Trainable params: 8,974,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 7s - loss: 0.6916 - out1_loss: 0.7423 - out2_loss: 0.5734 - val_loss: 0.3996 - val_out1_loss: 0.4358 - val_out2_loss: 0.3150\n",
      "Epoch 2/120\n",
      "53/53 - 5s - loss: 0.3838 - out1_loss: 0.4239 - out2_loss: 0.2903 - val_loss: 0.3566 - val_out1_loss: 0.3972 - val_out2_loss: 0.2619\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3508 - out1_loss: 0.3896 - out2_loss: 0.2603 - val_loss: 0.3502 - val_out1_loss: 0.3908 - val_out2_loss: 0.2555\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3352 - out1_loss: 0.3720 - out2_loss: 0.2495 - val_loss: 0.3250 - val_out1_loss: 0.3617 - val_out2_loss: 0.2394\n",
      "Epoch 5/120\n",
      "53/53 - 5s - loss: 0.3228 - out1_loss: 0.3590 - out2_loss: 0.2385 - val_loss: 0.3240 - val_out1_loss: 0.3572 - val_out2_loss: 0.2467\n",
      "Epoch 6/120\n",
      "53/53 - 5s - loss: 0.3066 - out1_loss: 0.3420 - out2_loss: 0.2241 - val_loss: 0.3017 - val_out1_loss: 0.3404 - val_out2_loss: 0.2113\n",
      "Epoch 7/120\n",
      "53/53 - 5s - loss: 0.2958 - out1_loss: 0.3298 - out2_loss: 0.2164 - val_loss: 0.2862 - val_out1_loss: 0.3200 - val_out2_loss: 0.2073\n",
      "Epoch 8/120\n",
      "53/53 - 5s - loss: 0.2830 - out1_loss: 0.3151 - out2_loss: 0.2081 - val_loss: 0.2711 - val_out1_loss: 0.3029 - val_out2_loss: 0.1969\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2727 - out1_loss: 0.3028 - out2_loss: 0.2024 - val_loss: 0.2707 - val_out1_loss: 0.2995 - val_out2_loss: 0.2034\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2650 - out1_loss: 0.2946 - out2_loss: 0.1959 - val_loss: 0.2618 - val_out1_loss: 0.2929 - val_out2_loss: 0.1893\n",
      "Epoch 11/120\n",
      "53/53 - 5s - loss: 0.2583 - out1_loss: 0.2871 - out2_loss: 0.1911 - val_loss: 0.2608 - val_out1_loss: 0.2916 - val_out2_loss: 0.1889\n",
      "Epoch 12/120\n",
      "53/53 - 5s - loss: 0.2528 - out1_loss: 0.2812 - out2_loss: 0.1866 - val_loss: 0.2480 - val_out1_loss: 0.2769 - val_out2_loss: 0.1805\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2484 - out1_loss: 0.2758 - out2_loss: 0.1844 - val_loss: 0.2441 - val_out1_loss: 0.2709 - val_out2_loss: 0.1817\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2392 - out1_loss: 0.2654 - out2_loss: 0.1782 - val_loss: 0.2373 - val_out1_loss: 0.2641 - val_out2_loss: 0.1748\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2345 - out1_loss: 0.2597 - out2_loss: 0.1755 - val_loss: 0.2360 - val_out1_loss: 0.2622 - val_out2_loss: 0.1748\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2283 - out1_loss: 0.2533 - out2_loss: 0.1701 - val_loss: 0.2331 - val_out1_loss: 0.2604 - val_out2_loss: 0.1695\n",
      "Epoch 17/120\n",
      "53/53 - 5s - loss: 0.2254 - out1_loss: 0.2499 - out2_loss: 0.1682 - val_loss: 0.2260 - val_out1_loss: 0.2525 - val_out2_loss: 0.1643\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2178 - out1_loss: 0.2415 - out2_loss: 0.1624 - val_loss: 0.2228 - val_out1_loss: 0.2486 - val_out2_loss: 0.1625\n",
      "Epoch 19/120\n",
      "53/53 - 5s - loss: 0.2159 - out1_loss: 0.2396 - out2_loss: 0.1606 - val_loss: 0.2192 - val_out1_loss: 0.2445 - val_out2_loss: 0.1602\n",
      "Epoch 20/120\n",
      "53/53 - 5s - loss: 0.2106 - out1_loss: 0.2335 - out2_loss: 0.1572 - val_loss: 0.2218 - val_out1_loss: 0.2466 - val_out2_loss: 0.1641\n",
      "Epoch 21/120\n",
      "53/53 - 5s - loss: 0.2060 - out1_loss: 0.2285 - out2_loss: 0.1536 - val_loss: 0.2129 - val_out1_loss: 0.2373 - val_out2_loss: 0.1558\n",
      "Epoch 22/120\n",
      "53/53 - 5s - loss: 0.2034 - out1_loss: 0.2255 - out2_loss: 0.1519 - val_loss: 0.2118 - val_out1_loss: 0.2363 - val_out2_loss: 0.1545\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1997 - out1_loss: 0.2212 - out2_loss: 0.1495 - val_loss: 0.2090 - val_out1_loss: 0.2334 - val_out2_loss: 0.1519\n",
      "Epoch 24/120\n",
      "53/53 - 5s - loss: 0.2006 - out1_loss: 0.2220 - out2_loss: 0.1504 - val_loss: 0.2129 - val_out1_loss: 0.2374 - val_out2_loss: 0.1556\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1965 - out1_loss: 0.2172 - out2_loss: 0.1482 - val_loss: 0.2086 - val_out1_loss: 0.2329 - val_out2_loss: 0.1520\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1901 - out1_loss: 0.2102 - out2_loss: 0.1430 - val_loss: 0.2142 - val_out1_loss: 0.2381 - val_out2_loss: 0.1583\n",
      "Epoch 27/120\n",
      "53/53 - 5s - loss: 0.1909 - out1_loss: 0.2107 - out2_loss: 0.1446 - val_loss: 0.2096 - val_out1_loss: 0.2335 - val_out2_loss: 0.1536\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1885 - out1_loss: 0.2082 - out2_loss: 0.1425 - val_loss: 0.2077 - val_out1_loss: 0.2306 - val_out2_loss: 0.1544\n",
      "Epoch 29/120\n",
      "53/53 - 5s - loss: 0.1839 - out1_loss: 0.2031 - out2_loss: 0.1392 - val_loss: 0.2050 - val_out1_loss: 0.2287 - val_out2_loss: 0.1499\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1801 - out1_loss: 0.1989 - out2_loss: 0.1364 - val_loss: 0.2063 - val_out1_loss: 0.2295 - val_out2_loss: 0.1523\n",
      "Epoch 31/120\n",
      "53/53 - 5s - loss: 0.1779 - out1_loss: 0.1962 - out2_loss: 0.1350 - val_loss: 0.2058 - val_out1_loss: 0.2303 - val_out2_loss: 0.1486\n",
      "Epoch 32/120\n",
      "53/53 - 5s - loss: 0.1749 - out1_loss: 0.1931 - out2_loss: 0.1324 - val_loss: 0.2025 - val_out1_loss: 0.2263 - val_out2_loss: 0.1470\n",
      "Epoch 33/120\n",
      "53/53 - 5s - loss: 0.1730 - out1_loss: 0.1908 - out2_loss: 0.1315 - val_loss: 0.2020 - val_out1_loss: 0.2252 - val_out2_loss: 0.1478\n",
      "Epoch 34/120\n",
      "53/53 - 5s - loss: 0.1716 - out1_loss: 0.1891 - out2_loss: 0.1307 - val_loss: 0.2028 - val_out1_loss: 0.2262 - val_out2_loss: 0.1479\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1701 - out1_loss: 0.1875 - out2_loss: 0.1297 - val_loss: 0.2051 - val_out1_loss: 0.2275 - val_out2_loss: 0.1527\n",
      "Epoch 36/120\n",
      "53/53 - 5s - loss: 0.1687 - out1_loss: 0.1854 - out2_loss: 0.1297 - val_loss: 0.2007 - val_out1_loss: 0.2236 - val_out2_loss: 0.1473\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1666 - out1_loss: 0.1831 - out2_loss: 0.1280 - val_loss: 0.2012 - val_out1_loss: 0.2243 - val_out2_loss: 0.1474\n",
      "Epoch 38/120\n",
      "53/53 - 5s - loss: 0.1641 - out1_loss: 0.1806 - out2_loss: 0.1255 - val_loss: 0.2000 - val_out1_loss: 0.2231 - val_out2_loss: 0.1461\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1620 - out1_loss: 0.1782 - out2_loss: 0.1241 - val_loss: 0.1981 - val_out1_loss: 0.2214 - val_out2_loss: 0.1439\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1615 - out1_loss: 0.1774 - out2_loss: 0.1243 - val_loss: 0.2015 - val_out1_loss: 0.2243 - val_out2_loss: 0.1482\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1609 - out1_loss: 0.1764 - out2_loss: 0.1248 - val_loss: 0.2000 - val_out1_loss: 0.2222 - val_out2_loss: 0.1481\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1641 - out1_loss: 0.1802 - out2_loss: 0.1265 - val_loss: 0.2025 - val_out1_loss: 0.2249 - val_out2_loss: 0.1502\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1573 - out1_loss: 0.1723 - out2_loss: 0.1223 - val_loss: 0.1982 - val_out1_loss: 0.2214 - val_out2_loss: 0.1440\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1558 - out1_loss: 0.1709 - out2_loss: 0.1207 - val_loss: 0.1989 - val_out1_loss: 0.2224 - val_out2_loss: 0.1440\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1541 - out1_loss: 0.1689 - out2_loss: 0.1194 - val_loss: 0.1992 - val_out1_loss: 0.2213 - val_out2_loss: 0.1475\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1524 - out1_loss: 0.1669 - out2_loss: 0.1184 - val_loss: 0.1987 - val_out1_loss: 0.2224 - val_out2_loss: 0.1435\n",
      "Epoch 47/120\n",
      "53/53 - 5s - loss: 0.1503 - out1_loss: 0.1647 - out2_loss: 0.1166 - val_loss: 0.1997 - val_out1_loss: 0.2226 - val_out2_loss: 0.1461\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1497 - out1_loss: 0.1642 - out2_loss: 0.1159 - val_loss: 0.1991 - val_out1_loss: 0.2222 - val_out2_loss: 0.1453\n",
      "Epoch 49/120\n",
      "53/53 - 5s - loss: 0.1491 - out1_loss: 0.1634 - out2_loss: 0.1157 - val_loss: 0.1973 - val_out1_loss: 0.2202 - val_out2_loss: 0.1438\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1489 - out1_loss: 0.1628 - out2_loss: 0.1163 - val_loss: 0.1970 - val_out1_loss: 0.2199 - val_out2_loss: 0.1435\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1486 - out1_loss: 0.1626 - out2_loss: 0.1160 - val_loss: 0.2003 - val_out1_loss: 0.2247 - val_out2_loss: 0.1435\n",
      "Epoch 52/120\n",
      "53/53 - 5s - loss: 0.1463 - out1_loss: 0.1600 - out2_loss: 0.1143 - val_loss: 0.1989 - val_out1_loss: 0.2223 - val_out2_loss: 0.1441\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1471 - out1_loss: 0.1609 - out2_loss: 0.1148 - val_loss: 0.1967 - val_out1_loss: 0.2196 - val_out2_loss: 0.1434\n",
      "Epoch 54/120\n",
      "53/53 - 5s - loss: 0.1451 - out1_loss: 0.1585 - out2_loss: 0.1139 - val_loss: 0.1960 - val_out1_loss: 0.2189 - val_out2_loss: 0.1426\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1424 - out1_loss: 0.1558 - out2_loss: 0.1111 - val_loss: 0.1966 - val_out1_loss: 0.2198 - val_out2_loss: 0.1424\n",
      "Epoch 56/120\n",
      "53/53 - 5s - loss: 0.1415 - out1_loss: 0.1547 - out2_loss: 0.1106 - val_loss: 0.1967 - val_out1_loss: 0.2199 - val_out2_loss: 0.1427\n",
      "Epoch 57/120\n",
      "53/53 - 5s - loss: 0.1409 - out1_loss: 0.1539 - out2_loss: 0.1107 - val_loss: 0.1976 - val_out1_loss: 0.2206 - val_out2_loss: 0.1440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1411 - out1_loss: 0.1540 - out2_loss: 0.1111 - val_loss: 0.1968 - val_out1_loss: 0.2202 - val_out2_loss: 0.1422\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1395 - out1_loss: 0.1525 - out2_loss: 0.1094 - val_loss: 0.1966 - val_out1_loss: 0.2199 - val_out2_loss: 0.1422\n",
      "Epoch 60/120\n",
      "53/53 - 5s - loss: 0.1397 - out1_loss: 0.1522 - out2_loss: 0.1104 - val_loss: 0.1967 - val_out1_loss: 0.2198 - val_out2_loss: 0.1429\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1391 - out1_loss: 0.1514 - out2_loss: 0.1106 - val_loss: 0.2014 - val_out1_loss: 0.2252 - val_out2_loss: 0.1457\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1378 - out1_loss: 0.1505 - out2_loss: 0.1083 - val_loss: 0.1974 - val_out1_loss: 0.2204 - val_out2_loss: 0.1438\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1369 - out1_loss: 0.1493 - out2_loss: 0.1079 - val_loss: 0.1969 - val_out1_loss: 0.2200 - val_out2_loss: 0.1431\n",
      "Epoch 64/120\n",
      "53/53 - 5s - loss: 0.1357 - out1_loss: 0.1480 - out2_loss: 0.1070 - val_loss: 0.1969 - val_out1_loss: 0.2199 - val_out2_loss: 0.1432\n",
      "Epoch 65/120\n",
      "53/53 - 5s - loss: 0.1302 - out1_loss: 0.1418 - out2_loss: 0.1031 - val_loss: 0.1939 - val_out1_loss: 0.2169 - val_out2_loss: 0.1401\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1275 - out1_loss: 0.1388 - out2_loss: 0.1011 - val_loss: 0.1935 - val_out1_loss: 0.2164 - val_out2_loss: 0.1399\n",
      "Epoch 67/120\n",
      "53/53 - 5s - loss: 0.1265 - out1_loss: 0.1376 - out2_loss: 0.1005 - val_loss: 0.1936 - val_out1_loss: 0.2166 - val_out2_loss: 0.1399\n",
      "Epoch 68/120\n",
      "53/53 - 5s - loss: 0.1258 - out1_loss: 0.1369 - out2_loss: 0.1000 - val_loss: 0.1933 - val_out1_loss: 0.2162 - val_out2_loss: 0.1397\n",
      "Epoch 69/120\n",
      "53/53 - 5s - loss: 0.1251 - out1_loss: 0.1361 - out2_loss: 0.0995 - val_loss: 0.1933 - val_out1_loss: 0.2163 - val_out2_loss: 0.1397\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1247 - out1_loss: 0.1356 - out2_loss: 0.0993 - val_loss: 0.1932 - val_out1_loss: 0.2162 - val_out2_loss: 0.1396\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1243 - out1_loss: 0.1351 - out2_loss: 0.0990 - val_loss: 0.1933 - val_out1_loss: 0.2162 - val_out2_loss: 0.1399\n",
      "Epoch 72/120\n",
      "53/53 - 5s - loss: 0.1240 - out1_loss: 0.1349 - out2_loss: 0.0988 - val_loss: 0.1932 - val_out1_loss: 0.2161 - val_out2_loss: 0.1396\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1237 - out1_loss: 0.1345 - out2_loss: 0.0986 - val_loss: 0.1932 - val_out1_loss: 0.2162 - val_out2_loss: 0.1396\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1235 - out1_loss: 0.1342 - out2_loss: 0.0985 - val_loss: 0.1929 - val_out1_loss: 0.2158 - val_out2_loss: 0.1394\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1232 - out1_loss: 0.1339 - out2_loss: 0.0983 - val_loss: 0.1931 - val_out1_loss: 0.2161 - val_out2_loss: 0.1396\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1230 - out1_loss: 0.1337 - out2_loss: 0.0980 - val_loss: 0.1933 - val_out1_loss: 0.2163 - val_out2_loss: 0.1397\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1229 - out1_loss: 0.1336 - out2_loss: 0.0980 - val_loss: 0.1929 - val_out1_loss: 0.2158 - val_out2_loss: 0.1396\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1224 - out1_loss: 0.1330 - out2_loss: 0.0978 - val_loss: 0.1930 - val_out1_loss: 0.2160 - val_out2_loss: 0.1394\n",
      "Epoch 79/120\n",
      "53/53 - 5s - loss: 0.1222 - out1_loss: 0.1328 - out2_loss: 0.0976 - val_loss: 0.1929 - val_out1_loss: 0.2159 - val_out2_loss: 0.1394\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1222 - out1_loss: 0.1327 - out2_loss: 0.0976 - val_loss: 0.1930 - val_out1_loss: 0.2159 - val_out2_loss: 0.1394\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.1217 - out1_loss: 0.1322 - out2_loss: 0.0973 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1394\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1215 - out1_loss: 0.1320 - out2_loss: 0.0972 - val_loss: 0.1931 - val_out1_loss: 0.2160 - val_out2_loss: 0.1395\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1215 - out1_loss: 0.1320 - out2_loss: 0.0971 - val_loss: 0.1927 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 84/120\n",
      "53/53 - 5s - loss: 0.1213 - out1_loss: 0.1317 - out2_loss: 0.0969 - val_loss: 0.1932 - val_out1_loss: 0.2162 - val_out2_loss: 0.1395\n",
      "Epoch 85/120\n",
      "53/53 - 5s - loss: 0.1212 - out1_loss: 0.1316 - out2_loss: 0.0969 - val_loss: 0.1931 - val_out1_loss: 0.2160 - val_out2_loss: 0.1395\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1208 - out1_loss: 0.1312 - out2_loss: 0.0966 - val_loss: 0.1930 - val_out1_loss: 0.2160 - val_out2_loss: 0.1393\n",
      "Epoch 87/120\n",
      "53/53 - 5s - loss: 0.1209 - out1_loss: 0.1312 - out2_loss: 0.0967 - val_loss: 0.1928 - val_out1_loss: 0.2158 - val_out2_loss: 0.1393\n",
      "Epoch 88/120\n",
      "53/53 - 5s - loss: 0.1205 - out1_loss: 0.1309 - out2_loss: 0.0964 - val_loss: 0.1930 - val_out1_loss: 0.2160 - val_out2_loss: 0.1393\n",
      "Epoch 89/120\n",
      "53/53 - 5s - loss: 0.1204 - out1_loss: 0.1307 - out2_loss: 0.0963 - val_loss: 0.1930 - val_out1_loss: 0.2160 - val_out2_loss: 0.1395\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1202 - out1_loss: 0.1305 - out2_loss: 0.0962 - val_loss: 0.1930 - val_out1_loss: 0.2159 - val_out2_loss: 0.1395\n",
      "Epoch 91/120\n",
      "53/53 - 5s - loss: 0.1200 - out1_loss: 0.1302 - out2_loss: 0.0961 - val_loss: 0.1931 - val_out1_loss: 0.2161 - val_out2_loss: 0.1393\n",
      "Epoch 92/120\n",
      "53/53 - 5s - loss: 0.1200 - out1_loss: 0.1303 - out2_loss: 0.0961 - val_loss: 0.1930 - val_out1_loss: 0.2160 - val_out2_loss: 0.1394\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1197 - out1_loss: 0.1299 - out2_loss: 0.0959 - val_loss: 0.1930 - val_out1_loss: 0.2160 - val_out2_loss: 0.1394\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1193 - out1_loss: 0.1295 - out2_loss: 0.0956 - val_loss: 0.1929 - val_out1_loss: 0.2159 - val_out2_loss: 0.1393\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1191 - out1_loss: 0.1293 - out2_loss: 0.0953 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1393\n",
      "Epoch 96/120\n",
      "53/53 - 5s - loss: 0.1191 - out1_loss: 0.1293 - out2_loss: 0.0955 - val_loss: 0.1928 - val_out1_loss: 0.2158 - val_out2_loss: 0.1392\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1189 - out1_loss: 0.1290 - out2_loss: 0.0954 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1188 - out1_loss: 0.1289 - out2_loss: 0.0952 - val_loss: 0.1928 - val_out1_loss: 0.2158 - val_out2_loss: 0.1392\n",
      "Epoch 99/120\n",
      "53/53 - 5s - loss: 0.1190 - out1_loss: 0.1291 - out2_loss: 0.0953 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1391\n",
      "Epoch 100/120\n",
      "53/53 - 5s - loss: 0.1191 - out1_loss: 0.1292 - out2_loss: 0.0954 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1188 - out1_loss: 0.1290 - out2_loss: 0.0952 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1187 - out1_loss: 0.1288 - out2_loss: 0.0952 - val_loss: 0.1928 - val_out1_loss: 0.2158 - val_out2_loss: 0.1392\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1188 - out1_loss: 0.1289 - out2_loss: 0.0953 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1186 - out1_loss: 0.1287 - out2_loss: 0.0950 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1187 - out1_loss: 0.1289 - out2_loss: 0.0952 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 106/120\n",
      "53/53 - 5s - loss: 0.1186 - out1_loss: 0.1286 - out2_loss: 0.0951 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1186 - out1_loss: 0.1286 - out2_loss: 0.0951 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1187 - out1_loss: 0.1287 - out2_loss: 0.0951 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 109/120\n",
      "53/53 - 5s - loss: 0.1187 - out1_loss: 0.1288 - out2_loss: 0.0951 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1187 - out1_loss: 0.1288 - out2_loss: 0.0951 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 111/120\n",
      "53/53 - 5s - loss: 0.1188 - out1_loss: 0.1288 - out2_loss: 0.0952 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 112/120\n",
      "53/53 - 5s - loss: 0.1186 - out1_loss: 0.1287 - out2_loss: 0.0951 - val_loss: 0.1927 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 113/120\n",
      "53/53 - 5s - loss: 0.1186 - out1_loss: 0.1286 - out2_loss: 0.0952 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1391\n",
      "Epoch 114/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 5s - loss: 0.1187 - out1_loss: 0.1287 - out2_loss: 0.0951 - val_loss: 0.1927 - val_out1_loss: 0.2157 - val_out2_loss: 0.1391\n",
      "Epoch 115/120\n",
      "53/53 - 5s - loss: 0.1185 - out1_loss: 0.1286 - out2_loss: 0.0951 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1391\n",
      "Epoch 116/120\n",
      "53/53 - 5s - loss: 0.1187 - out1_loss: 0.1287 - out2_loss: 0.0951 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1391\n",
      "Epoch 117/120\n",
      "53/53 - 5s - loss: 0.1187 - out1_loss: 0.1287 - out2_loss: 0.0952 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1391\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1186 - out1_loss: 0.1287 - out2_loss: 0.0951 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1391\n",
      "Epoch 119/120\n",
      "53/53 - 5s - loss: 0.1185 - out1_loss: 0.1285 - out2_loss: 0.0951 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1392\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1188 - out1_loss: 0.1289 - out2_loss: 0.0952 - val_loss: 0.1928 - val_out1_loss: 0.2157 - val_out2_loss: 0.1391\n",
      "#################### 0.3552603000922184\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_48 (T [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_49 (T [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_50 (T [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_36 (Embedding)        (None, 107, 128)     512         tf_op_layer_strided_slice_48[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_37 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_49[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_38 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_50[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_48 (SpatialDr (None, 107, 128)     0           embedding_36[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_49 (SpatialDr (None, 107, 128)     0           embedding_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_50 (SpatialDr (None, 107, 128)     0           embedding_38[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_24 (TensorFl [(None, 107, 384)]   0           spatial_dropout1d_48[0][0]       \n",
      "                                                                 spatial_dropout1d_49[0][0]       \n",
      "                                                                 spatial_dropout1d_50[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_12 (TensorFlo [(None, 107, 384)]   0           tf_op_layer_concat_24[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_51 (SpatialDr (None, 107, 384)     0           tf_op_layer_AddV2_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 107, 128)     256         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_25 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_51[0][0]       \n",
      "                                                                 dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_12 (Transform (None, 107, 512)     1577984     tf_op_layer_concat_25[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 107, 768)     2068992     transformer_block_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 107, 768)     2658816     bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_38 (Bidirectional (None, 107, 768)     2658816     bidirectional_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_51 (T [(None, 68, 768)]    0           bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_51[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_51[0][0\n",
      "==================================================================================================\n",
      "Total params: 8,974,346\n",
      "Trainable params: 8,974,346\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 8s - loss: 0.7280 - out1_loss: 0.7569 - out2_loss: 0.6605 - val_loss: 0.3967 - val_out1_loss: 0.4364 - val_out2_loss: 0.3043\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3921 - out1_loss: 0.4314 - out2_loss: 0.3006 - val_loss: 0.3965 - val_out1_loss: 0.4386 - val_out2_loss: 0.2983\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3624 - out1_loss: 0.4014 - out2_loss: 0.2713 - val_loss: 0.3458 - val_out1_loss: 0.3856 - val_out2_loss: 0.2530\n",
      "Epoch 4/120\n",
      "53/53 - 5s - loss: 0.3416 - out1_loss: 0.3787 - out2_loss: 0.2549 - val_loss: 0.3339 - val_out1_loss: 0.3717 - val_out2_loss: 0.2457\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3311 - out1_loss: 0.3672 - out2_loss: 0.2466 - val_loss: 0.3223 - val_out1_loss: 0.3604 - val_out2_loss: 0.2336\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.3178 - out1_loss: 0.3539 - out2_loss: 0.2337 - val_loss: 0.3119 - val_out1_loss: 0.3456 - val_out2_loss: 0.2332\n",
      "Epoch 7/120\n",
      "53/53 - 5s - loss: 0.3050 - out1_loss: 0.3393 - out2_loss: 0.2249 - val_loss: 0.2979 - val_out1_loss: 0.3335 - val_out2_loss: 0.2150\n",
      "Epoch 8/120\n",
      "53/53 - 5s - loss: 0.2965 - out1_loss: 0.3300 - out2_loss: 0.2182 - val_loss: 0.2899 - val_out1_loss: 0.3236 - val_out2_loss: 0.2114\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2833 - out1_loss: 0.3156 - out2_loss: 0.2078 - val_loss: 0.2727 - val_out1_loss: 0.3044 - val_out2_loss: 0.1986\n",
      "Epoch 10/120\n",
      "53/53 - 5s - loss: 0.2713 - out1_loss: 0.3013 - out2_loss: 0.2013 - val_loss: 0.2663 - val_out1_loss: 0.2965 - val_out2_loss: 0.1960\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2652 - out1_loss: 0.2954 - out2_loss: 0.1948 - val_loss: 0.2629 - val_out1_loss: 0.2943 - val_out2_loss: 0.1897\n",
      "Epoch 12/120\n",
      "53/53 - 5s - loss: 0.2589 - out1_loss: 0.2884 - out2_loss: 0.1903 - val_loss: 0.2585 - val_out1_loss: 0.2888 - val_out2_loss: 0.1877\n",
      "Epoch 13/120\n",
      "53/53 - 5s - loss: 0.2537 - out1_loss: 0.2826 - out2_loss: 0.1862 - val_loss: 0.2564 - val_out1_loss: 0.2874 - val_out2_loss: 0.1840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2504 - out1_loss: 0.2784 - out2_loss: 0.1852 - val_loss: 0.2512 - val_out1_loss: 0.2804 - val_out2_loss: 0.1829\n",
      "Epoch 15/120\n",
      "53/53 - 5s - loss: 0.2439 - out1_loss: 0.2713 - out2_loss: 0.1799 - val_loss: 0.2480 - val_out1_loss: 0.2781 - val_out2_loss: 0.1776\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2397 - out1_loss: 0.2667 - out2_loss: 0.1767 - val_loss: 0.2436 - val_out1_loss: 0.2747 - val_out2_loss: 0.1710\n",
      "Epoch 17/120\n",
      "53/53 - 5s - loss: 0.2350 - out1_loss: 0.2608 - out2_loss: 0.1749 - val_loss: 0.2320 - val_out1_loss: 0.2582 - val_out2_loss: 0.1709\n",
      "Epoch 18/120\n",
      "53/53 - 5s - loss: 0.2281 - out1_loss: 0.2529 - out2_loss: 0.1701 - val_loss: 0.2303 - val_out1_loss: 0.2573 - val_out2_loss: 0.1673\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.2238 - out1_loss: 0.2488 - out2_loss: 0.1653 - val_loss: 0.2253 - val_out1_loss: 0.2507 - val_out2_loss: 0.1661\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.2148 - out1_loss: 0.2382 - out2_loss: 0.1601 - val_loss: 0.2198 - val_out1_loss: 0.2415 - val_out2_loss: 0.1693\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.2105 - out1_loss: 0.2331 - out2_loss: 0.1577 - val_loss: 0.2157 - val_out1_loss: 0.2406 - val_out2_loss: 0.1574\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.2085 - out1_loss: 0.2305 - out2_loss: 0.1574 - val_loss: 0.2170 - val_out1_loss: 0.2417 - val_out2_loss: 0.1593\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.2024 - out1_loss: 0.2244 - out2_loss: 0.1512 - val_loss: 0.2128 - val_out1_loss: 0.2370 - val_out2_loss: 0.1562\n",
      "Epoch 24/120\n",
      "53/53 - 5s - loss: 0.1997 - out1_loss: 0.2208 - out2_loss: 0.1502 - val_loss: 0.2098 - val_out1_loss: 0.2330 - val_out2_loss: 0.1557\n",
      "Epoch 25/120\n",
      "53/53 - 5s - loss: 0.1984 - out1_loss: 0.2195 - out2_loss: 0.1490 - val_loss: 0.2124 - val_out1_loss: 0.2375 - val_out2_loss: 0.1538\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1941 - out1_loss: 0.2147 - out2_loss: 0.1459 - val_loss: 0.2102 - val_out1_loss: 0.2351 - val_out2_loss: 0.1521\n",
      "Epoch 27/120\n",
      "53/53 - 5s - loss: 0.1922 - out1_loss: 0.2125 - out2_loss: 0.1450 - val_loss: 0.2089 - val_out1_loss: 0.2322 - val_out2_loss: 0.1546\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1882 - out1_loss: 0.2080 - out2_loss: 0.1418 - val_loss: 0.2062 - val_out1_loss: 0.2303 - val_out2_loss: 0.1498\n",
      "Epoch 29/120\n",
      "53/53 - 5s - loss: 0.1862 - out1_loss: 0.2056 - out2_loss: 0.1411 - val_loss: 0.2035 - val_out1_loss: 0.2272 - val_out2_loss: 0.1481\n",
      "Epoch 30/120\n",
      "53/53 - 5s - loss: 0.1829 - out1_loss: 0.2021 - out2_loss: 0.1383 - val_loss: 0.2049 - val_out1_loss: 0.2276 - val_out2_loss: 0.1521\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1810 - out1_loss: 0.1996 - out2_loss: 0.1376 - val_loss: 0.2039 - val_out1_loss: 0.2267 - val_out2_loss: 0.1506\n",
      "Epoch 32/120\n",
      "53/53 - 5s - loss: 0.1775 - out1_loss: 0.1958 - out2_loss: 0.1347 - val_loss: 0.2032 - val_out1_loss: 0.2269 - val_out2_loss: 0.1478\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1771 - out1_loss: 0.1952 - out2_loss: 0.1348 - val_loss: 0.2028 - val_out1_loss: 0.2267 - val_out2_loss: 0.1470\n",
      "Epoch 34/120\n",
      "53/53 - 5s - loss: 0.1744 - out1_loss: 0.1923 - out2_loss: 0.1326 - val_loss: 0.2008 - val_out1_loss: 0.2238 - val_out2_loss: 0.1470\n",
      "Epoch 35/120\n",
      "53/53 - 5s - loss: 0.1716 - out1_loss: 0.1891 - out2_loss: 0.1310 - val_loss: 0.2006 - val_out1_loss: 0.2234 - val_out2_loss: 0.1474\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1706 - out1_loss: 0.1879 - out2_loss: 0.1304 - val_loss: 0.2024 - val_out1_loss: 0.2265 - val_out2_loss: 0.1460\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1691 - out1_loss: 0.1857 - out2_loss: 0.1302 - val_loss: 0.2021 - val_out1_loss: 0.2264 - val_out2_loss: 0.1454\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1669 - out1_loss: 0.1837 - out2_loss: 0.1278 - val_loss: 0.1992 - val_out1_loss: 0.2223 - val_out2_loss: 0.1451\n",
      "Epoch 39/120\n",
      "53/53 - 5s - loss: 0.1634 - out1_loss: 0.1798 - out2_loss: 0.1253 - val_loss: 0.1976 - val_out1_loss: 0.2208 - val_out2_loss: 0.1435\n",
      "Epoch 40/120\n",
      "53/53 - 5s - loss: 0.1626 - out1_loss: 0.1789 - out2_loss: 0.1246 - val_loss: 0.1989 - val_out1_loss: 0.2216 - val_out2_loss: 0.1459\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1627 - out1_loss: 0.1786 - out2_loss: 0.1258 - val_loss: 0.1983 - val_out1_loss: 0.2207 - val_out2_loss: 0.1462\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1597 - out1_loss: 0.1753 - out2_loss: 0.1233 - val_loss: 0.1990 - val_out1_loss: 0.2217 - val_out2_loss: 0.1461\n",
      "Epoch 43/120\n",
      "53/53 - 5s - loss: 0.1587 - out1_loss: 0.1744 - out2_loss: 0.1222 - val_loss: 0.1981 - val_out1_loss: 0.2212 - val_out2_loss: 0.1442\n",
      "Epoch 44/120\n",
      "53/53 - 5s - loss: 0.1565 - out1_loss: 0.1718 - out2_loss: 0.1210 - val_loss: 0.1980 - val_out1_loss: 0.2202 - val_out2_loss: 0.1463\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1566 - out1_loss: 0.1717 - out2_loss: 0.1213 - val_loss: 0.2006 - val_out1_loss: 0.2234 - val_out2_loss: 0.1473\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1541 - out1_loss: 0.1689 - out2_loss: 0.1196 - val_loss: 0.1969 - val_out1_loss: 0.2192 - val_out2_loss: 0.1451\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1531 - out1_loss: 0.1679 - out2_loss: 0.1185 - val_loss: 0.1986 - val_out1_loss: 0.2221 - val_out2_loss: 0.1437\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1552 - out1_loss: 0.1698 - out2_loss: 0.1214 - val_loss: 0.2003 - val_out1_loss: 0.2241 - val_out2_loss: 0.1445\n",
      "Epoch 49/120\n",
      "53/53 - 5s - loss: 0.1531 - out1_loss: 0.1675 - out2_loss: 0.1195 - val_loss: 0.1993 - val_out1_loss: 0.2221 - val_out2_loss: 0.1460\n",
      "Epoch 50/120\n",
      "53/53 - 5s - loss: 0.1503 - out1_loss: 0.1645 - out2_loss: 0.1171 - val_loss: 0.1987 - val_out1_loss: 0.2211 - val_out2_loss: 0.1465\n",
      "Epoch 51/120\n",
      "53/53 - 5s - loss: 0.1494 - out1_loss: 0.1635 - out2_loss: 0.1163 - val_loss: 0.1947 - val_out1_loss: 0.2175 - val_out2_loss: 0.1414\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1473 - out1_loss: 0.1611 - out2_loss: 0.1151 - val_loss: 0.1972 - val_out1_loss: 0.2203 - val_out2_loss: 0.1434\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1463 - out1_loss: 0.1600 - out2_loss: 0.1143 - val_loss: 0.1966 - val_out1_loss: 0.2200 - val_out2_loss: 0.1421\n",
      "Epoch 54/120\n",
      "53/53 - 5s - loss: 0.1454 - out1_loss: 0.1590 - out2_loss: 0.1136 - val_loss: 0.1950 - val_out1_loss: 0.2179 - val_out2_loss: 0.1416\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1442 - out1_loss: 0.1577 - out2_loss: 0.1128 - val_loss: 0.1964 - val_out1_loss: 0.2190 - val_out2_loss: 0.1435\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1444 - out1_loss: 0.1578 - out2_loss: 0.1133 - val_loss: 0.1966 - val_out1_loss: 0.2193 - val_out2_loss: 0.1439\n",
      "Epoch 57/120\n",
      "53/53 - 5s - loss: 0.1441 - out1_loss: 0.1574 - out2_loss: 0.1130 - val_loss: 0.1969 - val_out1_loss: 0.2193 - val_out2_loss: 0.1446\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1433 - out1_loss: 0.1563 - out2_loss: 0.1130 - val_loss: 0.1973 - val_out1_loss: 0.2205 - val_out2_loss: 0.1433\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1412 - out1_loss: 0.1542 - out2_loss: 0.1106 - val_loss: 0.1960 - val_out1_loss: 0.2186 - val_out2_loss: 0.1434\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1403 - out1_loss: 0.1528 - out2_loss: 0.1112 - val_loss: 0.1985 - val_out1_loss: 0.2218 - val_out2_loss: 0.1443\n",
      "Epoch 61/120\n",
      "53/53 - 5s - loss: 0.1407 - out1_loss: 0.1533 - out2_loss: 0.1114 - val_loss: 0.1967 - val_out1_loss: 0.2192 - val_out2_loss: 0.1440\n",
      "Epoch 62/120\n",
      "53/53 - 5s - loss: 0.1331 - out1_loss: 0.1452 - out2_loss: 0.1051 - val_loss: 0.1920 - val_out1_loss: 0.2147 - val_out2_loss: 0.1390\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1306 - out1_loss: 0.1423 - out2_loss: 0.1032 - val_loss: 0.1919 - val_out1_loss: 0.2146 - val_out2_loss: 0.1388\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1296 - out1_loss: 0.1413 - out2_loss: 0.1025 - val_loss: 0.1918 - val_out1_loss: 0.2145 - val_out2_loss: 0.1388\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1287 - out1_loss: 0.1402 - out2_loss: 0.1018 - val_loss: 0.1917 - val_out1_loss: 0.2144 - val_out2_loss: 0.1386\n",
      "Epoch 66/120\n",
      "53/53 - 5s - loss: 0.1284 - out1_loss: 0.1399 - out2_loss: 0.1017 - val_loss: 0.1917 - val_out1_loss: 0.2144 - val_out2_loss: 0.1387\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1278 - out1_loss: 0.1392 - out2_loss: 0.1014 - val_loss: 0.1917 - val_out1_loss: 0.2144 - val_out2_loss: 0.1385\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1274 - out1_loss: 0.1387 - out2_loss: 0.1010 - val_loss: 0.1917 - val_out1_loss: 0.2144 - val_out2_loss: 0.1388\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.1271 - out1_loss: 0.1384 - out2_loss: 0.1008 - val_loss: 0.1914 - val_out1_loss: 0.2141 - val_out2_loss: 0.1383\n",
      "Epoch 70/120\n",
      "53/53 - 5s - loss: 0.1270 - out1_loss: 0.1383 - out2_loss: 0.1007 - val_loss: 0.1914 - val_out1_loss: 0.2141 - val_out2_loss: 0.1384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/120\n",
      "53/53 - 5s - loss: 0.1267 - out1_loss: 0.1379 - out2_loss: 0.1006 - val_loss: 0.1914 - val_out1_loss: 0.2140 - val_out2_loss: 0.1384\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1264 - out1_loss: 0.1376 - out2_loss: 0.1004 - val_loss: 0.1915 - val_out1_loss: 0.2142 - val_out2_loss: 0.1386\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1261 - out1_loss: 0.1372 - out2_loss: 0.1002 - val_loss: 0.1917 - val_out1_loss: 0.2144 - val_out2_loss: 0.1387\n",
      "Epoch 74/120\n",
      "53/53 - 5s - loss: 0.1256 - out1_loss: 0.1367 - out2_loss: 0.0998 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1384\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1255 - out1_loss: 0.1365 - out2_loss: 0.0998 - val_loss: 0.1916 - val_out1_loss: 0.2144 - val_out2_loss: 0.1384\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1252 - out1_loss: 0.1362 - out2_loss: 0.0996 - val_loss: 0.1915 - val_out1_loss: 0.2143 - val_out2_loss: 0.1384\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1252 - out1_loss: 0.1363 - out2_loss: 0.0995 - val_loss: 0.1914 - val_out1_loss: 0.2142 - val_out2_loss: 0.1383\n",
      "Epoch 78/120\n",
      "53/53 - 5s - loss: 0.1250 - out1_loss: 0.1360 - out2_loss: 0.0993 - val_loss: 0.1915 - val_out1_loss: 0.2142 - val_out2_loss: 0.1384\n",
      "Epoch 79/120\n",
      "53/53 - 5s - loss: 0.1249 - out1_loss: 0.1358 - out2_loss: 0.0993 - val_loss: 0.1915 - val_out1_loss: 0.2142 - val_out2_loss: 0.1384\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1242 - out1_loss: 0.1351 - out2_loss: 0.0990 - val_loss: 0.1915 - val_out1_loss: 0.2142 - val_out2_loss: 0.1384\n",
      "Epoch 81/120\n",
      "53/53 - 5s - loss: 0.1241 - out1_loss: 0.1350 - out2_loss: 0.0988 - val_loss: 0.1914 - val_out1_loss: 0.2142 - val_out2_loss: 0.1383\n",
      "Epoch 82/120\n",
      "53/53 - 5s - loss: 0.1240 - out1_loss: 0.1348 - out2_loss: 0.0987 - val_loss: 0.1914 - val_out1_loss: 0.2141 - val_out2_loss: 0.1383\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1241 - out1_loss: 0.1350 - out2_loss: 0.0988 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 84/120\n",
      "53/53 - 5s - loss: 0.1240 - out1_loss: 0.1348 - out2_loss: 0.0988 - val_loss: 0.1914 - val_out1_loss: 0.2141 - val_out2_loss: 0.1383\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.1239 - out1_loss: 0.1347 - out2_loss: 0.0987 - val_loss: 0.1914 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 86/120\n",
      "53/53 - 5s - loss: 0.1238 - out1_loss: 0.1346 - out2_loss: 0.0986 - val_loss: 0.1914 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1238 - out1_loss: 0.1346 - out2_loss: 0.0985 - val_loss: 0.1914 - val_out1_loss: 0.2142 - val_out2_loss: 0.1383\n",
      "Epoch 88/120\n",
      "53/53 - 5s - loss: 0.1237 - out1_loss: 0.1345 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.1238 - out1_loss: 0.1346 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1235 - out1_loss: 0.1343 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 91/120\n",
      "53/53 - 5s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.1238 - out1_loss: 0.1345 - out2_loss: 0.0986 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1237 - out1_loss: 0.1345 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1237 - out1_loss: 0.1344 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 96/120\n",
      "53/53 - 5s - loss: 0.1237 - out1_loss: 0.1345 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1343 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1237 - out1_loss: 0.1345 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1237 - out1_loss: 0.1346 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1343 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1237 - out1_loss: 0.1345 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1343 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1237 - out1_loss: 0.1345 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1343 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1238 - out1_loss: 0.1346 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1235 - out1_loss: 0.1342 - out2_loss: 0.0983 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1235 - out1_loss: 0.1343 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1237 - out1_loss: 0.1345 - out2_loss: 0.0984 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.1237 - out1_loss: 0.1344 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1236 - out1_loss: 0.1344 - out2_loss: 0.0985 - val_loss: 0.1913 - val_out1_loss: 0.2141 - val_out2_loss: 0.1382\n",
      "#################### 0.37139703164681226\n",
      "(629, 107, 5) (3005, 130, 5)\n"
     ]
    }
   ],
   "source": [
    "FOLDS = KFold(n_splits=5, random_state=815, shuffle=True)\n",
    "\n",
    "oofs_pred = np.zeros_like(train_labels)\n",
    "public_preds_array = []\n",
    "public_preds_array = []\n",
    "\n",
    "for i, (trn_idx, vld_idx) in enumerate(FOLDS.split(train_inputs)):\n",
    "    trn_inputs = train_inputs[trn_idx]\n",
    "    vld_inputs = train_inputs[vld_idx]\n",
    "    \n",
    "    trn_inputs_bpps = train_bpps[trn_idx]\n",
    "    vld_inputs_bpps = train_bpps[vld_idx]\n",
    "\n",
    "    trn_labels = train_labels[trn_idx]\n",
    "    vld_labels = train_labels[vld_idx]\n",
    "\n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        [trn_inputs, trn_inputs_bpps], trn_labels, \n",
    "        validation_data=([vld_inputs, vld_inputs_bpps], vld_labels),\n",
    "        batch_size=32,\n",
    "        epochs=120,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "            tf.keras.callbacks.ModelCheckpoint('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_posEnc_BeforeConcat_815.h5')\n",
    "        ],\n",
    "        verbose=2,\n",
    "    )\n",
    "    model.load_weights('./tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_posEnc_BeforeConcat_815.h5')\n",
    "    outputs, outputs2 = model.predict([vld_inputs, vld_inputs_bpps])\n",
    "    oofs_pred[vld_idx] = outputs\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    errors = []\n",
    "    for idx in range(5):\n",
    "         errors.append(np.sqrt(mean_squared_error(vld_labels[:, idx], outputs[:, idx])))\n",
    "    final_error = np.mean(errors)\n",
    "    print('#'*20, final_error)\n",
    "\n",
    "    public_df = test.query(\"seq_length == 107\").copy()\n",
    "    private_df = test.query(\"seq_length == 130\").copy()\n",
    "    \n",
    "    public_df['sequence'] = public_df['sequence'].apply(lambda x: [token2int0[ele] for ele in x])\n",
    "    public_df['structure'] = public_df['structure'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    public_df['predicted_loop_type'] = public_df['predicted_loop_type'].apply(lambda x: [token2int2[ele] for ele in x])\n",
    "    public_inputs = np.transpose(np.array(public_df[['sequence', 'structure', 'predicted_loop_type']].values.tolist()), (0, 2, 1))\n",
    "\n",
    "    private_df['sequence'] = private_df['sequence'].apply(lambda x: [token2int0[ele] for ele in x])\n",
    "    private_df['structure'] = private_df['structure'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    private_df['predicted_loop_type'] = private_df['predicted_loop_type'].apply(lambda x: [token2int2[ele] for ele in x])\n",
    "    private_inputs = np.transpose(np.array(private_df[['sequence', 'structure', 'predicted_loop_type']].values.tolist()), (0, 2, 1))\n",
    "\n",
    "    public_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in public_df['id']])\n",
    "    public_bpps = public_bpps[:, :, np.newaxis]\n",
    "    \n",
    "    private_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in private_df['id']])\n",
    "    private_bpps = private_bpps[:, :, np.newaxis] \n",
    "\n",
    "    # Caveat: The prediction format requires the output to be the same length as the input,\n",
    "    # although it's not the case for the training data.\n",
    "    model_short = build_model(seq_len=107, pred_len=107)\n",
    "    model_long = build_model(seq_len=130, pred_len=130)\n",
    "\n",
    "    model_short.load_weights('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_posEnc_BeforeConcat_815.h5')\n",
    "    model_long.load_weights('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_posEnc_BeforeConcat_815.h5')\n",
    "\n",
    "    public_preds, outputs2 = model_short.predict([public_inputs, public_bpps])\n",
    "    private_preds, outputs2 = model_long.predict([private_inputs,private_bpps])\n",
    "    \n",
    "    public_preds_array.append(public_preds)\n",
    "    public_preds_array.append(private_preds)\n",
    "\n",
    "    print(public_preds.shape, private_preds.shape)\n",
    "\n",
    "    preds_ls = []\n",
    "\n",
    "    for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
    "        for idx, uid in enumerate(df.id):\n",
    "            single_pred = preds[idx]\n",
    "\n",
    "            single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "            preds_ls.append(single_df)\n",
    "\n",
    "    preds_df = pd.concat(preds_ls)\n",
    "\n",
    "    submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "    submission.to_csv(f'submission_tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_posEnc_BeforeConcat_815_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, uid in enumerate(train.id):\n",
    "#     single_pred = oofs_pred[i]\n",
    "\n",
    "#     oof_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "#     oof_df['id_seqpos'] = [f'{uid}_{x}' for x in range(oof_df.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gru 가 들어가면 좋은게 long term corelation 이 있는 것 아닐까...꼬이고 하니까\n",
    "- Positional encoding 넣으면 확 뛸거 같은디"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyh",
   "language": "python",
   "name": "lyh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 161.997015,
   "end_time": "2020-09-12T05:49:46.470488",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-12T05:47:04.473473",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
