{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:08.823964Z",
     "iopub.status.busy": "2020-09-12T05:47:08.823205Z",
     "iopub.status.idle": "2020-09-12T05:47:15.758339Z",
     "shell.execute_reply": "2020-09-12T05:47:15.757303Z"
    },
    "papermill": {
     "duration": 6.954489,
     "end_time": "2020-09-12T05:47:15.758481",
     "exception": false,
     "start_time": "2020-09-12T05:47:08.803992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01294,
     "end_time": "2020-09-12T05:47:15.784990",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.772050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define helper functions and useful vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.817688Z",
     "iopub.status.busy": "2020-09-12T05:47:15.815907Z",
     "iopub.status.idle": "2020-09-12T05:47:15.818497Z",
     "shell.execute_reply": "2020-09-12T05:47:15.818980Z"
    },
    "papermill": {
     "duration": 0.020522,
     "end_time": "2020-09-12T05:47:15.819094",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.798572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will tell us the columns we are predicting\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Classifier((None, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.GRU(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.LSTM(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def build_model(gru=False,seq_len=107, pred_len=68, dropout=0.25,\n",
    "                embed_dim=128, hidden_dim=384):\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n",
    "    inputs_bpps = tf.keras.layers.Input(shape=(seq_len, 1))\n",
    "    \n",
    "    bpps = tf.keras.layers.Dense(embed_dim, activation='relu')(inputs_bpps)\n",
    "    \n",
    "    \n",
    "    token_embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)\n",
    "    query_embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)\n",
    "    \n",
    "    t_embed = token_embed(inputs)\n",
    "    q_embed = query_embed(inputs)\n",
    "    \n",
    "    t_reshaped = tf.reshape(\n",
    "        t_embed, shape=(-1, t_embed.shape[1],  t_embed.shape[2] * t_embed.shape[3]))\n",
    "    \n",
    "    t_reshaped = tf.keras.layers.SpatialDropout1D(.2)(t_reshaped)\n",
    "    \n",
    "    t_reshaped = tf.concat([t_reshaped, bpps], axis=2)\n",
    "    \n",
    "    t_hidden = gru_layer(hidden_dim, dropout)(t_reshaped)\n",
    "    t_hidden = gru_layer(hidden_dim, dropout)(t_hidden)\n",
    "    t_hidden = gru_layer(hidden_dim, dropout)(t_hidden)\n",
    "    \n",
    "    q_reshaped = tf.reshape(\n",
    "        q_embed, shape=(-1, q_embed.shape[1],  q_embed.shape[2] * q_embed.shape[3]))\n",
    "    \n",
    "    q_reshaped = tf.keras.layers.SpatialDropout1D(.2)(q_reshaped)\n",
    "    \n",
    "    q_reshaped = tf.concat([q_reshaped, bpps], axis=2)\n",
    "    \n",
    "    q_hidden = gru_layer(hidden_dim, dropout)(q_reshaped)\n",
    "    q_hidden = gru_layer(hidden_dim, dropout)(q_hidden)\n",
    "    q_hidden = gru_layer(hidden_dim, dropout)(q_hidden)\n",
    "    \n",
    "    query_value_attention_seq = tf.keras.layers.Attention()(\n",
    "    [t_hidden, q_hidden])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #query_encoding = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "    #    q_hidden)\n",
    "    #query_value_attention = tf.keras.layers.GlobalAveragePooling1D()(\n",
    "    #    query_value_attention_seq)\n",
    "\n",
    "    hidden = tf.keras.layers.Concatenate()(\n",
    "        [q_hidden, query_value_attention_seq])\n",
    "    \n",
    "    #hidden = tf.keras.layers.Concatenate()(\n",
    "    #    [q_hidden, query_value_attention_seq, bpps])\n",
    "    hidden = tf.keras.layers.Dense(768, activation='relu')(hidden)\n",
    "    \n",
    "    \n",
    "    #only making predictions on the first part of each sequence\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    \n",
    "    out = tf.keras.layers.Dense(5)(truncated)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs, inputs_bpps], outputs=out)\n",
    "\n",
    "    #some optimizers\n",
    "    adam = tf.optimizers.Adam()\n",
    "    \n",
    "    model.compile(optimizer = adam, loss='mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.894673Z",
     "iopub.status.busy": "2020-09-12T05:47:15.893039Z",
     "iopub.status.idle": "2020-09-12T05:47:15.895372Z",
     "shell.execute_reply": "2020-09-12T05:47:15.895926Z"
    },
    "papermill": {
     "duration": 0.023046,
     "end_time": "2020-09-12T05:47:15.896053",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.873007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    return np.transpose(\n",
    "        np.array(\n",
    "            df[cols]\n",
    "            .applymap(lambda seq: [token2int[x] for x in seq])\n",
    "            .values\n",
    "            .tolist()\n",
    "        ),\n",
    "        (0, 2, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013134,
     "end_time": "2020-09-12T05:47:15.922732",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.909598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.957048Z",
     "iopub.status.busy": "2020-09-12T05:47:15.956359Z",
     "iopub.status.idle": "2020-09-12T05:47:16.951033Z",
     "shell.execute_reply": "2020-09-12T05:47:16.950138Z"
    },
    "papermill": {
     "duration": 1.012628,
     "end_time": "2020-09-12T05:47:16.951150",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.938522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('../input//train.json', lines=True)\n",
    "test = pd.read_json('../input//test.json', lines=True)\n",
    "sample_df = pd.read_csv('../input//sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id_001f94081'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = np.load('../input/bpps/id_001f94081.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80145771, 0.8162878 , 0.9399976 , 0.98687779, 0.98872014,\n",
       "       0.8726042 , 0.64923491, 0.45909952, 0.38734203, 0.37291085,\n",
       "       0.48373307, 0.89664275, 0.90951632, 0.90861451, 0.98940993,\n",
       "       0.98145491, 0.81965108, 0.79170963, 0.38557835, 0.52880297,\n",
       "       0.5372444 , 0.52122251, 0.90823082, 0.40080513, 0.43650824,\n",
       "       0.54643881, 0.38305727, 0.53568993, 0.67795352, 0.8628183 ,\n",
       "       0.78497647, 0.83994244, 0.78492865, 0.70795306, 0.73116841,\n",
       "       0.82452095, 0.86113227, 0.52072924, 0.37224691, 0.20266188,\n",
       "       0.26856484, 0.39608598, 0.14207184, 0.65970159, 0.65338135,\n",
       "       0.80168215, 0.97622094, 0.40194761, 0.28440304, 0.09579655,\n",
       "       0.23852457, 0.80521037, 0.70261301, 0.81546441, 0.94987859,\n",
       "       0.92402902, 0.76050376, 0.63090152, 0.77919177, 0.73839201,\n",
       "       0.61416194, 0.70487221, 0.35752507, 0.40452985, 0.65327547,\n",
       "       0.58192038, 0.92482731, 0.95905864, 0.13151534, 0.09435281,\n",
       "       0.0744179 , 0.05975572, 0.04247293, 0.05214685, 0.0915126 ,\n",
       "       0.81173428, 0.93450864, 0.96903919, 0.88908934, 0.17730243,\n",
       "       0.11017743, 0.09443205, 0.13040592, 0.17304841, 0.19466995,\n",
       "       0.21206308, 1.        , 0.99890886, 0.99869359, 0.9428686 ,\n",
       "       0.86038865, 0.93654079, 0.96160082, 0.96708391, 0.94263689,\n",
       "       0.99683127, 0.98872616, 0.93275765, 1.        , 0.99814014,\n",
       "       0.95080026, 1.        , 1.        , 0.9606901 , 1.        ,\n",
       "       1.        , 0.95382831])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - foo.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target columns\n",
    "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:16.996064Z",
     "iopub.status.busy": "2020-09-12T05:47:16.993995Z",
     "iopub.status.idle": "2020-09-12T05:47:17.326887Z",
     "shell.execute_reply": "2020-09-12T05:47:17.326212Z"
    },
    "papermill": {
     "duration": 0.361794,
     "end_time": "2020-09-12T05:47:17.327041",
     "exception": false,
     "start_time": "2020-09-12T05:47:16.965247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs = preprocess_inputs(train[train.signal_to_noise > 1])\n",
    "train_labels = np.array(train[train.signal_to_noise > 1][target_cols].values.tolist()).transpose((0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in train['id']])\n",
    "train_bpps = train_bpps[train.signal_to_noise > 1][:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like(train_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 107, 3, 128)  1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 107, 3, 128)  1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 107, 384)]   0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 107, 384)]   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 107, 384)     0           tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 107, 128)     256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 107, 384)     0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_1[0][0]        \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 107, 512)]   0           spatial_dropout1d[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 107, 768)     2068992     tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 107, 768)     2068992     tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 107, 768)     2658816     bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 107, 768)     2658816     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 107, 768)     2658816     bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 107, 768)     2658816     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 107, 768)     0           bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 107, 1536)    0           bidirectional_5[0][0]            \n",
      "                                                                 attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 107, 768)     1180416     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 68, 768)]    0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 68, 5)        3845        tf_op_layer_strided_slice[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 15,961,349\n",
      "Trainable params: 15,961,349\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 11s - loss: 0.1938 - val_loss: 0.1444\n",
      "Epoch 2/120\n",
      "53/53 - 8s - loss: 0.1378 - val_loss: 0.1274\n",
      "Epoch 3/120\n",
      "53/53 - 8s - loss: 0.1215 - val_loss: 0.1151\n",
      "Epoch 4/120\n",
      "53/53 - 8s - loss: 0.1122 - val_loss: 0.1028\n",
      "Epoch 5/120\n",
      "53/53 - 8s - loss: 0.1053 - val_loss: 0.0928\n",
      "Epoch 6/120\n",
      "53/53 - 8s - loss: 0.0955 - val_loss: 0.0848\n",
      "Epoch 7/120\n",
      "53/53 - 8s - loss: 0.0876 - val_loss: 0.0770\n",
      "Epoch 8/120\n",
      "53/53 - 8s - loss: 0.0812 - val_loss: 0.0782\n",
      "Epoch 9/120\n",
      "53/53 - 7s - loss: 0.0775 - val_loss: 0.0725\n",
      "Epoch 10/120\n",
      "53/53 - 7s - loss: 0.0735 - val_loss: 0.0744\n",
      "Epoch 11/120\n",
      "53/53 - 8s - loss: 0.0705 - val_loss: 0.0733\n",
      "Epoch 12/120\n",
      "53/53 - 8s - loss: 0.0671 - val_loss: 0.0676\n",
      "Epoch 13/120\n",
      "53/53 - 8s - loss: 0.0658 - val_loss: 0.0695\n",
      "Epoch 14/120\n",
      "53/53 - 7s - loss: 0.0623 - val_loss: 0.0654\n",
      "Epoch 15/120\n",
      "53/53 - 8s - loss: 0.0589 - val_loss: 0.0664\n",
      "Epoch 16/120\n",
      "53/53 - 8s - loss: 0.0560 - val_loss: 0.0644\n",
      "Epoch 17/120\n",
      "53/53 - 8s - loss: 0.0547 - val_loss: 0.0639\n",
      "Epoch 18/120\n",
      "53/53 - 8s - loss: 0.0525 - val_loss: 0.0632\n",
      "Epoch 19/120\n",
      "53/53 - 8s - loss: 0.0496 - val_loss: 0.0633\n",
      "Epoch 20/120\n",
      "53/53 - 7s - loss: 0.0478 - val_loss: 0.0647\n",
      "Epoch 21/120\n",
      "53/53 - 7s - loss: 0.0508 - val_loss: 0.0629\n",
      "Epoch 22/120\n",
      "53/53 - 8s - loss: 0.0476 - val_loss: 0.0619\n",
      "Epoch 23/120\n",
      "53/53 - 8s - loss: 0.0484 - val_loss: 0.0617\n",
      "Epoch 24/120\n",
      "53/53 - 8s - loss: 0.0457 - val_loss: 0.0626\n",
      "Epoch 25/120\n",
      "53/53 - 8s - loss: 0.0423 - val_loss: 0.0597\n",
      "Epoch 26/120\n",
      "53/53 - 7s - loss: 0.0400 - val_loss: 0.0615\n",
      "Epoch 27/120\n",
      "53/53 - 8s - loss: 0.0383 - val_loss: 0.0593\n",
      "Epoch 28/120\n",
      "53/53 - 8s - loss: 0.0355 - val_loss: 0.0592\n",
      "Epoch 29/120\n",
      "53/53 - 8s - loss: 0.0336 - val_loss: 0.0591\n",
      "Epoch 30/120\n",
      "53/53 - 8s - loss: 0.0331 - val_loss: 0.0588\n",
      "Epoch 31/120\n",
      "53/53 - 8s - loss: 0.0323 - val_loss: 0.0603\n",
      "Epoch 32/120\n",
      "53/53 - 8s - loss: 0.0338 - val_loss: 0.0596\n",
      "Epoch 33/120\n",
      "53/53 - 7s - loss: 0.0317 - val_loss: 0.0594\n",
      "Epoch 34/120\n",
      "53/53 - 8s - loss: 0.0295 - val_loss: 0.0583\n",
      "Epoch 35/120\n",
      "53/53 - 8s - loss: 0.0281 - val_loss: 0.0581\n",
      "Epoch 36/120\n",
      "53/53 - 8s - loss: 0.0273 - val_loss: 0.0590\n",
      "Epoch 37/120\n",
      "53/53 - 7s - loss: 0.0270 - val_loss: 0.0584\n",
      "Epoch 38/120\n",
      "53/53 - 8s - loss: 0.0265 - val_loss: 0.0593\n",
      "Epoch 39/120\n",
      "53/53 - 8s - loss: 0.0255 - val_loss: 0.0588\n",
      "Epoch 40/120\n",
      "53/53 - 8s - loss: 0.0240 - val_loss: 0.0586\n",
      "Epoch 41/120\n",
      "53/53 - 8s - loss: 0.0242 - val_loss: 0.0586\n",
      "Epoch 42/120\n",
      "53/53 - 8s - loss: 0.0233 - val_loss: 0.0584\n",
      "Epoch 43/120\n",
      "53/53 - 7s - loss: 0.0229 - val_loss: 0.0581\n",
      "Epoch 44/120\n",
      "53/53 - 7s - loss: 0.0219 - val_loss: 0.0581\n",
      "Epoch 45/120\n",
      "53/53 - 7s - loss: 0.0210 - val_loss: 0.0588\n",
      "Epoch 46/120\n",
      "53/53 - 8s - loss: 0.0187 - val_loss: 0.0570\n",
      "Epoch 47/120\n",
      "53/53 - 7s - loss: 0.0174 - val_loss: 0.0570\n",
      "Epoch 48/120\n",
      "53/53 - 8s - loss: 0.0170 - val_loss: 0.0570\n",
      "Epoch 49/120\n",
      "53/53 - 7s - loss: 0.0166 - val_loss: 0.0569\n",
      "Epoch 50/120\n",
      "53/53 - 7s - loss: 0.0164 - val_loss: 0.0569\n",
      "Epoch 51/120\n",
      "53/53 - 7s - loss: 0.0163 - val_loss: 0.0570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/120\n",
      "53/53 - 6s - loss: 0.0160 - val_loss: 0.0571\n",
      "Epoch 53/120\n",
      "53/53 - 7s - loss: 0.0159 - val_loss: 0.0570\n",
      "Epoch 54/120\n",
      "53/53 - 7s - loss: 0.0157 - val_loss: 0.0570\n",
      "Epoch 55/120\n",
      "53/53 - 7s - loss: 0.0156 - val_loss: 0.0571\n",
      "Epoch 56/120\n",
      "53/53 - 7s - loss: 0.0155 - val_loss: 0.0571\n",
      "Epoch 57/120\n",
      "53/53 - 8s - loss: 0.0153 - val_loss: 0.0570\n",
      "Epoch 58/120\n",
      "53/53 - 7s - loss: 0.0152 - val_loss: 0.0571\n",
      "Epoch 59/120\n",
      "53/53 - 7s - loss: 0.0151 - val_loss: 0.0573\n",
      "Epoch 60/120\n",
      "53/53 - 7s - loss: 0.0149 - val_loss: 0.0573\n",
      "Epoch 61/120\n",
      "53/53 - 7s - loss: 0.0149 - val_loss: 0.0573\n",
      "Epoch 62/120\n",
      "53/53 - 8s - loss: 0.0148 - val_loss: 0.0572\n",
      "Epoch 63/120\n",
      "53/53 - 8s - loss: 0.0148 - val_loss: 0.0572\n",
      "Epoch 64/120\n",
      "53/53 - 8s - loss: 0.0148 - val_loss: 0.0572\n",
      "Epoch 65/120\n",
      "53/53 - 7s - loss: 0.0148 - val_loss: 0.0572\n",
      "Epoch 66/120\n",
      "53/53 - 8s - loss: 0.0148 - val_loss: 0.0572\n",
      "Epoch 67/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0572\n",
      "Epoch 68/120\n",
      "53/53 - 8s - loss: 0.0148 - val_loss: 0.0573\n",
      "Epoch 69/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0572\n",
      "Epoch 70/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0572\n",
      "Epoch 71/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0572\n",
      "Epoch 72/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 73/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 74/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 75/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 76/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 77/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 78/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 79/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 80/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 81/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 82/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 83/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 84/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 85/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 86/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 87/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 88/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 89/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 90/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 91/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 92/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 93/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 94/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 95/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 96/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 97/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 98/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 99/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 100/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 101/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 102/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 103/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 104/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 105/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 106/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 107/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 108/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 109/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 110/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 111/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 112/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 113/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 114/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 115/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 116/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 117/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 118/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0573\n",
      "Epoch 119/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0573\n",
      "Epoch 120/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0573\n",
      "#################### 0.3799612005947971\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 107, 3, 128)  1792        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 107, 3, 128)  1792        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_7 (TensorFl [(None, 107, 384)]   0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 107, 384)]   0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 107, 384)     0           tf_op_layer_Reshape_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 107, 128)     256         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 107, 384)     0           tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_7 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_7[0][0]        \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_6[0][0]        \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 107, 768)     2068992     tf_op_layer_concat_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 107, 768)     2068992     tf_op_layer_concat_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_22 (Bidirectional (None, 107, 768)     2658816     bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 107, 768)     2658816     bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_23 (Bidirectional (None, 107, 768)     2658816     bidirectional_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 107, 768)     2658816     bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_3 (Attention)         (None, 107, 768)     0           bidirectional_20[0][0]           \n",
      "                                                                 bidirectional_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 107, 1536)    0           bidirectional_23[0][0]           \n",
      "                                                                 attention_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 107, 768)     1180416     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 68, 768)]    0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 68, 5)        3845        tf_op_layer_strided_slice_3[0][0]\n",
      "==================================================================================================\n",
      "Total params: 15,961,349\n",
      "Trainable params: 15,961,349\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 10s - loss: 0.2066 - val_loss: 0.1513\n",
      "Epoch 2/120\n",
      "53/53 - 8s - loss: 0.1378 - val_loss: 0.1235\n",
      "Epoch 3/120\n",
      "53/53 - 8s - loss: 0.1227 - val_loss: 0.1156\n",
      "Epoch 4/120\n",
      "53/53 - 7s - loss: 0.1145 - val_loss: 0.1113\n",
      "Epoch 5/120\n",
      "53/53 - 8s - loss: 0.1080 - val_loss: 0.1019\n",
      "Epoch 6/120\n",
      "53/53 - 8s - loss: 0.0983 - val_loss: 0.0950\n",
      "Epoch 7/120\n",
      "53/53 - 8s - loss: 0.0917 - val_loss: 0.0840\n",
      "Epoch 8/120\n",
      "53/53 - 8s - loss: 0.0833 - val_loss: 0.0795\n",
      "Epoch 9/120\n",
      "53/53 - 8s - loss: 0.0794 - val_loss: 0.0764\n",
      "Epoch 10/120\n",
      "53/53 - 7s - loss: 0.0754 - val_loss: 0.0724\n",
      "Epoch 11/120\n",
      "53/53 - 8s - loss: 0.0697 - val_loss: 0.0716\n",
      "Epoch 12/120\n",
      "53/53 - 8s - loss: 0.0665 - val_loss: 0.0692\n",
      "Epoch 13/120\n",
      "53/53 - 8s - loss: 0.0648 - val_loss: 0.0674\n",
      "Epoch 14/120\n",
      "53/53 - 8s - loss: 0.0613 - val_loss: 0.0668\n",
      "Epoch 15/120\n",
      "53/53 - 8s - loss: 0.0586 - val_loss: 0.0673\n",
      "Epoch 16/120\n",
      "53/53 - 7s - loss: 0.0558 - val_loss: 0.0679\n",
      "Epoch 17/120\n",
      "53/53 - 8s - loss: 0.0525 - val_loss: 0.0657\n",
      "Epoch 18/120\n",
      "53/53 - 8s - loss: 0.0499 - val_loss: 0.0628\n",
      "Epoch 19/120\n",
      "53/53 - 8s - loss: 0.0463 - val_loss: 0.0613\n",
      "Epoch 20/120\n",
      "53/53 - 7s - loss: 0.0440 - val_loss: 0.0615\n",
      "Epoch 21/120\n",
      "53/53 - 8s - loss: 0.0419 - val_loss: 0.0613\n",
      "Epoch 22/120\n",
      "53/53 - 8s - loss: 0.0397 - val_loss: 0.0614\n",
      "Epoch 23/120\n",
      "53/53 - 8s - loss: 0.0371 - val_loss: 0.0604\n",
      "Epoch 24/120\n",
      "53/53 - 8s - loss: 0.0354 - val_loss: 0.0604\n",
      "Epoch 25/120\n",
      "53/53 - 8s - loss: 0.0345 - val_loss: 0.0610\n",
      "Epoch 26/120\n",
      "53/53 - 7s - loss: 0.0332 - val_loss: 0.0609\n",
      "Epoch 27/120\n",
      "53/53 - 7s - loss: 0.0324 - val_loss: 0.0609\n",
      "Epoch 28/120\n",
      "53/53 - 8s - loss: 0.0310 - val_loss: 0.0611\n",
      "Epoch 29/120\n",
      "53/53 - 8s - loss: 0.0293 - val_loss: 0.0615\n",
      "Epoch 30/120\n",
      "53/53 - 8s - loss: 0.0282 - val_loss: 0.0617\n",
      "Epoch 31/120\n",
      "53/53 - 8s - loss: 0.0278 - val_loss: 0.0611\n",
      "Epoch 32/120\n",
      "53/53 - 7s - loss: 0.0270 - val_loss: 0.0614\n",
      "Epoch 33/120\n",
      "53/53 - 8s - loss: 0.0259 - val_loss: 0.0602\n",
      "Epoch 34/120\n",
      "53/53 - 8s - loss: 0.0241 - val_loss: 0.0604\n",
      "Epoch 35/120\n",
      "53/53 - 8s - loss: 0.0235 - val_loss: 0.0602\n",
      "Epoch 36/120\n",
      "53/53 - 8s - loss: 0.0228 - val_loss: 0.0609\n",
      "Epoch 37/120\n",
      "53/53 - 8s - loss: 0.0222 - val_loss: 0.0607\n",
      "Epoch 38/120\n",
      "53/53 - 7s - loss: 0.0215 - val_loss: 0.0605\n",
      "Epoch 39/120\n",
      "53/53 - 8s - loss: 0.0218 - val_loss: 0.0622\n",
      "Epoch 40/120\n",
      "53/53 - 8s - loss: 0.0214 - val_loss: 0.0604\n",
      "Epoch 41/120\n",
      "53/53 - 8s - loss: 0.0202 - val_loss: 0.0604\n",
      "Epoch 42/120\n",
      "53/53 - 8s - loss: 0.0194 - val_loss: 0.0603\n",
      "Epoch 43/120\n",
      "53/53 - 7s - loss: 0.0186 - val_loss: 0.0601\n",
      "Epoch 44/120\n",
      "53/53 - 8s - loss: 0.0168 - val_loss: 0.0589\n",
      "Epoch 45/120\n",
      "53/53 - 7s - loss: 0.0157 - val_loss: 0.0590\n",
      "Epoch 46/120\n",
      "53/53 - 8s - loss: 0.0152 - val_loss: 0.0589\n",
      "Epoch 47/120\n",
      "53/53 - 8s - loss: 0.0150 - val_loss: 0.0590\n",
      "Epoch 48/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0589\n",
      "Epoch 49/120\n",
      "53/53 - 7s - loss: 0.0145 - val_loss: 0.0590\n",
      "Epoch 50/120\n",
      "53/53 - 8s - loss: 0.0144 - val_loss: 0.0590\n",
      "Epoch 51/120\n",
      "53/53 - 7s - loss: 0.0143 - val_loss: 0.0591\n",
      "Epoch 52/120\n",
      "53/53 - 8s - loss: 0.0141 - val_loss: 0.0590\n",
      "Epoch 53/120\n",
      "53/53 - 7s - loss: 0.0140 - val_loss: 0.0591\n",
      "Epoch 54/120\n",
      "53/53 - 7s - loss: 0.0139 - val_loss: 0.0591\n",
      "Epoch 55/120\n",
      "53/53 - 7s - loss: 0.0138 - val_loss: 0.0591\n",
      "Epoch 56/120\n",
      "53/53 - 8s - loss: 0.0138 - val_loss: 0.0591\n",
      "Epoch 57/120\n",
      "53/53 - 7s - loss: 0.0137 - val_loss: 0.0591\n",
      "Epoch 58/120\n",
      "53/53 - 8s - loss: 0.0137 - val_loss: 0.0591\n",
      "Epoch 59/120\n",
      "53/53 - 8s - loss: 0.0137 - val_loss: 0.0591\n",
      "Epoch 60/120\n",
      "53/53 - 8s - loss: 0.0137 - val_loss: 0.0591\n",
      "Epoch 61/120\n",
      "53/53 - 8s - loss: 0.0137 - val_loss: 0.0591\n",
      "Epoch 62/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 63/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 64/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 65/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 66/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 67/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 68/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 69/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 70/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 71/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 72/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 73/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 74/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 75/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 76/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 77/120\n",
      "53/53 - 8s - loss: 0.0135 - val_loss: 0.0591\n",
      "Epoch 78/120\n",
      "53/53 - 8s - loss: 0.0135 - val_loss: 0.0591\n",
      "Epoch 79/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 80/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 81/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 82/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 83/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 84/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 85/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 86/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 87/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 88/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 89/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 90/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 91/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 92/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 93/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 94/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 95/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 96/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 97/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 98/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 99/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 100/120\n",
      "53/53 - 9s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 101/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 102/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 103/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 104/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 105/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 106/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 107/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 108/120\n",
      "53/53 - 8s - loss: 0.0135 - val_loss: 0.0591\n",
      "Epoch 109/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 110/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 111/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 112/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 113/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 114/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 115/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 116/120\n",
      "53/53 - 7s - loss: 0.0135 - val_loss: 0.0591\n",
      "Epoch 117/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 118/120\n",
      "53/53 - 7s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 119/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "Epoch 120/120\n",
      "53/53 - 8s - loss: 0.0136 - val_loss: 0.0591\n",
      "#################### 0.37769436824020075\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 107, 3, 128)  1792        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 107, 3, 128)  1792        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_13 (TensorF [(None, 107, 384)]   0           embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_12 (TensorF [(None, 107, 384)]   0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_13 (SpatialDr (None, 107, 384)     0           tf_op_layer_Reshape_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 107, 128)     256         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 107, 384)     0           tf_op_layer_Reshape_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_13 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_13[0][0]       \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_12 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_12[0][0]       \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_39 (Bidirectional (None, 107, 768)     2068992     tf_op_layer_concat_13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 107, 768)     2068992     tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_40 (Bidirectional (None, 107, 768)     2658816     bidirectional_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 107, 768)     2658816     bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_41 (Bidirectional (None, 107, 768)     2658816     bidirectional_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_38 (Bidirectional (None, 107, 768)     2658816     bidirectional_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_6 (Attention)         (None, 107, 768)     0           bidirectional_38[0][0]           \n",
      "                                                                 bidirectional_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 107, 1536)    0           bidirectional_41[0][0]           \n",
      "                                                                 attention_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 107, 768)     1180416     concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 68, 768)]    0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 68, 5)        3845        tf_op_layer_strided_slice_6[0][0]\n",
      "==================================================================================================\n",
      "Total params: 15,961,349\n",
      "Trainable params: 15,961,349\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 10s - loss: 0.2212 - val_loss: 0.1590\n",
      "Epoch 2/120\n",
      "53/53 - 8s - loss: 0.1421 - val_loss: 0.1284\n",
      "Epoch 3/120\n",
      "53/53 - 8s - loss: 0.1228 - val_loss: 0.1175\n",
      "Epoch 4/120\n",
      "53/53 - 8s - loss: 0.1142 - val_loss: 0.1148\n",
      "Epoch 5/120\n",
      "53/53 - 7s - loss: 0.1051 - val_loss: 0.0986\n",
      "Epoch 6/120\n",
      "53/53 - 8s - loss: 0.0940 - val_loss: 0.0910\n",
      "Epoch 7/120\n",
      "53/53 - 9s - loss: 0.0871 - val_loss: 0.0853\n",
      "Epoch 8/120\n",
      "53/53 - 7s - loss: 0.0817 - val_loss: 0.0820\n",
      "Epoch 9/120\n",
      "53/53 - 7s - loss: 0.0778 - val_loss: 0.0816\n",
      "Epoch 10/120\n",
      "53/53 - 7s - loss: 0.0741 - val_loss: 0.0772\n",
      "Epoch 11/120\n",
      "53/53 - 7s - loss: 0.0701 - val_loss: 0.0774\n",
      "Epoch 12/120\n",
      "53/53 - 7s - loss: 0.0663 - val_loss: 0.0726\n",
      "Epoch 13/120\n",
      "53/53 - 7s - loss: 0.0632 - val_loss: 0.0736\n",
      "Epoch 14/120\n",
      "53/53 - 7s - loss: 0.0618 - val_loss: 0.0722\n",
      "Epoch 15/120\n",
      "53/53 - 8s - loss: 0.0602 - val_loss: 0.0722\n",
      "Epoch 16/120\n",
      "53/53 - 8s - loss: 0.0587 - val_loss: 0.0699\n",
      "Epoch 17/120\n",
      "53/53 - 7s - loss: 0.0541 - val_loss: 0.0700\n",
      "Epoch 18/120\n",
      "53/53 - 8s - loss: 0.0515 - val_loss: 0.0689\n",
      "Epoch 19/120\n",
      "53/53 - 8s - loss: 0.0494 - val_loss: 0.0688\n",
      "Epoch 20/120\n",
      "53/53 - 8s - loss: 0.0486 - val_loss: 0.0668\n",
      "Epoch 21/120\n",
      "53/53 - 8s - loss: 0.0463 - val_loss: 0.0673\n",
      "Epoch 22/120\n",
      "53/53 - 8s - loss: 0.0445 - val_loss: 0.0670\n",
      "Epoch 23/120\n",
      "53/53 - 7s - loss: 0.0432 - val_loss: 0.0659\n",
      "Epoch 24/120\n",
      "53/53 - 8s - loss: 0.0424 - val_loss: 0.0671\n",
      "Epoch 25/120\n",
      "53/53 - 8s - loss: 0.0416 - val_loss: 0.0672\n",
      "Epoch 26/120\n",
      "53/53 - 7s - loss: 0.0395 - val_loss: 0.0664\n",
      "Epoch 27/120\n",
      "53/53 - 7s - loss: 0.0388 - val_loss: 0.0656\n",
      "Epoch 28/120\n",
      "53/53 - 7s - loss: 0.0376 - val_loss: 0.0673\n",
      "Epoch 29/120\n",
      "53/53 - 8s - loss: 0.0358 - val_loss: 0.0662\n",
      "Epoch 30/120\n",
      "53/53 - 7s - loss: 0.0347 - val_loss: 0.0658\n",
      "Epoch 31/120\n",
      "53/53 - 8s - loss: 0.0340 - val_loss: 0.0660\n",
      "Epoch 32/120\n",
      "53/53 - 8s - loss: 0.0326 - val_loss: 0.0668\n",
      "Epoch 33/120\n",
      "53/53 - 8s - loss: 0.0328 - val_loss: 0.0668\n",
      "Epoch 34/120\n",
      "53/53 - 7s - loss: 0.0319 - val_loss: 0.0662\n",
      "Epoch 35/120\n",
      "53/53 - 7s - loss: 0.0307 - val_loss: 0.0653\n",
      "Epoch 36/120\n",
      "53/53 - 8s - loss: 0.0288 - val_loss: 0.0660\n",
      "Epoch 37/120\n",
      "53/53 - 8s - loss: 0.0293 - val_loss: 0.0674\n",
      "Epoch 38/120\n",
      "53/53 - 8s - loss: 0.0308 - val_loss: 0.0658\n",
      "Epoch 39/120\n",
      "53/53 - 7s - loss: 0.0298 - val_loss: 0.0675\n",
      "Epoch 40/120\n",
      "53/53 - 8s - loss: 0.0289 - val_loss: 0.0659\n",
      "Epoch 41/120\n",
      "53/53 - 8s - loss: 0.0268 - val_loss: 0.0649\n",
      "Epoch 42/120\n",
      "53/53 - 8s - loss: 0.0256 - val_loss: 0.0658\n",
      "Epoch 43/120\n",
      "53/53 - 8s - loss: 0.0251 - val_loss: 0.0667\n",
      "Epoch 44/120\n",
      "53/53 - 8s - loss: 0.0253 - val_loss: 0.0666\n",
      "Epoch 45/120\n",
      "53/53 - 7s - loss: 0.0263 - val_loss: 0.0674\n",
      "Epoch 46/120\n",
      "53/53 - 7s - loss: 0.0256 - val_loss: 0.0666\n",
      "Epoch 47/120\n",
      "53/53 - 8s - loss: 0.0244 - val_loss: 0.0661\n",
      "Epoch 48/120\n",
      "53/53 - 8s - loss: 0.0234 - val_loss: 0.0662\n",
      "Epoch 49/120\n",
      "53/53 - 8s - loss: 0.0222 - val_loss: 0.0651\n",
      "Epoch 50/120\n",
      "53/53 - 8s - loss: 0.0218 - val_loss: 0.0659\n",
      "Epoch 51/120\n",
      "53/53 - 7s - loss: 0.0208 - val_loss: 0.0655\n",
      "Epoch 52/120\n",
      "53/53 - 7s - loss: 0.0184 - val_loss: 0.0642\n",
      "Epoch 53/120\n",
      "53/53 - 7s - loss: 0.0173 - val_loss: 0.0641\n",
      "Epoch 54/120\n",
      "53/53 - 7s - loss: 0.0168 - val_loss: 0.0641\n",
      "Epoch 55/120\n",
      "53/53 - 7s - loss: 0.0165 - val_loss: 0.0642\n",
      "Epoch 56/120\n",
      "53/53 - 7s - loss: 0.0163 - val_loss: 0.0642\n",
      "Epoch 57/120\n",
      "53/53 - 7s - loss: 0.0160 - val_loss: 0.0643\n",
      "Epoch 58/120\n",
      "53/53 - 7s - loss: 0.0159 - val_loss: 0.0643\n",
      "Epoch 59/120\n",
      "53/53 - 7s - loss: 0.0157 - val_loss: 0.0643\n",
      "Epoch 60/120\n",
      "53/53 - 7s - loss: 0.0155 - val_loss: 0.0646\n",
      "Epoch 61/120\n",
      "53/53 - 7s - loss: 0.0154 - val_loss: 0.0645\n",
      "Epoch 62/120\n",
      "53/53 - 7s - loss: 0.0153 - val_loss: 0.0644\n",
      "Epoch 63/120\n",
      "53/53 - 7s - loss: 0.0152 - val_loss: 0.0645\n",
      "Epoch 64/120\n",
      "53/53 - 7s - loss: 0.0150 - val_loss: 0.0645\n",
      "Epoch 65/120\n",
      "53/53 - 7s - loss: 0.0148 - val_loss: 0.0645\n",
      "Epoch 66/120\n",
      "53/53 - 7s - loss: 0.0148 - val_loss: 0.0645\n",
      "Epoch 67/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0646\n",
      "Epoch 68/120\n",
      "53/53 - 7s - loss: 0.0148 - val_loss: 0.0646\n",
      "Epoch 69/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0645\n",
      "Epoch 70/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0645\n",
      "Epoch 71/120\n",
      "53/53 - 8s - loss: 0.0147 - val_loss: 0.0645\n",
      "Epoch 72/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0646\n",
      "Epoch 73/120\n",
      "53/53 - 8s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 74/120\n",
      "53/53 - 7s - loss: 0.0147 - val_loss: 0.0646\n",
      "Epoch 75/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 76/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 77/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 78/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 79/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 80/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 81/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 82/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 83/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 84/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 85/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 86/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 87/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 88/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 89/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 90/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 91/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 92/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 93/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 94/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 95/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 96/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 97/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 98/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 99/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 100/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 101/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 102/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 103/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 104/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 105/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 106/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 107/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 108/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 109/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 110/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 111/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 112/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 113/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 114/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 115/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 116/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 117/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 118/120\n",
      "53/53 - 6s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 119/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "Epoch 120/120\n",
      "53/53 - 7s - loss: 0.0146 - val_loss: 0.0646\n",
      "#################### 0.3860202801895579\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_19 (Embedding)        (None, 107, 3, 128)  1792        input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_18 (Embedding)        (None, 107, 3, 128)  1792        input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_19 (TensorF [(None, 107, 384)]   0           embedding_19[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_18 (TensorF [(None, 107, 384)]   0           embedding_18[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_19 (SpatialDr (None, 107, 384)     0           tf_op_layer_Reshape_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 107, 128)     256         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_18 (SpatialDr (None, 107, 384)     0           tf_op_layer_Reshape_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_19 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_19[0][0]       \n",
      "                                                                 dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_18 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_18[0][0]       \n",
      "                                                                 dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_57 (Bidirectional (None, 107, 768)     2068992     tf_op_layer_concat_19[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_54 (Bidirectional (None, 107, 768)     2068992     tf_op_layer_concat_18[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_58 (Bidirectional (None, 107, 768)     2658816     bidirectional_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_55 (Bidirectional (None, 107, 768)     2658816     bidirectional_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_59 (Bidirectional (None, 107, 768)     2658816     bidirectional_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_56 (Bidirectional (None, 107, 768)     2658816     bidirectional_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_9 (Attention)         (None, 107, 768)     0           bidirectional_56[0][0]           \n",
      "                                                                 bidirectional_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 107, 1536)    0           bidirectional_59[0][0]           \n",
      "                                                                 attention_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 107, 768)     1180416     concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None, 68, 768)]    0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 68, 5)        3845        tf_op_layer_strided_slice_9[0][0]\n",
      "==================================================================================================\n",
      "Total params: 15,961,349\n",
      "Trainable params: 15,961,349\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 9s - loss: 0.2904 - val_loss: 0.1604\n",
      "Epoch 2/120\n",
      "53/53 - 6s - loss: 0.1487 - val_loss: 0.1285\n",
      "Epoch 3/120\n",
      "53/53 - 6s - loss: 0.1235 - val_loss: 0.1155\n",
      "Epoch 4/120\n",
      "53/53 - 6s - loss: 0.1123 - val_loss: 0.1084\n",
      "Epoch 5/120\n",
      "53/53 - 7s - loss: 0.1070 - val_loss: 0.1045\n",
      "Epoch 6/120\n",
      "53/53 - 6s - loss: 0.1011 - val_loss: 0.1008\n",
      "Epoch 7/120\n",
      "53/53 - 7s - loss: 0.0938 - val_loss: 0.0932\n",
      "Epoch 8/120\n",
      "53/53 - 6s - loss: 0.0877 - val_loss: 0.0875\n",
      "Epoch 9/120\n",
      "53/53 - 7s - loss: 0.0831 - val_loss: 0.0813\n",
      "Epoch 10/120\n",
      "53/53 - 6s - loss: 0.0788 - val_loss: 0.0795\n",
      "Epoch 11/120\n",
      "53/53 - 7s - loss: 0.0751 - val_loss: 0.0776\n",
      "Epoch 12/120\n",
      "53/53 - 7s - loss: 0.0712 - val_loss: 0.0732\n",
      "Epoch 13/120\n",
      "53/53 - 7s - loss: 0.0676 - val_loss: 0.0728\n",
      "Epoch 14/120\n",
      "53/53 - 7s - loss: 0.0648 - val_loss: 0.0703\n",
      "Epoch 15/120\n",
      "53/53 - 7s - loss: 0.0622 - val_loss: 0.0695\n",
      "Epoch 16/120\n",
      "53/53 - 7s - loss: 0.0595 - val_loss: 0.0705\n",
      "Epoch 17/120\n",
      "53/53 - 7s - loss: 0.0563 - val_loss: 0.0686\n",
      "Epoch 18/120\n",
      "53/53 - 7s - loss: 0.0539 - val_loss: 0.0692\n",
      "Epoch 19/120\n",
      "53/53 - 7s - loss: 0.0516 - val_loss: 0.0670\n",
      "Epoch 20/120\n",
      "53/53 - 6s - loss: 0.0493 - val_loss: 0.0653\n",
      "Epoch 21/120\n",
      "53/53 - 6s - loss: 0.0477 - val_loss: 0.0653\n",
      "Epoch 22/120\n",
      "53/53 - 6s - loss: 0.0461 - val_loss: 0.0647\n",
      "Epoch 23/120\n",
      "53/53 - 7s - loss: 0.0445 - val_loss: 0.0651\n",
      "Epoch 24/120\n",
      "53/53 - 7s - loss: 0.0430 - val_loss: 0.0662\n",
      "Epoch 25/120\n",
      "53/53 - 7s - loss: 0.0415 - val_loss: 0.0652\n",
      "Epoch 26/120\n",
      "53/53 - 7s - loss: 0.0397 - val_loss: 0.0637\n",
      "Epoch 27/120\n",
      "53/53 - 7s - loss: 0.0382 - val_loss: 0.0639\n",
      "Epoch 28/120\n",
      "53/53 - 7s - loss: 0.0380 - val_loss: 0.0635\n",
      "Epoch 29/120\n",
      "53/53 - 7s - loss: 0.0367 - val_loss: 0.0635\n",
      "Epoch 30/120\n",
      "53/53 - 7s - loss: 0.0365 - val_loss: 0.0647\n",
      "Epoch 31/120\n",
      "53/53 - 7s - loss: 0.0357 - val_loss: 0.0639\n",
      "Epoch 32/120\n",
      "53/53 - 7s - loss: 0.0363 - val_loss: 0.0649\n",
      "Epoch 33/120\n",
      "53/53 - 6s - loss: 0.0370 - val_loss: 0.0637\n",
      "Epoch 34/120\n",
      "53/53 - 7s - loss: 0.0349 - val_loss: 0.0649\n",
      "Epoch 35/120\n",
      "53/53 - 7s - loss: 0.0330 - val_loss: 0.0638\n",
      "Epoch 36/120\n",
      "53/53 - 7s - loss: 0.0318 - val_loss: 0.0638\n",
      "Epoch 37/120\n",
      "53/53 - 7s - loss: 0.0314 - val_loss: 0.0637\n",
      "Epoch 38/120\n",
      "53/53 - 6s - loss: 0.0311 - val_loss: 0.0638\n",
      "Epoch 39/120\n",
      "53/53 - 7s - loss: 0.0282 - val_loss: 0.0622\n",
      "Epoch 40/120\n",
      "53/53 - 7s - loss: 0.0269 - val_loss: 0.0619\n",
      "Epoch 41/120\n",
      "53/53 - 7s - loss: 0.0264 - val_loss: 0.0616\n",
      "Epoch 42/120\n",
      "53/53 - 7s - loss: 0.0260 - val_loss: 0.0618\n",
      "Epoch 43/120\n",
      "53/53 - 7s - loss: 0.0257 - val_loss: 0.0618\n",
      "Epoch 44/120\n",
      "53/53 - 7s - loss: 0.0255 - val_loss: 0.0616\n",
      "Epoch 45/120\n",
      "53/53 - 7s - loss: 0.0253 - val_loss: 0.0618\n",
      "Epoch 46/120\n",
      "53/53 - 7s - loss: 0.0251 - val_loss: 0.0617\n",
      "Epoch 47/120\n",
      "53/53 - 7s - loss: 0.0249 - val_loss: 0.0618\n",
      "Epoch 48/120\n",
      "53/53 - 7s - loss: 0.0246 - val_loss: 0.0620\n",
      "Epoch 49/120\n",
      "53/53 - 7s - loss: 0.0245 - val_loss: 0.0619\n",
      "Epoch 50/120\n",
      "53/53 - 7s - loss: 0.0244 - val_loss: 0.0619\n",
      "Epoch 51/120\n",
      "53/53 - 7s - loss: 0.0242 - val_loss: 0.0617\n",
      "Epoch 52/120\n",
      "53/53 - 7s - loss: 0.0240 - val_loss: 0.0618\n",
      "Epoch 53/120\n",
      "53/53 - 7s - loss: 0.0240 - val_loss: 0.0618\n",
      "Epoch 54/120\n",
      "53/53 - 7s - loss: 0.0238 - val_loss: 0.0618\n",
      "Epoch 55/120\n",
      "53/53 - 7s - loss: 0.0238 - val_loss: 0.0618\n",
      "Epoch 56/120\n",
      "53/53 - 7s - loss: 0.0238 - val_loss: 0.0618\n",
      "Epoch 57/120\n",
      "53/53 - 7s - loss: 0.0238 - val_loss: 0.0618\n",
      "Epoch 58/120\n",
      "53/53 - 7s - loss: 0.0238 - val_loss: 0.0618\n",
      "Epoch 59/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 60/120\n",
      "53/53 - 7s - loss: 0.0238 - val_loss: 0.0618\n",
      "Epoch 61/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 62/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 63/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 64/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 65/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 66/120\n",
      "53/53 - 6s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 67/120\n",
      "53/53 - 6s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 68/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 69/120\n",
      "53/53 - 6s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 70/120\n",
      "53/53 - 6s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 71/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 72/120\n",
      "53/53 - 6s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 73/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 74/120\n",
      "53/53 - 6s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 75/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 76/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 77/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 78/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 79/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 80/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 81/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 82/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 83/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 84/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 85/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 86/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 87/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 88/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 89/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 90/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 91/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 92/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 93/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 94/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 95/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 96/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 97/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 98/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 99/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 100/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 101/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 102/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 103/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 104/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 105/120\n",
      "53/53 - 6s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 106/120\n",
      "53/53 - 6s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 107/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 108/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 109/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 110/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 111/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 112/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 113/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 114/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 115/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 116/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 117/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 118/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "Epoch 119/120\n",
      "53/53 - 7s - loss: 0.0236 - val_loss: 0.0618\n",
      "Epoch 120/120\n",
      "53/53 - 7s - loss: 0.0237 - val_loss: 0.0618\n",
      "#################### 0.3651146861944036\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 107, 3, 128)  1792        input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 107, 3, 128)  1792        input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_25 (TensorF [(None, 107, 384)]   0           embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_24 (TensorF [(None, 107, 384)]   0           embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 107, 384)     0           tf_op_layer_Reshape_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 107, 128)     256         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 107, 384)     0           tf_op_layer_Reshape_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_25 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_25[0][0]       \n",
      "                                                                 dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_24 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_24[0][0]       \n",
      "                                                                 dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_75 (Bidirectional (None, 107, 768)     2068992     tf_op_layer_concat_25[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_72 (Bidirectional (None, 107, 768)     2068992     tf_op_layer_concat_24[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_76 (Bidirectional (None, 107, 768)     2658816     bidirectional_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_73 (Bidirectional (None, 107, 768)     2658816     bidirectional_72[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_77 (Bidirectional (None, 107, 768)     2658816     bidirectional_76[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_74 (Bidirectional (None, 107, 768)     2658816     bidirectional_73[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "attention_12 (Attention)        (None, 107, 768)     0           bidirectional_74[0][0]           \n",
      "                                                                 bidirectional_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 107, 1536)    0           bidirectional_77[0][0]           \n",
      "                                                                 attention_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 107, 768)     1180416     concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 68, 768)]    0           dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 68, 5)        3845        tf_op_layer_strided_slice_12[0][0\n",
      "==================================================================================================\n",
      "Total params: 15,961,349\n",
      "Trainable params: 15,961,349\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 9s - loss: 0.2692 - val_loss: 0.1601\n",
      "Epoch 2/120\n",
      "53/53 - 7s - loss: 0.1459 - val_loss: 0.1313\n",
      "Epoch 3/120\n",
      "53/53 - 6s - loss: 0.1230 - val_loss: 0.1220\n",
      "Epoch 4/120\n",
      "53/53 - 7s - loss: 0.1125 - val_loss: 0.1126\n",
      "Epoch 5/120\n",
      "53/53 - 7s - loss: 0.1054 - val_loss: 0.1042\n",
      "Epoch 6/120\n",
      "53/53 - 7s - loss: 0.1001 - val_loss: 0.1042\n",
      "Epoch 7/120\n",
      "53/53 - 7s - loss: 0.0942 - val_loss: 0.0901\n",
      "Epoch 8/120\n",
      "53/53 - 6s - loss: 0.0863 - val_loss: 0.0833\n",
      "Epoch 9/120\n",
      "53/53 - 7s - loss: 0.0812 - val_loss: 0.0835\n",
      "Epoch 10/120\n",
      "53/53 - 6s - loss: 0.0780 - val_loss: 0.0779\n",
      "Epoch 11/120\n",
      "53/53 - 6s - loss: 0.0737 - val_loss: 0.0753\n",
      "Epoch 12/120\n",
      "53/53 - 6s - loss: 0.0707 - val_loss: 0.0774\n",
      "Epoch 13/120\n",
      "53/53 - 6s - loss: 0.0674 - val_loss: 0.0728\n",
      "Epoch 14/120\n",
      "53/53 - 7s - loss: 0.0665 - val_loss: 0.0712\n",
      "Epoch 15/120\n",
      "53/53 - 7s - loss: 0.0618 - val_loss: 0.0682\n",
      "Epoch 16/120\n",
      "53/53 - 6s - loss: 0.0589 - val_loss: 0.0692\n",
      "Epoch 17/120\n",
      "53/53 - 6s - loss: 0.0567 - val_loss: 0.0685\n",
      "Epoch 18/120\n",
      "53/53 - 7s - loss: 0.0542 - val_loss: 0.0684\n",
      "Epoch 19/120\n",
      "53/53 - 7s - loss: 0.0513 - val_loss: 0.0659\n",
      "Epoch 20/120\n",
      "53/53 - 6s - loss: 0.0497 - val_loss: 0.0648\n",
      "Epoch 21/120\n",
      "53/53 - 7s - loss: 0.0473 - val_loss: 0.0648\n",
      "Epoch 22/120\n",
      "53/53 - 7s - loss: 0.0465 - val_loss: 0.0655\n",
      "Epoch 23/120\n",
      "53/53 - 7s - loss: 0.0450 - val_loss: 0.0641\n",
      "Epoch 24/120\n",
      "53/53 - 7s - loss: 0.0422 - val_loss: 0.0651\n",
      "Epoch 25/120\n",
      "53/53 - 7s - loss: 0.0413 - val_loss: 0.0650\n",
      "Epoch 26/120\n",
      "53/53 - 7s - loss: 0.0405 - val_loss: 0.0652\n",
      "Epoch 27/120\n",
      "53/53 - 6s - loss: 0.0398 - val_loss: 0.0654\n",
      "Epoch 28/120\n",
      "53/53 - 6s - loss: 0.0383 - val_loss: 0.0629\n",
      "Epoch 29/120\n",
      "53/53 - 7s - loss: 0.0364 - val_loss: 0.0630\n",
      "Epoch 30/120\n",
      "53/53 - 7s - loss: 0.0360 - val_loss: 0.0638\n",
      "Epoch 31/120\n",
      "53/53 - 7s - loss: 0.0345 - val_loss: 0.0625\n",
      "Epoch 32/120\n",
      "53/53 - 7s - loss: 0.0332 - val_loss: 0.0620\n",
      "Epoch 33/120\n",
      "53/53 - 6s - loss: 0.0326 - val_loss: 0.0624\n",
      "Epoch 34/120\n",
      "53/53 - 7s - loss: 0.0318 - val_loss: 0.0635\n",
      "Epoch 35/120\n",
      "53/53 - 7s - loss: 0.0315 - val_loss: 0.0632\n",
      "Epoch 36/120\n",
      "53/53 - 6s - loss: 0.0309 - val_loss: 0.0619\n",
      "Epoch 37/120\n",
      "53/53 - 6s - loss: 0.0299 - val_loss: 0.0623\n",
      "Epoch 38/120\n",
      "53/53 - 7s - loss: 0.0292 - val_loss: 0.0623\n",
      "Epoch 39/120\n",
      "53/53 - 7s - loss: 0.0295 - val_loss: 0.0625\n",
      "Epoch 40/120\n",
      "53/53 - 7s - loss: 0.0294 - val_loss: 0.0625\n",
      "Epoch 41/120\n",
      "53/53 - 7s - loss: 0.0283 - val_loss: 0.0615\n",
      "Epoch 42/120\n",
      "53/53 - 7s - loss: 0.0274 - val_loss: 0.0621\n",
      "Epoch 43/120\n",
      "53/53 - 6s - loss: 0.0266 - val_loss: 0.0618\n",
      "Epoch 44/120\n",
      "53/53 - 7s - loss: 0.0260 - val_loss: 0.0617\n",
      "Epoch 45/120\n",
      "53/53 - 7s - loss: 0.0256 - val_loss: 0.0628\n",
      "Epoch 46/120\n",
      "53/53 - 6s - loss: 0.0261 - val_loss: 0.0648\n",
      "Epoch 47/120\n",
      "53/53 - 7s - loss: 0.0287 - val_loss: 0.0631\n",
      "Epoch 48/120\n",
      "53/53 - 6s - loss: 0.0271 - val_loss: 0.0628\n",
      "Epoch 49/120\n",
      "53/53 - 6s - loss: 0.0267 - val_loss: 0.0621\n",
      "Epoch 50/120\n",
      "53/53 - 6s - loss: 0.0249 - val_loss: 0.0619\n",
      "Epoch 51/120\n",
      "53/53 - 7s - loss: 0.0241 - val_loss: 0.0627\n",
      "Epoch 52/120\n",
      "53/53 - 7s - loss: 0.0223 - val_loss: 0.0607\n",
      "Epoch 53/120\n",
      "53/53 - 7s - loss: 0.0210 - val_loss: 0.0603\n",
      "Epoch 54/120\n",
      "53/53 - 6s - loss: 0.0204 - val_loss: 0.0602\n",
      "Epoch 55/120\n",
      "53/53 - 7s - loss: 0.0201 - val_loss: 0.0603\n",
      "Epoch 56/120\n",
      "53/53 - 7s - loss: 0.0198 - val_loss: 0.0603\n",
      "Epoch 57/120\n",
      "53/53 - 7s - loss: 0.0196 - val_loss: 0.0603\n",
      "Epoch 58/120\n",
      "53/53 - 7s - loss: 0.0194 - val_loss: 0.0602\n",
      "Epoch 59/120\n",
      "53/53 - 7s - loss: 0.0193 - val_loss: 0.0604\n",
      "Epoch 60/120\n",
      "53/53 - 7s - loss: 0.0191 - val_loss: 0.0603\n",
      "Epoch 61/120\n",
      "53/53 - 7s - loss: 0.0190 - val_loss: 0.0603\n",
      "Epoch 62/120\n",
      "53/53 - 7s - loss: 0.0189 - val_loss: 0.0604\n",
      "Epoch 63/120\n",
      "53/53 - 7s - loss: 0.0187 - val_loss: 0.0604\n",
      "Epoch 64/120\n",
      "53/53 - 7s - loss: 0.0186 - val_loss: 0.0602\n",
      "Epoch 65/120\n",
      "53/53 - 7s - loss: 0.0184 - val_loss: 0.0602\n",
      "Epoch 66/120\n",
      "53/53 - 7s - loss: 0.0183 - val_loss: 0.0603\n",
      "Epoch 67/120\n",
      "53/53 - 7s - loss: 0.0183 - val_loss: 0.0603\n",
      "Epoch 68/120\n",
      "53/53 - 7s - loss: 0.0183 - val_loss: 0.0603\n",
      "Epoch 69/120\n",
      "53/53 - 7s - loss: 0.0183 - val_loss: 0.0603\n",
      "Epoch 70/120\n",
      "53/53 - 7s - loss: 0.0183 - val_loss: 0.0603\n",
      "Epoch 71/120\n",
      "53/53 - 7s - loss: 0.0183 - val_loss: 0.0603\n",
      "Epoch 72/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 73/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 74/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 75/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 76/120\n",
      "53/53 - 6s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 77/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 78/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 79/120\n",
      "53/53 - 6s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 80/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 81/120\n",
      "53/53 - 7s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 82/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 83/120\n",
      "53/53 - 6s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 84/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 85/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 86/120\n",
      "53/53 - 6s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 87/120\n",
      "53/53 - 6s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 88/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 89/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 90/120\n",
      "53/53 - 7s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 91/120\n",
      "53/53 - 7s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 92/120\n",
      "53/53 - 7s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 93/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 94/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 95/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 96/120\n",
      "53/53 - 7s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 97/120\n",
      "53/53 - 7s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 98/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 99/120\n",
      "53/53 - 7s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 100/120\n",
      "53/53 - 7s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 101/120\n",
      "53/53 - 6s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 102/120\n",
      "53/53 - 6s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 103/120\n",
      "53/53 - 6s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 104/120\n",
      "53/53 - 6s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 105/120\n",
      "53/53 - 6s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 106/120\n",
      "53/53 - 6s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 107/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 108/120\n",
      "53/53 - 7s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 109/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 110/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 111/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 112/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 113/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 114/120\n",
      "53/53 - 7s - loss: 0.0181 - val_loss: 0.0603\n",
      "Epoch 115/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 116/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 117/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 118/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 119/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "Epoch 120/120\n",
      "53/53 - 7s - loss: 0.0182 - val_loss: 0.0603\n",
      "#################### 0.37886624708200783\n",
      "(629, 107, 5) (3005, 130, 5)\n"
     ]
    }
   ],
   "source": [
    "FOLDS = KFold(n_splits=5, random_state=815, shuffle=True)\n",
    "\n",
    "oofs_pred = np.zeros_like(train_labels)\n",
    "public_preds_array = []\n",
    "public_preds_array = []\n",
    "\n",
    "for i, (trn_idx, vld_idx) in enumerate(FOLDS.split(train_inputs)):\n",
    "    trn_inputs = train_inputs[trn_idx]\n",
    "    vld_inputs = train_inputs[vld_idx]\n",
    "    \n",
    "    trn_inputs_bpps = train_bpps[trn_idx]\n",
    "    vld_inputs_bpps = train_bpps[vld_idx]\n",
    "\n",
    "    trn_labels = train_labels[trn_idx]\n",
    "    vld_labels = train_labels[vld_idx]\n",
    "\n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        [trn_inputs, trn_inputs_bpps], trn_labels, \n",
    "        validation_data=([vld_inputs, vld_inputs_bpps], vld_labels),\n",
    "        batch_size=32,\n",
    "        epochs=120,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "            tf.keras.callbacks.ModelCheckpoint('bpps_large_attention_relu_dense_815.h5')\n",
    "        ],\n",
    "        verbose=2,\n",
    "    )\n",
    "    model.load_weights('./bpps_large_attention_relu_dense_815.h5')\n",
    "    outputs = model.predict([vld_inputs, vld_inputs_bpps])\n",
    "    oofs_pred[vld_idx] = outputs\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    errors = []\n",
    "    for idx in range(5):\n",
    "         errors.append(np.sqrt(mean_squared_error(vld_labels[:, idx], outputs[:, idx])))\n",
    "    final_error = np.mean(errors)\n",
    "    print('#'*20, final_error)\n",
    "\n",
    "    public_df = test.query(\"seq_length == 107\").copy()\n",
    "    private_df = test.query(\"seq_length == 130\").copy()\n",
    "\n",
    "    public_inputs = preprocess_inputs(public_df)\n",
    "    private_inputs = preprocess_inputs(private_df)\n",
    "    \n",
    "    public_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in public_df['id']])\n",
    "    public_bpps = public_bpps[:, :, np.newaxis]\n",
    "    \n",
    "    private_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in private_df['id']])\n",
    "    private_bpps = private_bpps[:, :, np.newaxis] \n",
    "\n",
    "    # Caveat: The prediction format requires the output to be the same length as the input,\n",
    "    # although it's not the case for the training data.\n",
    "    model_short = build_model(seq_len=107, pred_len=107)\n",
    "    model_long = build_model(seq_len=130, pred_len=130)\n",
    "\n",
    "    model_short.load_weights('bpps_large_attention_relu_dense_815.h5')\n",
    "    model_long.load_weights('bpps_large_attention_relu_dense_815.h5')\n",
    "\n",
    "    public_preds = model_short.predict([public_inputs, public_bpps])\n",
    "    private_preds = model_long.predict([private_inputs,private_bpps])\n",
    "    \n",
    "    public_preds_array.append(public_preds)\n",
    "    public_preds_array.append(private_preds)\n",
    "\n",
    "    print(public_preds.shape, private_preds.shape)\n",
    "\n",
    "    preds_ls = []\n",
    "\n",
    "    for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
    "        for idx, uid in enumerate(df.id):\n",
    "            single_pred = preds[idx]\n",
    "\n",
    "            single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "            preds_ls.append(single_df)\n",
    "\n",
    "    preds_df = pd.concat(preds_ls)\n",
    "\n",
    "    submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "    submission.to_csv(f'submission_bpps_large_attention_relu_dense_815_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, uid in enumerate(train.id):\n",
    "#     single_pred = oofs_pred[i]\n",
    "\n",
    "#     oof_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "#     oof_df['id_seqpos'] = [f'{uid}_{x}' for x in range(oof_df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute 'roi_heads'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4d9071f78b6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Functional' object has no attribute 'roi_heads'"
     ]
    }
   ],
   "source": [
    "model.roi_heads.box_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyh",
   "language": "python",
   "name": "lyh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 161.997015,
   "end_time": "2020-09-12T05:49:46.470488",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-12T05:47:04.473473",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
