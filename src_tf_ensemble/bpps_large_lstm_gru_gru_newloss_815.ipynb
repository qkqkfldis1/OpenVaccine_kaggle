{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:08.823964Z",
     "iopub.status.busy": "2020-09-12T05:47:08.823205Z",
     "iopub.status.idle": "2020-09-12T05:47:15.758339Z",
     "shell.execute_reply": "2020-09-12T05:47:15.757303Z"
    },
    "papermill": {
     "duration": 6.954489,
     "end_time": "2020-09-12T05:47:15.758481",
     "exception": false,
     "start_time": "2020-09-12T05:47:08.803992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01294,
     "end_time": "2020-09-12T05:47:15.784990",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.772050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define helper functions and useful vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.817688Z",
     "iopub.status.busy": "2020-09-12T05:47:15.815907Z",
     "iopub.status.idle": "2020-09-12T05:47:15.818497Z",
     "shell.execute_reply": "2020-09-12T05:47:15.818980Z"
    },
    "papermill": {
     "duration": 0.020522,
     "end_time": "2020-09-12T05:47:15.819094",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.798572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will tell us the columns we are predicting\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.856138Z",
     "iopub.status.busy": "2020-09-12T05:47:15.855349Z",
     "iopub.status.idle": "2020-09-12T05:47:15.859535Z",
     "shell.execute_reply": "2020-09-12T05:47:15.859055Z"
    },
    "papermill": {
     "duration": 0.027513,
     "end_time": "2020-09-12T05:47:15.859623",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.832110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.GRU(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.LSTM(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def build_model(gru=False,seq_len=107, pred_len=68, dropout=0.25,\n",
    "                embed_dim=128, hidden_dim=384):\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n",
    "    \n",
    "    inputs_bpps = tf.keras.layers.Input(shape=(seq_len, 1))\n",
    "\n",
    "    embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n",
    "    reshaped = tf.reshape(\n",
    "        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n",
    "    \n",
    "    reshaped = tf.keras.layers.SpatialDropout1D(.2)(reshaped)\n",
    "    bpps = tf.keras.layers.Dense(embed_dim, activation='linear')(inputs_bpps)\n",
    "    \n",
    "    reshaped = tf.concat([reshaped, bpps], axis=2)\n",
    "    \n",
    "    hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    \n",
    "    #only making predictions on the first part of each sequence\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    \n",
    "\n",
    "    \n",
    "    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs, inputs_bpps], outputs=out)\n",
    "\n",
    "    #some optimizers\n",
    "    adam = tf.optimizers.Adam()\n",
    "    \n",
    "    def MCRMSE(y_true, y_pred):\n",
    "        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
    "    \n",
    "    model.compile(optimizer = adam, loss=MCRMSE)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.894673Z",
     "iopub.status.busy": "2020-09-12T05:47:15.893039Z",
     "iopub.status.idle": "2020-09-12T05:47:15.895372Z",
     "shell.execute_reply": "2020-09-12T05:47:15.895926Z"
    },
    "papermill": {
     "duration": 0.023046,
     "end_time": "2020-09-12T05:47:15.896053",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.873007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    return np.transpose(\n",
    "        np.array(\n",
    "            df[cols]\n",
    "            .applymap(lambda seq: [token2int[x] for x in seq])\n",
    "            .values\n",
    "            .tolist()\n",
    "        ),\n",
    "        (0, 2, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013134,
     "end_time": "2020-09-12T05:47:15.922732",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.909598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.957048Z",
     "iopub.status.busy": "2020-09-12T05:47:15.956359Z",
     "iopub.status.idle": "2020-09-12T05:47:16.951033Z",
     "shell.execute_reply": "2020-09-12T05:47:16.950138Z"
    },
    "papermill": {
     "duration": 1.012628,
     "end_time": "2020-09-12T05:47:16.951150",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.938522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('../input//train.json', lines=True)\n",
    "test = pd.read_json('../input//test.json', lines=True)\n",
    "sample_df = pd.read_csv('../input//sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id_001f94081'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = np.load('../input/bpps/id_001f94081.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80145771, 0.8162878 , 0.9399976 , 0.98687779, 0.98872014,\n",
       "       0.8726042 , 0.64923491, 0.45909952, 0.38734203, 0.37291085,\n",
       "       0.48373307, 0.89664275, 0.90951632, 0.90861451, 0.98940993,\n",
       "       0.98145491, 0.81965108, 0.79170963, 0.38557835, 0.52880297,\n",
       "       0.5372444 , 0.52122251, 0.90823082, 0.40080513, 0.43650824,\n",
       "       0.54643881, 0.38305727, 0.53568993, 0.67795352, 0.8628183 ,\n",
       "       0.78497647, 0.83994244, 0.78492865, 0.70795306, 0.73116841,\n",
       "       0.82452095, 0.86113227, 0.52072924, 0.37224691, 0.20266188,\n",
       "       0.26856484, 0.39608598, 0.14207184, 0.65970159, 0.65338135,\n",
       "       0.80168215, 0.97622094, 0.40194761, 0.28440304, 0.09579655,\n",
       "       0.23852457, 0.80521037, 0.70261301, 0.81546441, 0.94987859,\n",
       "       0.92402902, 0.76050376, 0.63090152, 0.77919177, 0.73839201,\n",
       "       0.61416194, 0.70487221, 0.35752507, 0.40452985, 0.65327547,\n",
       "       0.58192038, 0.92482731, 0.95905864, 0.13151534, 0.09435281,\n",
       "       0.0744179 , 0.05975572, 0.04247293, 0.05214685, 0.0915126 ,\n",
       "       0.81173428, 0.93450864, 0.96903919, 0.88908934, 0.17730243,\n",
       "       0.11017743, 0.09443205, 0.13040592, 0.17304841, 0.19466995,\n",
       "       0.21206308, 1.        , 0.99890886, 0.99869359, 0.9428686 ,\n",
       "       0.86038865, 0.93654079, 0.96160082, 0.96708391, 0.94263689,\n",
       "       0.99683127, 0.98872616, 0.93275765, 1.        , 0.99814014,\n",
       "       0.95080026, 1.        , 1.        , 0.9606901 , 1.        ,\n",
       "       1.        , 0.95382831])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - foo.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target columns\n",
    "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:16.996064Z",
     "iopub.status.busy": "2020-09-12T05:47:16.993995Z",
     "iopub.status.idle": "2020-09-12T05:47:17.326887Z",
     "shell.execute_reply": "2020-09-12T05:47:17.326212Z"
    },
    "papermill": {
     "duration": 0.361794,
     "end_time": "2020-09-12T05:47:17.327041",
     "exception": false,
     "start_time": "2020-09-12T05:47:16.965247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs = preprocess_inputs(train[train.signal_to_noise > 1])\n",
    "train_labels = np.array(train[train.signal_to_noise > 1][target_cols].values.tolist()).transpose((0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in train['id']])\n",
    "train_bpps = train_bpps[train.signal_to_noise > 1][:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like(train_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 107, 3, 128)  1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 107, 384)]   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 107, 384)     0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 107, 128)     256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 107, 512)]   0           spatial_dropout1d[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 107, 768)     2755584     tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 107, 768)     2658816     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 107, 768)     2658816     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 68, 768)]    0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 68, 5)        3845        tf_op_layer_strided_slice[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 8,079,109\n",
      "Trainable params: 8,079,109\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 5s - loss: 0.4264 - val_loss: 0.3687\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3530 - val_loss: 0.3388\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3334 - val_loss: 0.3231\n",
      "Epoch 4/120\n",
      "53/53 - 3s - loss: 0.3197 - val_loss: 0.3074\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3098 - val_loss: 0.2969\n",
      "Epoch 6/120\n",
      "53/53 - 3s - loss: 0.2970 - val_loss: 0.2832\n",
      "Epoch 7/120\n",
      "53/53 - 3s - loss: 0.2824 - val_loss: 0.2718\n",
      "Epoch 8/120\n",
      "53/53 - 3s - loss: 0.2721 - val_loss: 0.2627\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2630 - val_loss: 0.2614\n",
      "Epoch 10/120\n",
      "53/53 - 3s - loss: 0.2565 - val_loss: 0.2470\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2509 - val_loss: 0.2433\n",
      "Epoch 12/120\n",
      "53/53 - 3s - loss: 0.2426 - val_loss: 0.2387\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2376 - val_loss: 0.2404\n",
      "Epoch 14/120\n",
      "53/53 - 3s - loss: 0.2345 - val_loss: 0.2351\n",
      "Epoch 15/120\n",
      "53/53 - 3s - loss: 0.2287 - val_loss: 0.2336\n",
      "Epoch 16/120\n",
      "53/53 - 3s - loss: 0.2250 - val_loss: 0.2319\n",
      "Epoch 17/120\n",
      "53/53 - 3s - loss: 0.2210 - val_loss: 0.2275\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2150 - val_loss: 0.2271\n",
      "Epoch 19/120\n",
      "53/53 - 3s - loss: 0.2104 - val_loss: 0.2254\n",
      "Epoch 20/120\n",
      "53/53 - 3s - loss: 0.2073 - val_loss: 0.2221\n",
      "Epoch 21/120\n",
      "53/53 - 3s - loss: 0.2017 - val_loss: 0.2238\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1991 - val_loss: 0.2252\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1943 - val_loss: 0.2238\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1901 - val_loss: 0.2230\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1858 - val_loss: 0.2201\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1821 - val_loss: 0.2205\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1778 - val_loss: 0.2194\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1743 - val_loss: 0.2186\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1707 - val_loss: 0.2202\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1671 - val_loss: 0.2187\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1634 - val_loss: 0.2192\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1606 - val_loss: 0.2174\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1578 - val_loss: 0.2176\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1544 - val_loss: 0.2156\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1518 - val_loss: 0.2186\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1502 - val_loss: 0.2188\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1478 - val_loss: 0.2163\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1449 - val_loss: 0.2191\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1446 - val_loss: 0.2181\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1419 - val_loss: 0.2172\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1402 - val_loss: 0.2171\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1375 - val_loss: 0.2185\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1351 - val_loss: 0.2185\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1339 - val_loss: 0.2166\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1260 - val_loss: 0.2138\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1217 - val_loss: 0.2138\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1200 - val_loss: 0.2141\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1188 - val_loss: 0.2134\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1179 - val_loss: 0.2138\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1171 - val_loss: 0.2141\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1165 - val_loss: 0.2137\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1159 - val_loss: 0.2139\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1157 - val_loss: 0.2136\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1153 - val_loss: 0.2141\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1150 - val_loss: 0.2139\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1145 - val_loss: 0.2144\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1140 - val_loss: 0.2141\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1138 - val_loss: 0.2141\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1130 - val_loss: 0.2140\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1128 - val_loss: 0.2140\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1128 - val_loss: 0.2139\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1127 - val_loss: 0.2140\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1126 - val_loss: 0.2140\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2140\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2141\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2141\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2141\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2141\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2141\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2141\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2140\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1120 - val_loss: 0.2140\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1120 - val_loss: 0.2140\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2140\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1120 - val_loss: 0.2140\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 91/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.1119 - val_loss: 0.2140\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2140\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1120 - val_loss: 0.2140\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1120 - val_loss: 0.2140\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1120 - val_loss: 0.2140\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1119 - val_loss: 0.2140\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1119 - val_loss: 0.2140\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2140\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1121 - val_loss: 0.2140\n",
      "#################### 0.37553529794523877\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 107, 3, 128)  1792        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 107, 384)]   0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 107, 384)     0           tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 107, 128)     256         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_3[0][0]        \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 107, 768)     2755584     tf_op_layer_concat_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 107, 768)     2658816     bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 107, 768)     2658816     bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 68, 768)]    0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 68, 5)        3845        tf_op_layer_strided_slice_3[0][0]\n",
      "==================================================================================================\n",
      "Total params: 8,079,109\n",
      "Trainable params: 8,079,109\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 5s - loss: 0.4255 - val_loss: 0.3679\n",
      "Epoch 2/120\n",
      "53/53 - 3s - loss: 0.3542 - val_loss: 0.3335\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3330 - val_loss: 0.3168\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3226 - val_loss: 0.3132\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3129 - val_loss: 0.2966\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2958 - val_loss: 0.2824\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2846 - val_loss: 0.2783\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2766 - val_loss: 0.2625\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2648 - val_loss: 0.2574\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2579 - val_loss: 0.2515\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2522 - val_loss: 0.2499\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2456 - val_loss: 0.2380\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2392 - val_loss: 0.2364\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2364 - val_loss: 0.2332\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2301 - val_loss: 0.2282\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2263 - val_loss: 0.2251\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2217 - val_loss: 0.2278\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2170 - val_loss: 0.2235\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.2113 - val_loss: 0.2225\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.2082 - val_loss: 0.2206\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.2029 - val_loss: 0.2173\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1985 - val_loss: 0.2184\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1933 - val_loss: 0.2171\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1890 - val_loss: 0.2158\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1851 - val_loss: 0.2171\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1820 - val_loss: 0.2157\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1782 - val_loss: 0.2147\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1740 - val_loss: 0.2188\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1708 - val_loss: 0.2172\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1667 - val_loss: 0.2165\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1635 - val_loss: 0.2139\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1605 - val_loss: 0.2134\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1576 - val_loss: 0.2155\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1548 - val_loss: 0.2148\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1521 - val_loss: 0.2116\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1501 - val_loss: 0.2140\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1474 - val_loss: 0.2128\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1457 - val_loss: 0.2146\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1436 - val_loss: 0.2150\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1413 - val_loss: 0.2124\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1389 - val_loss: 0.2127\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1370 - val_loss: 0.2122\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1353 - val_loss: 0.2132\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1340 - val_loss: 0.2127\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1320 - val_loss: 0.2141\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1242 - val_loss: 0.2090\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1197 - val_loss: 0.2087\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1181 - val_loss: 0.2088\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1170 - val_loss: 0.2088\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1162 - val_loss: 0.2087\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1153 - val_loss: 0.2090\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1149 - val_loss: 0.2091\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1144 - val_loss: 0.2087\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1140 - val_loss: 0.2090\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1136 - val_loss: 0.2089\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1131 - val_loss: 0.2093\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1127 - val_loss: 0.2090\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1118 - val_loss: 0.2091\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1115 - val_loss: 0.2091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1115 - val_loss: 0.2090\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1114 - val_loss: 0.2090\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1116 - val_loss: 0.2089\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1115 - val_loss: 0.2090\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1114 - val_loss: 0.2090\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1114 - val_loss: 0.2090\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1112 - val_loss: 0.2090\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2090\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1112 - val_loss: 0.2090\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1112 - val_loss: 0.2090\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2090\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2090\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2090\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2090\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2090\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1112 - val_loss: 0.2090\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1108 - val_loss: 0.2090\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1108 - val_loss: 0.2090\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2090\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2090\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.1108 - val_loss: 0.2090\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2090\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1110 - val_loss: 0.2090\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.1111 - val_loss: 0.2090\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2090\n",
      "#################### 0.3667069875055281\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 107, 3, 128)  1792        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 107, 384)]   0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 107, 384)     0           tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 107, 128)     256         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_6[0][0]        \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 107, 768)     2755584     tf_op_layer_concat_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 107, 768)     2658816     bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 107, 768)     2658816     bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 68, 768)]    0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 68, 5)        3845        tf_op_layer_strided_slice_6[0][0]\n",
      "==================================================================================================\n",
      "Total params: 8,079,109\n",
      "Trainable params: 8,079,109\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 5s - loss: 0.4199 - val_loss: 0.3651\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3529 - val_loss: 0.3354\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3335 - val_loss: 0.3329\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3214 - val_loss: 0.3166\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3120 - val_loss: 0.2985\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2988 - val_loss: 0.2844\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2848 - val_loss: 0.2705\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2754 - val_loss: 0.2631\n",
      "Epoch 9/120\n",
      "53/53 - 3s - loss: 0.2637 - val_loss: 0.2607\n",
      "Epoch 10/120\n",
      "53/53 - 3s - loss: 0.2568 - val_loss: 0.2515\n",
      "Epoch 11/120\n",
      "53/53 - 3s - loss: 0.2500 - val_loss: 0.2457\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2432 - val_loss: 0.2408\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2386 - val_loss: 0.2396\n",
      "Epoch 14/120\n",
      "53/53 - 3s - loss: 0.2345 - val_loss: 0.2387\n",
      "Epoch 15/120\n",
      "53/53 - 3s - loss: 0.2292 - val_loss: 0.2335\n",
      "Epoch 16/120\n",
      "53/53 - 3s - loss: 0.2236 - val_loss: 0.2316\n",
      "Epoch 17/120\n",
      "53/53 - 3s - loss: 0.2200 - val_loss: 0.2304\n",
      "Epoch 18/120\n",
      "53/53 - 3s - loss: 0.2142 - val_loss: 0.2302\n",
      "Epoch 19/120\n",
      "53/53 - 3s - loss: 0.2108 - val_loss: 0.2273\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.2063 - val_loss: 0.2294\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.2017 - val_loss: 0.2270\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1983 - val_loss: 0.2270\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1956 - val_loss: 0.2273\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1893 - val_loss: 0.2232\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1855 - val_loss: 0.2263\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1816 - val_loss: 0.2228\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1778 - val_loss: 0.2215\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1734 - val_loss: 0.2235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1707 - val_loss: 0.2217\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1678 - val_loss: 0.2205\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1640 - val_loss: 0.2200\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1616 - val_loss: 0.2206\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1591 - val_loss: 0.2214\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1569 - val_loss: 0.2219\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1539 - val_loss: 0.2217\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1501 - val_loss: 0.2209\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1475 - val_loss: 0.2196\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1465 - val_loss: 0.2222\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1444 - val_loss: 0.2203\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1430 - val_loss: 0.2203\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1406 - val_loss: 0.2205\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1386 - val_loss: 0.2221\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1366 - val_loss: 0.2203\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1349 - val_loss: 0.2211\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1334 - val_loss: 0.2205\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1327 - val_loss: 0.2207\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1308 - val_loss: 0.2195\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1293 - val_loss: 0.2210\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1271 - val_loss: 0.2191\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1263 - val_loss: 0.2208\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1249 - val_loss: 0.2202\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1236 - val_loss: 0.2220\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1228 - val_loss: 0.2217\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1212 - val_loss: 0.2194\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1201 - val_loss: 0.2209\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1192 - val_loss: 0.2213\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1184 - val_loss: 0.2211\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1169 - val_loss: 0.2206\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1164 - val_loss: 0.2202\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1091 - val_loss: 0.2176\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1050 - val_loss: 0.2173\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1032 - val_loss: 0.2172\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1023 - val_loss: 0.2173\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1017 - val_loss: 0.2172\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1009 - val_loss: 0.2176\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1003 - val_loss: 0.2176\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.0999 - val_loss: 0.2176\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.0995 - val_loss: 0.2175\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.0991 - val_loss: 0.2179\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2178\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.0982 - val_loss: 0.2176\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.0980 - val_loss: 0.2179\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.0975 - val_loss: 0.2176\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.0973 - val_loss: 0.2176\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.0973 - val_loss: 0.2177\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.0971 - val_loss: 0.2176\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.0971 - val_loss: 0.2176\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.0969 - val_loss: 0.2176\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.0969 - val_loss: 0.2177\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.0969 - val_loss: 0.2176\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.0969 - val_loss: 0.2176\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.0968 - val_loss: 0.2176\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.0968 - val_loss: 0.2176\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.0965 - val_loss: 0.2176\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.0968 - val_loss: 0.2176\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.0968 - val_loss: 0.2176\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.0965 - val_loss: 0.2176\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.0968 - val_loss: 0.2176\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.0968 - val_loss: 0.2176\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.0966 - val_loss: 0.2176\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.0965 - val_loss: 0.2176\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.0967 - val_loss: 0.2176\n",
      "#################### 0.380315710469456\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 107, 3, 128)  1792        input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 107, 384)]   0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 107, 384)     0           tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 107, 128)     256         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_9 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_9[0][0]        \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_27 (Bidirectional (None, 107, 768)     2755584     tf_op_layer_concat_9[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_28 (Bidirectional (None, 107, 768)     2658816     bidirectional_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_29 (Bidirectional (None, 107, 768)     2658816     bidirectional_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None, 68, 768)]    0           bidirectional_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 68, 5)        3845        tf_op_layer_strided_slice_9[0][0]\n",
      "==================================================================================================\n",
      "Total params: 8,079,109\n",
      "Trainable params: 8,079,109\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 6s - loss: 0.4260 - val_loss: 0.3691\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3523 - val_loss: 0.3433\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3315 - val_loss: 0.3231\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3205 - val_loss: 0.3156\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3091 - val_loss: 0.2980\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2961 - val_loss: 0.2895\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2824 - val_loss: 0.2811\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2710 - val_loss: 0.2754\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2604 - val_loss: 0.2593\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2530 - val_loss: 0.2557\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2472 - val_loss: 0.2478\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2429 - val_loss: 0.2441\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2370 - val_loss: 0.2422\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2322 - val_loss: 0.2392\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2283 - val_loss: 0.2361\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2246 - val_loss: 0.2336\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2191 - val_loss: 0.2318\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2151 - val_loss: 0.2283\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.2106 - val_loss: 0.2274\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.2068 - val_loss: 0.2265\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.2016 - val_loss: 0.2250\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1976 - val_loss: 0.2239\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1935 - val_loss: 0.2216\n",
      "Epoch 24/120\n",
      "53/53 - 3s - loss: 0.1893 - val_loss: 0.2247\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1855 - val_loss: 0.2232\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1817 - val_loss: 0.2229\n",
      "Epoch 27/120\n",
      "53/53 - 3s - loss: 0.1773 - val_loss: 0.2206\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1736 - val_loss: 0.2251\n",
      "Epoch 29/120\n",
      "53/53 - 3s - loss: 0.1703 - val_loss: 0.2213\n",
      "Epoch 30/120\n",
      "53/53 - 3s - loss: 0.1672 - val_loss: 0.2219\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1646 - val_loss: 0.2205\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1610 - val_loss: 0.2193\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1577 - val_loss: 0.2197\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1554 - val_loss: 0.2217\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1532 - val_loss: 0.2204\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1498 - val_loss: 0.2178\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1476 - val_loss: 0.2200\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1456 - val_loss: 0.2209\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1438 - val_loss: 0.2224\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1416 - val_loss: 0.2200\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1394 - val_loss: 0.2197\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1376 - val_loss: 0.2215\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1356 - val_loss: 0.2204\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1340 - val_loss: 0.2194\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1327 - val_loss: 0.2201\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1312 - val_loss: 0.2200\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1230 - val_loss: 0.2160\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1186 - val_loss: 0.2152\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1168 - val_loss: 0.2155\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1156 - val_loss: 0.2159\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1152 - val_loss: 0.2159\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1145 - val_loss: 0.2158\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1139 - val_loss: 0.2158\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1132 - val_loss: 0.2156\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1129 - val_loss: 0.2157\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2162\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1119 - val_loss: 0.2156\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1116 - val_loss: 0.2162\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2158\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1107 - val_loss: 0.2158\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1105 - val_loss: 0.2158\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1104 - val_loss: 0.2157\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1102 - val_loss: 0.2158\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1102 - val_loss: 0.2158\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1103 - val_loss: 0.2156\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1103 - val_loss: 0.2158\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1102 - val_loss: 0.2158\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1103 - val_loss: 0.2157\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2157\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1102 - val_loss: 0.2158\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1102 - val_loss: 0.2158\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1098 - val_loss: 0.2158\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1098 - val_loss: 0.2158\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1098 - val_loss: 0.2158\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1098 - val_loss: 0.2158\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1102 - val_loss: 0.2158\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2158\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2158\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2158\n",
      "#################### 0.3629861535392821\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 107, 3, 128)  1792        input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_12 (TensorF [(None, 107, 384)]   0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 107, 384)     0           tf_op_layer_Reshape_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 107, 128)     256         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_12 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_12[0][0]       \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 107, 768)     2755584     tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 107, 768)     2658816     bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_38 (Bidirectional (None, 107, 768)     2658816     bidirectional_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 68, 768)]    0           bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 68, 5)        3845        tf_op_layer_strided_slice_12[0][0\n",
      "==================================================================================================\n",
      "Total params: 8,079,109\n",
      "Trainable params: 8,079,109\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 5s - loss: 0.4131 - val_loss: 0.3639\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3518 - val_loss: 0.3385\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3311 - val_loss: 0.3218\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3205 - val_loss: 0.3128\n",
      "Epoch 5/120\n",
      "53/53 - 3s - loss: 0.3078 - val_loss: 0.3049\n",
      "Epoch 6/120\n",
      "53/53 - 3s - loss: 0.2957 - val_loss: 0.2942\n",
      "Epoch 7/120\n",
      "53/53 - 3s - loss: 0.2839 - val_loss: 0.2811\n",
      "Epoch 8/120\n",
      "53/53 - 3s - loss: 0.2733 - val_loss: 0.2650\n",
      "Epoch 9/120\n",
      "53/53 - 3s - loss: 0.2631 - val_loss: 0.2584\n",
      "Epoch 10/120\n",
      "53/53 - 3s - loss: 0.2548 - val_loss: 0.2521\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2482 - val_loss: 0.2469\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2421 - val_loss: 0.2420\n",
      "Epoch 13/120\n",
      "53/53 - 3s - loss: 0.2361 - val_loss: 0.2371\n",
      "Epoch 14/120\n",
      "53/53 - 3s - loss: 0.2316 - val_loss: 0.2357\n",
      "Epoch 15/120\n",
      "53/53 - 3s - loss: 0.2275 - val_loss: 0.2321\n",
      "Epoch 16/120\n",
      "53/53 - 3s - loss: 0.2248 - val_loss: 0.2301\n",
      "Epoch 17/120\n",
      "53/53 - 3s - loss: 0.2192 - val_loss: 0.2282\n",
      "Epoch 18/120\n",
      "53/53 - 3s - loss: 0.2136 - val_loss: 0.2283\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.2118 - val_loss: 0.2253\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.2055 - val_loss: 0.2258\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.2025 - val_loss: 0.2254\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1977 - val_loss: 0.2224\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1935 - val_loss: 0.2211\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1886 - val_loss: 0.2224\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1851 - val_loss: 0.2198\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1805 - val_loss: 0.2211\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1776 - val_loss: 0.2212\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1743 - val_loss: 0.2182\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1703 - val_loss: 0.2205\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1667 - val_loss: 0.2178\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1637 - val_loss: 0.2222\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1602 - val_loss: 0.2197\n",
      "Epoch 33/120\n",
      "53/53 - 5s - loss: 0.1568 - val_loss: 0.2178\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1542 - val_loss: 0.2172\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1520 - val_loss: 0.2181\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1501 - val_loss: 0.2175\n",
      "Epoch 37/120\n",
      "53/53 - 3s - loss: 0.1475 - val_loss: 0.2203\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1449 - val_loss: 0.2190\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1426 - val_loss: 0.2198\n",
      "Epoch 40/120\n",
      "53/53 - 3s - loss: 0.1408 - val_loss: 0.2180\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1389 - val_loss: 0.2193\n",
      "Epoch 42/120\n",
      "53/53 - 3s - loss: 0.1374 - val_loss: 0.2221\n",
      "Epoch 43/120\n",
      "53/53 - 3s - loss: 0.1355 - val_loss: 0.2180\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1337 - val_loss: 0.2191\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1257 - val_loss: 0.2149\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1211 - val_loss: 0.2141\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1196 - val_loss: 0.2145\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1184 - val_loss: 0.2143\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1176 - val_loss: 0.2144\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1168 - val_loss: 0.2145\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1163 - val_loss: 0.2145\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1156 - val_loss: 0.2147\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1154 - val_loss: 0.2148\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1149 - val_loss: 0.2150\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1145 - val_loss: 0.2146\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1140 - val_loss: 0.2151\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1134 - val_loss: 0.2148\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1130 - val_loss: 0.2148\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1129 - val_loss: 0.2148\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1127 - val_loss: 0.2149\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1127 - val_loss: 0.2148\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1127 - val_loss: 0.2149\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1127 - val_loss: 0.2148\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1127 - val_loss: 0.2149\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1126 - val_loss: 0.2149\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2149\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2149\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2149\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2148\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2149\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2149\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2149\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2148\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2148\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2148\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2148\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2148\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2148\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1122 - val_loss: 0.2148\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1124 - val_loss: 0.2148\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.1125 - val_loss: 0.2148\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2148\n",
      "#################### 0.38172304774052457\n",
      "(629, 107, 5) (3005, 130, 5)\n"
     ]
    }
   ],
   "source": [
    "FOLDS = KFold(n_splits=5, random_state=815, shuffle=True)\n",
    "\n",
    "oofs_pred = np.zeros_like(train_labels)\n",
    "public_preds_array = []\n",
    "public_preds_array = []\n",
    "\n",
    "for i, (trn_idx, vld_idx) in enumerate(FOLDS.split(train_inputs)):\n",
    "    trn_inputs = train_inputs[trn_idx]\n",
    "    vld_inputs = train_inputs[vld_idx]\n",
    "    \n",
    "    trn_inputs_bpps = train_bpps[trn_idx]\n",
    "    vld_inputs_bpps = train_bpps[vld_idx]\n",
    "\n",
    "    trn_labels = train_labels[trn_idx]\n",
    "    vld_labels = train_labels[vld_idx]\n",
    "\n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        [trn_inputs, trn_inputs_bpps], trn_labels, \n",
    "        validation_data=([vld_inputs, vld_inputs_bpps], vld_labels),\n",
    "        batch_size=32,\n",
    "        epochs=120,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "            tf.keras.callbacks.ModelCheckpoint('bpps_large_lstm_gru_gru_newloss_815.h5')\n",
    "        ],\n",
    "        verbose=2,\n",
    "    )\n",
    "    model.load_weights('./bpps_large_lstm_gru_gru_newloss_815.h5')\n",
    "    outputs = model.predict([vld_inputs, vld_inputs_bpps])\n",
    "    oofs_pred[vld_idx] = outputs\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    errors = []\n",
    "    for idx in range(5):\n",
    "         errors.append(np.sqrt(mean_squared_error(vld_labels[:, idx], outputs[:, idx])))\n",
    "    final_error = np.mean(errors)\n",
    "    print('#'*20, final_error)\n",
    "\n",
    "    public_df = test.query(\"seq_length == 107\").copy()\n",
    "    private_df = test.query(\"seq_length == 130\").copy()\n",
    "\n",
    "    public_inputs = preprocess_inputs(public_df)\n",
    "    private_inputs = preprocess_inputs(private_df)\n",
    "    \n",
    "    public_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in public_df['id']])\n",
    "    public_bpps = public_bpps[:, :, np.newaxis]\n",
    "    \n",
    "    private_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in private_df['id']])\n",
    "    private_bpps = private_bpps[:, :, np.newaxis] \n",
    "\n",
    "    # Caveat: The prediction format requires the output to be the same length as the input,\n",
    "    # although it's not the case for the training data.\n",
    "    model_short = build_model(seq_len=107, pred_len=107)\n",
    "    model_long = build_model(seq_len=130, pred_len=130)\n",
    "\n",
    "    model_short.load_weights('bpps_large_lstm_gru_gru_newloss_815.h5')\n",
    "    model_long.load_weights('bpps_large_lstm_gru_gru_newloss_815.h5')\n",
    "\n",
    "    public_preds = model_short.predict([public_inputs, public_bpps])\n",
    "    private_preds = model_long.predict([private_inputs,private_bpps])\n",
    "    \n",
    "    public_preds_array.append(public_preds)\n",
    "    public_preds_array.append(private_preds)\n",
    "\n",
    "    print(public_preds.shape, private_preds.shape)\n",
    "\n",
    "    preds_ls = []\n",
    "\n",
    "    for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
    "        for idx, uid in enumerate(df.id):\n",
    "            single_pred = preds[idx]\n",
    "\n",
    "            single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "            preds_ls.append(single_df)\n",
    "\n",
    "    preds_df = pd.concat(preds_ls)\n",
    "\n",
    "    submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "    submission.to_csv(f'submission_bpps_large_lstm_gru_gru_newloss_815_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, uid in enumerate(train.id):\n",
    "#     single_pred = oofs_pred[i]\n",
    "\n",
    "#     oof_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "#     oof_df['id_seqpos'] = [f'{uid}_{x}' for x in range(oof_df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyh",
   "language": "python",
   "name": "lyh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 161.997015,
   "end_time": "2020-09-12T05:49:46.470488",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-12T05:47:04.473473",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
