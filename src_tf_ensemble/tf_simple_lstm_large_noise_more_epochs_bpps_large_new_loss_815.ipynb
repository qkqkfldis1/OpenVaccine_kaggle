{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:08.823964Z",
     "iopub.status.busy": "2020-09-12T05:47:08.823205Z",
     "iopub.status.idle": "2020-09-12T05:47:15.758339Z",
     "shell.execute_reply": "2020-09-12T05:47:15.757303Z"
    },
    "papermill": {
     "duration": 6.954489,
     "end_time": "2020-09-12T05:47:15.758481",
     "exception": false,
     "start_time": "2020-09-12T05:47:08.803992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01294,
     "end_time": "2020-09-12T05:47:15.784990",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.772050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define helper functions and useful vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.817688Z",
     "iopub.status.busy": "2020-09-12T05:47:15.815907Z",
     "iopub.status.idle": "2020-09-12T05:47:15.818497Z",
     "shell.execute_reply": "2020-09-12T05:47:15.818980Z"
    },
    "papermill": {
     "duration": 0.020522,
     "end_time": "2020-09-12T05:47:15.819094",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.798572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will tell us the columns we are predicting\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.856138Z",
     "iopub.status.busy": "2020-09-12T05:47:15.855349Z",
     "iopub.status.idle": "2020-09-12T05:47:15.859535Z",
     "shell.execute_reply": "2020-09-12T05:47:15.859055Z"
    },
    "papermill": {
     "duration": 0.027513,
     "end_time": "2020-09-12T05:47:15.859623",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.832110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.GRU(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.LSTM(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def build_model(gru=False,seq_len=107, pred_len=68, dropout=0.25,\n",
    "                embed_dim=128, hidden_dim=384):\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n",
    "    \n",
    "    inputs_bpps = tf.keras.layers.Input(shape=(seq_len, 1))\n",
    "\n",
    "    embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n",
    "    reshaped = tf.reshape(\n",
    "        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n",
    "    \n",
    "    reshaped = tf.keras.layers.SpatialDropout1D(.2)(reshaped)\n",
    "    bpps = tf.keras.layers.Dense(embed_dim, activation='linear')(inputs_bpps)\n",
    "    \n",
    "    reshaped = tf.concat([reshaped, bpps], axis=2)\n",
    "    \n",
    "    if gru:\n",
    "        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n",
    "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "        hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "        \n",
    "    else:\n",
    "        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n",
    "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
    "        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
    "    \n",
    "    #only making predictions on the first part of each sequence\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    \n",
    "    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs, inputs_bpps], outputs=out)\n",
    "\n",
    "    #some optimizers\n",
    "    adam = tf.optimizers.Adam()\n",
    "    def MCRMSE(y_true, y_pred):\n",
    "        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
    "    \n",
    "    model.compile(optimizer = adam, loss=MCRMSE)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.894673Z",
     "iopub.status.busy": "2020-09-12T05:47:15.893039Z",
     "iopub.status.idle": "2020-09-12T05:47:15.895372Z",
     "shell.execute_reply": "2020-09-12T05:47:15.895926Z"
    },
    "papermill": {
     "duration": 0.023046,
     "end_time": "2020-09-12T05:47:15.896053",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.873007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    return np.transpose(\n",
    "        np.array(\n",
    "            df[cols]\n",
    "            .applymap(lambda seq: [token2int[x] for x in seq])\n",
    "            .values\n",
    "            .tolist()\n",
    "        ),\n",
    "        (0, 2, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013134,
     "end_time": "2020-09-12T05:47:15.922732",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.909598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.957048Z",
     "iopub.status.busy": "2020-09-12T05:47:15.956359Z",
     "iopub.status.idle": "2020-09-12T05:47:16.951033Z",
     "shell.execute_reply": "2020-09-12T05:47:16.950138Z"
    },
    "papermill": {
     "duration": 1.012628,
     "end_time": "2020-09-12T05:47:16.951150",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.938522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('../input//train.json', lines=True)\n",
    "test = pd.read_json('../input//test.json', lines=True)\n",
    "sample_df = pd.read_csv('../input//sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id_001f94081'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = np.load('../input/bpps/id_001f94081.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80145771, 0.8162878 , 0.9399976 , 0.98687779, 0.98872014,\n",
       "       0.8726042 , 0.64923491, 0.45909952, 0.38734203, 0.37291085,\n",
       "       0.48373307, 0.89664275, 0.90951632, 0.90861451, 0.98940993,\n",
       "       0.98145491, 0.81965108, 0.79170963, 0.38557835, 0.52880297,\n",
       "       0.5372444 , 0.52122251, 0.90823082, 0.40080513, 0.43650824,\n",
       "       0.54643881, 0.38305727, 0.53568993, 0.67795352, 0.8628183 ,\n",
       "       0.78497647, 0.83994244, 0.78492865, 0.70795306, 0.73116841,\n",
       "       0.82452095, 0.86113227, 0.52072924, 0.37224691, 0.20266188,\n",
       "       0.26856484, 0.39608598, 0.14207184, 0.65970159, 0.65338135,\n",
       "       0.80168215, 0.97622094, 0.40194761, 0.28440304, 0.09579655,\n",
       "       0.23852457, 0.80521037, 0.70261301, 0.81546441, 0.94987859,\n",
       "       0.92402902, 0.76050376, 0.63090152, 0.77919177, 0.73839201,\n",
       "       0.61416194, 0.70487221, 0.35752507, 0.40452985, 0.65327547,\n",
       "       0.58192038, 0.92482731, 0.95905864, 0.13151534, 0.09435281,\n",
       "       0.0744179 , 0.05975572, 0.04247293, 0.05214685, 0.0915126 ,\n",
       "       0.81173428, 0.93450864, 0.96903919, 0.88908934, 0.17730243,\n",
       "       0.11017743, 0.09443205, 0.13040592, 0.17304841, 0.19466995,\n",
       "       0.21206308, 1.        , 0.99890886, 0.99869359, 0.9428686 ,\n",
       "       0.86038865, 0.93654079, 0.96160082, 0.96708391, 0.94263689,\n",
       "       0.99683127, 0.98872616, 0.93275765, 1.        , 0.99814014,\n",
       "       0.95080026, 1.        , 1.        , 0.9606901 , 1.        ,\n",
       "       1.        , 0.95382831])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - foo.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target columns\n",
    "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:16.996064Z",
     "iopub.status.busy": "2020-09-12T05:47:16.993995Z",
     "iopub.status.idle": "2020-09-12T05:47:17.326887Z",
     "shell.execute_reply": "2020-09-12T05:47:17.326212Z"
    },
    "papermill": {
     "duration": 0.361794,
     "end_time": "2020-09-12T05:47:17.327041",
     "exception": false,
     "start_time": "2020-09-12T05:47:16.965247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs = preprocess_inputs(train[train.signal_to_noise > 1])\n",
    "train_labels = np.array(train[train.signal_to_noise > 1][target_cols].values.tolist()).transpose((0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in train['id']])\n",
    "train_bpps = train_bpps[train.signal_to_noise > 1][:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like(train_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 107, 3, 128)  1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 107, 384)]   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 107, 384)     0           tf_op_layer_Reshape[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 107, 128)     256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 107, 512)]   0           spatial_dropout1d[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 107, 768)     2755584     tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 107, 768)     3542016     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 107, 768)     3542016     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 68, 768)]    0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 68, 5)        3845        tf_op_layer_strided_slice[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 9,845,509\n",
      "Trainable params: 9,845,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 5s - loss: 0.4263 - val_loss: 0.3707\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3579 - val_loss: 0.3367\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3362 - val_loss: 0.3302\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3258 - val_loss: 0.3112\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3088 - val_loss: 0.2969\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2978 - val_loss: 0.2845\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2825 - val_loss: 0.2696\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2694 - val_loss: 0.2580\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2562 - val_loss: 0.2506\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2510 - val_loss: 0.2472\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2419 - val_loss: 0.2410\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2355 - val_loss: 0.2381\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2295 - val_loss: 0.2336\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2232 - val_loss: 0.2311\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2181 - val_loss: 0.2318\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2129 - val_loss: 0.2272\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2078 - val_loss: 0.2267\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2017 - val_loss: 0.2233\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.1957 - val_loss: 0.2225\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.1922 - val_loss: 0.2221\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.1873 - val_loss: 0.2193\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1815 - val_loss: 0.2186\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1777 - val_loss: 0.2188\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1732 - val_loss: 0.2178\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1688 - val_loss: 0.2205\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1644 - val_loss: 0.2177\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1613 - val_loss: 0.2177\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1578 - val_loss: 0.2163\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1542 - val_loss: 0.2161\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1516 - val_loss: 0.2160\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1475 - val_loss: 0.2157\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1453 - val_loss: 0.2175\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1426 - val_loss: 0.2150\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1395 - val_loss: 0.2153\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1371 - val_loss: 0.2175\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1347 - val_loss: 0.2154\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1328 - val_loss: 0.2158\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1311 - val_loss: 0.2164\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1285 - val_loss: 0.2173\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1260 - val_loss: 0.2170\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1240 - val_loss: 0.2151\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1222 - val_loss: 0.2163\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1208 - val_loss: 0.2158\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1136 - val_loss: 0.2139\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1100 - val_loss: 0.2140\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1080 - val_loss: 0.2141\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1068 - val_loss: 0.2141\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1059 - val_loss: 0.2140\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1052 - val_loss: 0.2140\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1046 - val_loss: 0.2138\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1041 - val_loss: 0.2137\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1035 - val_loss: 0.2141\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1030 - val_loss: 0.2139\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1028 - val_loss: 0.2139\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1024 - val_loss: 0.2142\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1018 - val_loss: 0.2146\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1017 - val_loss: 0.2145\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1012 - val_loss: 0.2143\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1009 - val_loss: 0.2147\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1006 - val_loss: 0.2144\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1003 - val_loss: 0.2148\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.0997 - val_loss: 0.2147\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.0994 - val_loss: 0.2146\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.0993 - val_loss: 0.2146\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.0992 - val_loss: 0.2145\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.0992 - val_loss: 0.2146\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.0992 - val_loss: 0.2146\n",
      "Epoch 68/120\n",
      "53/53 - 5s - loss: 0.0992 - val_loss: 0.2146\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.0989 - val_loss: 0.2145\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.0990 - val_loss: 0.2146\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.0989 - val_loss: 0.2146\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.0989 - val_loss: 0.2146\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.0989 - val_loss: 0.2146\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.0985 - val_loss: 0.2146\n",
      "Epoch 91/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.0986 - val_loss: 0.2146\n",
      "Epoch 95/120\n",
      "53/53 - 5s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.0989 - val_loss: 0.2146\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.0989 - val_loss: 0.2146\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.0989 - val_loss: 0.2146\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2146\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.0989 - val_loss: 0.2146\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.0989 - val_loss: 0.2146\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.0988 - val_loss: 0.2146\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.0986 - val_loss: 0.2146\n",
      "#################### 0.3846338434946083\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 107, 3, 128)  1792        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 107, 384)]   0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 107, 384)     0           tf_op_layer_Reshape_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 107, 128)     256         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_3 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_3[0][0]        \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 107, 768)     2755584     tf_op_layer_concat_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 107, 768)     3542016     bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 107, 768)     3542016     bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 68, 768)]    0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 68, 5)        3845        tf_op_layer_strided_slice_3[0][0]\n",
      "==================================================================================================\n",
      "Total params: 9,845,509\n",
      "Trainable params: 9,845,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 6s - loss: 0.4295 - val_loss: 0.3711\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3598 - val_loss: 0.3409\n",
      "Epoch 3/120\n",
      "53/53 - 5s - loss: 0.3407 - val_loss: 0.3343\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3282 - val_loss: 0.3126\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3111 - val_loss: 0.2982\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2992 - val_loss: 0.2863\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2843 - val_loss: 0.2720\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2720 - val_loss: 0.2591\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2582 - val_loss: 0.2513\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2502 - val_loss: 0.2437\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2422 - val_loss: 0.2419\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2357 - val_loss: 0.2334\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2298 - val_loss: 0.2307\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2235 - val_loss: 0.2287\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2193 - val_loss: 0.2245\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2119 - val_loss: 0.2212\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2063 - val_loss: 0.2222\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2016 - val_loss: 0.2189\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.1961 - val_loss: 0.2193\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.1915 - val_loss: 0.2202\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.1866 - val_loss: 0.2178\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1819 - val_loss: 0.2165\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1774 - val_loss: 0.2151\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1729 - val_loss: 0.2148\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1684 - val_loss: 0.2138\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1639 - val_loss: 0.2158\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1608 - val_loss: 0.2139\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1568 - val_loss: 0.2139\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1535 - val_loss: 0.2135\n",
      "Epoch 30/120\n",
      "53/53 - 5s - loss: 0.1498 - val_loss: 0.2133\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1468 - val_loss: 0.2135\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1444 - val_loss: 0.2138\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1416 - val_loss: 0.2136\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1391 - val_loss: 0.2137\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1360 - val_loss: 0.2137\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1337 - val_loss: 0.2135\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1315 - val_loss: 0.2146\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1298 - val_loss: 0.2137\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1275 - val_loss: 0.2133\n",
      "Epoch 40/120\n",
      "53/53 - 5s - loss: 0.1255 - val_loss: 0.2143\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1189 - val_loss: 0.2114\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1143 - val_loss: 0.2112\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1123 - val_loss: 0.2110\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2114\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1099 - val_loss: 0.2112\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1090 - val_loss: 0.2113\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1086 - val_loss: 0.2114\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1080 - val_loss: 0.2114\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1075 - val_loss: 0.2117\n",
      "Epoch 50/120\n",
      "53/53 - 5s - loss: 0.1069 - val_loss: 0.2116\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1063 - val_loss: 0.2117\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2114\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1057 - val_loss: 0.2118\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1047 - val_loss: 0.2118\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1046 - val_loss: 0.2119\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1046 - val_loss: 0.2118\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1045 - val_loss: 0.2118\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1043 - val_loss: 0.2118\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1044 - val_loss: 0.2118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/120\n",
      "53/53 - 5s - loss: 0.1042 - val_loss: 0.2118\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1043 - val_loss: 0.2119\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1041 - val_loss: 0.2119\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1041 - val_loss: 0.2118\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1041 - val_loss: 0.2118\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1041 - val_loss: 0.2118\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.1041 - val_loss: 0.2118\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 81/120\n",
      "53/53 - 5s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 92/120\n",
      "53/53 - 5s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1041 - val_loss: 0.2118\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.1040 - val_loss: 0.2118\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1038 - val_loss: 0.2118\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1039 - val_loss: 0.2118\n",
      "#################### 0.3734650286853098\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 107, 3, 128)  1792        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_6 (TensorFl [(None, 107, 384)]   0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 107, 384)     0           tf_op_layer_Reshape_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 107, 128)     256         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_6[0][0]        \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 107, 768)     2755584     tf_op_layer_concat_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 107, 768)     3542016     bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 107, 768)     3542016     bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 68, 768)]    0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 68, 5)        3845        tf_op_layer_strided_slice_6[0][0]\n",
      "==================================================================================================\n",
      "Total params: 9,845,509\n",
      "Trainable params: 9,845,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 6s - loss: 0.4346 - val_loss: 0.3799\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3580 - val_loss: 0.3429\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3393 - val_loss: 0.3327\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3232 - val_loss: 0.3139\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3112 - val_loss: 0.3047\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2983 - val_loss: 0.2893\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2814 - val_loss: 0.2721\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2681 - val_loss: 0.2690\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2591 - val_loss: 0.2532\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2506 - val_loss: 0.2467\n",
      "Epoch 11/120\n",
      "53/53 - 5s - loss: 0.2436 - val_loss: 0.2447\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2359 - val_loss: 0.2369\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2296 - val_loss: 0.2366\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2248 - val_loss: 0.2331\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2193 - val_loss: 0.2311\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2123 - val_loss: 0.2289\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2068 - val_loss: 0.2273\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2013 - val_loss: 0.2260\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.1959 - val_loss: 0.2241\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.1906 - val_loss: 0.2271\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.1850 - val_loss: 0.2224\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1802 - val_loss: 0.2225\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1763 - val_loss: 0.2219\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1725 - val_loss: 0.2213\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1684 - val_loss: 0.2222\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1644 - val_loss: 0.2228\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1608 - val_loss: 0.2216\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1578 - val_loss: 0.2203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1539 - val_loss: 0.2187\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1504 - val_loss: 0.2206\n",
      "Epoch 31/120\n",
      "53/53 - 5s - loss: 0.1469 - val_loss: 0.2196\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1448 - val_loss: 0.2198\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1420 - val_loss: 0.2204\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1393 - val_loss: 0.2202\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1369 - val_loss: 0.2197\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1347 - val_loss: 0.2188\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1322 - val_loss: 0.2190\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1300 - val_loss: 0.2187\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1278 - val_loss: 0.2205\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1203 - val_loss: 0.2175\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1163 - val_loss: 0.2170\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1143 - val_loss: 0.2167\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1130 - val_loss: 0.2169\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1120 - val_loss: 0.2169\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1113 - val_loss: 0.2171\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1108 - val_loss: 0.2170\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1101 - val_loss: 0.2173\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1094 - val_loss: 0.2170\n",
      "Epoch 49/120\n",
      "53/53 - 5s - loss: 0.1092 - val_loss: 0.2173\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1086 - val_loss: 0.2175\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1080 - val_loss: 0.2177\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.1078 - val_loss: 0.2176\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.1070 - val_loss: 0.2176\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.1069 - val_loss: 0.2175\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.1065 - val_loss: 0.2176\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.1067 - val_loss: 0.2175\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.1064 - val_loss: 0.2175\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.1063 - val_loss: 0.2175\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.1064 - val_loss: 0.2175\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.1063 - val_loss: 0.2176\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.1063 - val_loss: 0.2176\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.1063 - val_loss: 0.2176\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.1062 - val_loss: 0.2176\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 77/120\n",
      "53/53 - 5s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.1062 - val_loss: 0.2176\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.1062 - val_loss: 0.2176\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.1062 - val_loss: 0.2176\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.1059 - val_loss: 0.2176\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.1062 - val_loss: 0.2176\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 102/120\n",
      "53/53 - 5s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.1062 - val_loss: 0.2176\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.1059 - val_loss: 0.2176\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "Epoch 119/120\n",
      "53/53 - 5s - loss: 0.1061 - val_loss: 0.2176\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.1060 - val_loss: 0.2176\n",
      "#################### 0.38143399431355135\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 107, 3, 128)  1792        input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_9 (TensorFl [(None, 107, 384)]   0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_9 (SpatialDro (None, 107, 384)     0           tf_op_layer_Reshape_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 107, 128)     256         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_9 (TensorFlo [(None, 107, 512)]   0           spatial_dropout1d_9[0][0]        \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_27 (Bidirectional (None, 107, 768)     2755584     tf_op_layer_concat_9[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_28 (Bidirectional (None, 107, 768)     3542016     bidirectional_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_29 (Bidirectional (None, 107, 768)     3542016     bidirectional_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None, 68, 768)]    0           bidirectional_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 68, 5)        3845        tf_op_layer_strided_slice_9[0][0]\n",
      "==================================================================================================\n",
      "Total params: 9,845,509\n",
      "Trainable params: 9,845,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 6s - loss: 0.4347 - val_loss: 0.3762\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3595 - val_loss: 0.3458\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3385 - val_loss: 0.3314\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3241 - val_loss: 0.3170\n",
      "Epoch 5/120\n",
      "53/53 - 5s - loss: 0.3118 - val_loss: 0.3047\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2975 - val_loss: 0.2920\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2854 - val_loss: 0.2775\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2697 - val_loss: 0.2701\n",
      "Epoch 9/120\n",
      "53/53 - 4s - loss: 0.2595 - val_loss: 0.2576\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2491 - val_loss: 0.2493\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2424 - val_loss: 0.2463\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2348 - val_loss: 0.2375\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2285 - val_loss: 0.2361\n",
      "Epoch 14/120\n",
      "53/53 - 5s - loss: 0.2237 - val_loss: 0.2336\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2167 - val_loss: 0.2307\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2123 - val_loss: 0.2299\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2076 - val_loss: 0.2281\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.2020 - val_loss: 0.2287\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.1964 - val_loss: 0.2243\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.1911 - val_loss: 0.2235\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.1859 - val_loss: 0.2243\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1812 - val_loss: 0.2228\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1767 - val_loss: 0.2219\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1720 - val_loss: 0.2224\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1684 - val_loss: 0.2210\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1647 - val_loss: 0.2219\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1608 - val_loss: 0.2221\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1562 - val_loss: 0.2200\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1529 - val_loss: 0.2190\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1505 - val_loss: 0.2200\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1472 - val_loss: 0.2195\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1439 - val_loss: 0.2192\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1413 - val_loss: 0.2196\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1389 - val_loss: 0.2199\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1360 - val_loss: 0.2190\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1343 - val_loss: 0.2201\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1318 - val_loss: 0.2187\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1297 - val_loss: 0.2202\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1273 - val_loss: 0.2215\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1252 - val_loss: 0.2201\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1236 - val_loss: 0.2202\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1215 - val_loss: 0.2198\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1194 - val_loss: 0.2199\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1181 - val_loss: 0.2212\n",
      "Epoch 45/120\n",
      "53/53 - 4s - loss: 0.1163 - val_loss: 0.2202\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1145 - val_loss: 0.2211\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1132 - val_loss: 0.2206\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1075 - val_loss: 0.2191\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1036 - val_loss: 0.2187\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1016 - val_loss: 0.2187\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1005 - val_loss: 0.2188\n",
      "Epoch 52/120\n",
      "53/53 - 4s - loss: 0.0995 - val_loss: 0.2187\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.0987 - val_loss: 0.2188\n",
      "Epoch 54/120\n",
      "53/53 - 5s - loss: 0.0984 - val_loss: 0.2188\n",
      "Epoch 55/120\n",
      "53/53 - 5s - loss: 0.0978 - val_loss: 0.2184\n",
      "Epoch 56/120\n",
      "53/53 - 5s - loss: 0.0973 - val_loss: 0.2187\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.0968 - val_loss: 0.2187\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.0964 - val_loss: 0.2187\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.0961 - val_loss: 0.2189\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.0955 - val_loss: 0.2187\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.0955 - val_loss: 0.2187\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.0952 - val_loss: 0.2188\n",
      "Epoch 63/120\n",
      "53/53 - 4s - loss: 0.0950 - val_loss: 0.2187\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.0944 - val_loss: 0.2189\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.0944 - val_loss: 0.2189\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.0936 - val_loss: 0.2190\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.0935 - val_loss: 0.2190\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.0936 - val_loss: 0.2189\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.0934 - val_loss: 0.2189\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.0933 - val_loss: 0.2189\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.0933 - val_loss: 0.2189\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.0931 - val_loss: 0.2189\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.0932 - val_loss: 0.2189\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.0931 - val_loss: 0.2189\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.0928 - val_loss: 0.2189\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.0931 - val_loss: 0.2189\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.0931 - val_loss: 0.2189\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.0928 - val_loss: 0.2189\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 91/120\n",
      "53/53 - 5s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.0928 - val_loss: 0.2189\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.0931 - val_loss: 0.2189\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 110/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.0930 - val_loss: 0.2189\n",
      "Epoch 119/120\n",
      "53/53 - 5s - loss: 0.0929 - val_loss: 0.2189\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.0929 - val_loss: 0.2189\n",
      "#################### 0.37207163916339725\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "Model: \"functional_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 107, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 107, 3, 128)  1792        input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_12 (TensorF [(None, 107, 384)]   0           embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_12 (SpatialDr (None, 107, 384)     0           tf_op_layer_Reshape_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 107, 128)     256         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_12 (TensorFl [(None, 107, 512)]   0           spatial_dropout1d_12[0][0]       \n",
      "                                                                 dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 107, 768)     2755584     tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 107, 768)     3542016     bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_38 (Bidirectional (None, 107, 768)     3542016     bidirectional_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 68, 768)]    0           bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 68, 5)        3845        tf_op_layer_strided_slice_12[0][0\n",
      "==================================================================================================\n",
      "Total params: 9,845,509\n",
      "Trainable params: 9,845,509\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 6s - loss: 0.4396 - val_loss: 0.3765\n",
      "Epoch 2/120\n",
      "53/53 - 4s - loss: 0.3591 - val_loss: 0.3451\n",
      "Epoch 3/120\n",
      "53/53 - 4s - loss: 0.3377 - val_loss: 0.3285\n",
      "Epoch 4/120\n",
      "53/53 - 4s - loss: 0.3213 - val_loss: 0.3204\n",
      "Epoch 5/120\n",
      "53/53 - 4s - loss: 0.3103 - val_loss: 0.3003\n",
      "Epoch 6/120\n",
      "53/53 - 4s - loss: 0.2938 - val_loss: 0.2873\n",
      "Epoch 7/120\n",
      "53/53 - 4s - loss: 0.2799 - val_loss: 0.2764\n",
      "Epoch 8/120\n",
      "53/53 - 4s - loss: 0.2665 - val_loss: 0.2631\n",
      "Epoch 9/120\n",
      "53/53 - 5s - loss: 0.2574 - val_loss: 0.2570\n",
      "Epoch 10/120\n",
      "53/53 - 4s - loss: 0.2473 - val_loss: 0.2495\n",
      "Epoch 11/120\n",
      "53/53 - 4s - loss: 0.2393 - val_loss: 0.2448\n",
      "Epoch 12/120\n",
      "53/53 - 4s - loss: 0.2336 - val_loss: 0.2395\n",
      "Epoch 13/120\n",
      "53/53 - 4s - loss: 0.2277 - val_loss: 0.2362\n",
      "Epoch 14/120\n",
      "53/53 - 4s - loss: 0.2213 - val_loss: 0.2316\n",
      "Epoch 15/120\n",
      "53/53 - 4s - loss: 0.2173 - val_loss: 0.2296\n",
      "Epoch 16/120\n",
      "53/53 - 4s - loss: 0.2104 - val_loss: 0.2251\n",
      "Epoch 17/120\n",
      "53/53 - 4s - loss: 0.2044 - val_loss: 0.2300\n",
      "Epoch 18/120\n",
      "53/53 - 4s - loss: 0.1999 - val_loss: 0.2282\n",
      "Epoch 19/120\n",
      "53/53 - 4s - loss: 0.1947 - val_loss: 0.2224\n",
      "Epoch 20/120\n",
      "53/53 - 4s - loss: 0.1893 - val_loss: 0.2217\n",
      "Epoch 21/120\n",
      "53/53 - 4s - loss: 0.1838 - val_loss: 0.2202\n",
      "Epoch 22/120\n",
      "53/53 - 4s - loss: 0.1798 - val_loss: 0.2220\n",
      "Epoch 23/120\n",
      "53/53 - 4s - loss: 0.1748 - val_loss: 0.2222\n",
      "Epoch 24/120\n",
      "53/53 - 4s - loss: 0.1715 - val_loss: 0.2194\n",
      "Epoch 25/120\n",
      "53/53 - 4s - loss: 0.1665 - val_loss: 0.2200\n",
      "Epoch 26/120\n",
      "53/53 - 4s - loss: 0.1631 - val_loss: 0.2196\n",
      "Epoch 27/120\n",
      "53/53 - 4s - loss: 0.1590 - val_loss: 0.2192\n",
      "Epoch 28/120\n",
      "53/53 - 4s - loss: 0.1556 - val_loss: 0.2205\n",
      "Epoch 29/120\n",
      "53/53 - 4s - loss: 0.1527 - val_loss: 0.2186\n",
      "Epoch 30/120\n",
      "53/53 - 4s - loss: 0.1491 - val_loss: 0.2193\n",
      "Epoch 31/120\n",
      "53/53 - 4s - loss: 0.1467 - val_loss: 0.2194\n",
      "Epoch 32/120\n",
      "53/53 - 4s - loss: 0.1436 - val_loss: 0.2184\n",
      "Epoch 33/120\n",
      "53/53 - 4s - loss: 0.1407 - val_loss: 0.2183\n",
      "Epoch 34/120\n",
      "53/53 - 4s - loss: 0.1386 - val_loss: 0.2197\n",
      "Epoch 35/120\n",
      "53/53 - 4s - loss: 0.1359 - val_loss: 0.2199\n",
      "Epoch 36/120\n",
      "53/53 - 4s - loss: 0.1335 - val_loss: 0.2189\n",
      "Epoch 37/120\n",
      "53/53 - 4s - loss: 0.1313 - val_loss: 0.2190\n",
      "Epoch 38/120\n",
      "53/53 - 4s - loss: 0.1291 - val_loss: 0.2186\n",
      "Epoch 39/120\n",
      "53/53 - 4s - loss: 0.1272 - val_loss: 0.2193\n",
      "Epoch 40/120\n",
      "53/53 - 4s - loss: 0.1258 - val_loss: 0.2179\n",
      "Epoch 41/120\n",
      "53/53 - 4s - loss: 0.1237 - val_loss: 0.2190\n",
      "Epoch 42/120\n",
      "53/53 - 4s - loss: 0.1211 - val_loss: 0.2185\n",
      "Epoch 43/120\n",
      "53/53 - 4s - loss: 0.1196 - val_loss: 0.2189\n",
      "Epoch 44/120\n",
      "53/53 - 4s - loss: 0.1181 - val_loss: 0.2186\n",
      "Epoch 45/120\n",
      "53/53 - 5s - loss: 0.1164 - val_loss: 0.2193\n",
      "Epoch 46/120\n",
      "53/53 - 4s - loss: 0.1150 - val_loss: 0.2184\n",
      "Epoch 47/120\n",
      "53/53 - 4s - loss: 0.1141 - val_loss: 0.2188\n",
      "Epoch 48/120\n",
      "53/53 - 4s - loss: 0.1118 - val_loss: 0.2184\n",
      "Epoch 49/120\n",
      "53/53 - 4s - loss: 0.1109 - val_loss: 0.2192\n",
      "Epoch 50/120\n",
      "53/53 - 4s - loss: 0.1096 - val_loss: 0.2191\n",
      "Epoch 51/120\n",
      "53/53 - 4s - loss: 0.1041 - val_loss: 0.2171\n",
      "Epoch 52/120\n",
      "53/53 - 5s - loss: 0.1002 - val_loss: 0.2166\n",
      "Epoch 53/120\n",
      "53/53 - 4s - loss: 0.0985 - val_loss: 0.2167\n",
      "Epoch 54/120\n",
      "53/53 - 4s - loss: 0.0974 - val_loss: 0.2169\n",
      "Epoch 55/120\n",
      "53/53 - 4s - loss: 0.0964 - val_loss: 0.2168\n",
      "Epoch 56/120\n",
      "53/53 - 4s - loss: 0.0960 - val_loss: 0.2165\n",
      "Epoch 57/120\n",
      "53/53 - 4s - loss: 0.0951 - val_loss: 0.2167\n",
      "Epoch 58/120\n",
      "53/53 - 4s - loss: 0.0947 - val_loss: 0.2168\n",
      "Epoch 59/120\n",
      "53/53 - 4s - loss: 0.0943 - val_loss: 0.2167\n",
      "Epoch 60/120\n",
      "53/53 - 4s - loss: 0.0939 - val_loss: 0.2169\n",
      "Epoch 61/120\n",
      "53/53 - 4s - loss: 0.0934 - val_loss: 0.2168\n",
      "Epoch 62/120\n",
      "53/53 - 4s - loss: 0.0932 - val_loss: 0.2171\n",
      "Epoch 63/120\n",
      "53/53 - 5s - loss: 0.0925 - val_loss: 0.2170\n",
      "Epoch 64/120\n",
      "53/53 - 4s - loss: 0.0924 - val_loss: 0.2169\n",
      "Epoch 65/120\n",
      "53/53 - 4s - loss: 0.0923 - val_loss: 0.2168\n",
      "Epoch 66/120\n",
      "53/53 - 4s - loss: 0.0923 - val_loss: 0.2169\n",
      "Epoch 67/120\n",
      "53/53 - 4s - loss: 0.0922 - val_loss: 0.2169\n",
      "Epoch 68/120\n",
      "53/53 - 4s - loss: 0.0921 - val_loss: 0.2168\n",
      "Epoch 69/120\n",
      "53/53 - 4s - loss: 0.0921 - val_loss: 0.2170\n",
      "Epoch 70/120\n",
      "53/53 - 4s - loss: 0.0921 - val_loss: 0.2169\n",
      "Epoch 71/120\n",
      "53/53 - 4s - loss: 0.0920 - val_loss: 0.2170\n",
      "Epoch 72/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 73/120\n",
      "53/53 - 4s - loss: 0.0921 - val_loss: 0.2169\n",
      "Epoch 74/120\n",
      "53/53 - 4s - loss: 0.0920 - val_loss: 0.2169\n",
      "Epoch 75/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 76/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 77/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 78/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 79/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 80/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 81/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 82/120\n",
      "53/53 - 4s - loss: 0.0920 - val_loss: 0.2169\n",
      "Epoch 83/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 84/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 85/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 86/120\n",
      "53/53 - 4s - loss: 0.0920 - val_loss: 0.2169\n",
      "Epoch 87/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 88/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 89/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 90/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 91/120\n",
      "53/53 - 4s - loss: 0.0917 - val_loss: 0.2169\n",
      "Epoch 92/120\n",
      "53/53 - 4s - loss: 0.0920 - val_loss: 0.2169\n",
      "Epoch 93/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 94/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 95/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 96/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 97/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 98/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 99/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 100/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 101/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 102/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 103/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 104/120\n",
      "53/53 - 4s - loss: 0.0921 - val_loss: 0.2169\n",
      "Epoch 105/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 106/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 107/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 108/120\n",
      "53/53 - 4s - loss: 0.0916 - val_loss: 0.2169\n",
      "Epoch 109/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 110/120\n",
      "53/53 - 5s - loss: 0.0917 - val_loss: 0.2169\n",
      "Epoch 111/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 112/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 113/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 114/120\n",
      "53/53 - 4s - loss: 0.0920 - val_loss: 0.2169\n",
      "Epoch 115/120\n",
      "53/53 - 4s - loss: 0.0920 - val_loss: 0.2169\n",
      "Epoch 116/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 117/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "Epoch 118/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 119/120\n",
      "53/53 - 4s - loss: 0.0919 - val_loss: 0.2169\n",
      "Epoch 120/120\n",
      "53/53 - 4s - loss: 0.0918 - val_loss: 0.2169\n",
      "#################### 0.3892126120647565\n",
      "(629, 107, 5) (3005, 130, 5)\n"
     ]
    }
   ],
   "source": [
    "FOLDS = KFold(n_splits=5, random_state=815, shuffle=True)\n",
    "\n",
    "oofs_pred = np.zeros_like(train_labels)\n",
    "public_preds_array = []\n",
    "public_preds_array = []\n",
    "\n",
    "for i, (trn_idx, vld_idx) in enumerate(FOLDS.split(train_inputs)):\n",
    "    trn_inputs = train_inputs[trn_idx]\n",
    "    vld_inputs = train_inputs[vld_idx]\n",
    "    \n",
    "    trn_inputs_bpps = train_bpps[trn_idx]\n",
    "    vld_inputs_bpps = train_bpps[vld_idx]\n",
    "\n",
    "    trn_labels = train_labels[trn_idx]\n",
    "    vld_labels = train_labels[vld_idx]\n",
    "\n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        [trn_inputs, trn_inputs_bpps], trn_labels, \n",
    "        validation_data=([vld_inputs, vld_inputs_bpps], vld_labels),\n",
    "        batch_size=32,\n",
    "        epochs=120,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "            tf.keras.callbacks.ModelCheckpoint('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_815.h5')\n",
    "        ],\n",
    "        verbose=2,\n",
    "    )\n",
    "    model.load_weights('./tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_815.h5')\n",
    "    outputs = model.predict([vld_inputs, vld_inputs_bpps])\n",
    "    oofs_pred[vld_idx] = outputs\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    errors = []\n",
    "    for idx in range(5):\n",
    "         errors.append(np.sqrt(mean_squared_error(vld_labels[:, idx], outputs[:, idx])))\n",
    "    final_error = np.mean(errors)\n",
    "    print('#'*20, final_error)\n",
    "\n",
    "    public_df = test.query(\"seq_length == 107\").copy()\n",
    "    private_df = test.query(\"seq_length == 130\").copy()\n",
    "\n",
    "    public_inputs = preprocess_inputs(public_df)\n",
    "    private_inputs = preprocess_inputs(private_df)\n",
    "    \n",
    "    public_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in public_df['id']])\n",
    "    public_bpps = public_bpps[:, :, np.newaxis]\n",
    "    \n",
    "    private_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in private_df['id']])\n",
    "    private_bpps = private_bpps[:, :, np.newaxis] \n",
    "\n",
    "    # Caveat: The prediction format requires the output to be the same length as the input,\n",
    "    # although it's not the case for the training data.\n",
    "    model_short = build_model(seq_len=107, pred_len=107)\n",
    "    model_long = build_model(seq_len=130, pred_len=130)\n",
    "\n",
    "    model_short.load_weights('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_815.h5')\n",
    "    model_long.load_weights('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_815.h5')\n",
    "\n",
    "    public_preds = model_short.predict([public_inputs, public_bpps])\n",
    "    private_preds = model_long.predict([private_inputs,private_bpps])\n",
    "    \n",
    "    public_preds_array.append(public_preds)\n",
    "    public_preds_array.append(private_preds)\n",
    "\n",
    "    print(public_preds.shape, private_preds.shape)\n",
    "\n",
    "    preds_ls = []\n",
    "\n",
    "    for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
    "        for idx, uid in enumerate(df.id):\n",
    "            single_pred = preds[idx]\n",
    "\n",
    "            single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "            preds_ls.append(single_df)\n",
    "\n",
    "    preds_df = pd.concat(preds_ls)\n",
    "\n",
    "    submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "    submission.to_csv(f'submission_tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_815_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, uid in enumerate(train.id):\n",
    "#     single_pred = oofs_pred[i]\n",
    "\n",
    "#     oof_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "#     oof_df['id_seqpos'] = [f'{uid}_{x}' for x in range(oof_df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyh",
   "language": "python",
   "name": "lyh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 161.997015,
   "end_time": "2020-09-12T05:49:46.470488",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-12T05:47:04.473473",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
