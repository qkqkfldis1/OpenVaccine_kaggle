{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:08.823964Z",
     "iopub.status.busy": "2020-09-12T05:47:08.823205Z",
     "iopub.status.idle": "2020-09-12T05:47:15.758339Z",
     "shell.execute_reply": "2020-09-12T05:47:15.757303Z"
    },
    "papermill": {
     "duration": 6.954489,
     "end_time": "2020-09-12T05:47:15.758481",
     "exception": false,
     "start_time": "2020-09-12T05:47:08.803992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow as tf\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01294,
     "end_time": "2020-09-12T05:47:15.784990",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.772050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define helper functions and useful vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.817688Z",
     "iopub.status.busy": "2020-09-12T05:47:15.815907Z",
     "iopub.status.idle": "2020-09-12T05:47:15.818497Z",
     "shell.execute_reply": "2020-09-12T05:47:15.818980Z"
    },
    "papermill": {
     "duration": 0.020522,
     "end_time": "2020-09-12T05:47:15.819094",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.798572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will tell us the columns we are predicting\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.856138Z",
     "iopub.status.busy": "2020-09-12T05:47:15.855349Z",
     "iopub.status.idle": "2020-09-12T05:47:15.859535Z",
     "shell.execute_reply": "2020-09-12T05:47:15.859055Z"
    },
    "papermill": {
     "duration": 0.027513,
     "end_time": "2020-09-12T05:47:15.859623",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.832110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.GRU(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "                                tf.keras.layers.LSTM(hidden_dim,\n",
    "                                dropout=dropout,\n",
    "                                return_sequences=True,\n",
    "                                kernel_initializer = 'orthogonal'))\n",
    "\n",
    "def build_model(gru=False,seq_len=107, pred_len=68, dropout=0.25,\n",
    "                embed_dim=128, hidden_dim=384):\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(seq_len, 7))\n",
    "    \n",
    "    inputs_bpps = tf.keras.layers.Input(shape=(seq_len, 1))\n",
    "    \n",
    "\n",
    "    embed0 = tf.keras.layers.Embedding(input_dim=len(token2int0), output_dim=embed_dim)(inputs[:, :, 0])\n",
    "    embed1 = tf.keras.layers.Embedding(input_dim=len(token2int1), output_dim=embed_dim)(inputs[:, :, 1])\n",
    "    embed2 = tf.keras.layers.Embedding(input_dim=len(token2int2), output_dim=embed_dim)(inputs[:, :, 2])\n",
    "    embed3 = tf.keras.layers.Embedding(input_dim=len(token2int2), output_dim=embed_dim)(inputs[:, :, 3])\n",
    "    embed4 = tf.keras.layers.Embedding(input_dim=len(token2int2), output_dim=embed_dim)(inputs[:, :, 4])\n",
    "    embed5 = tf.keras.layers.Embedding(input_dim=len(token2int2), output_dim=embed_dim)(inputs[:, :, 5])\n",
    "    embed6 = tf.keras.layers.Embedding(input_dim=len(token2int2), output_dim=embed_dim)(inputs[:, :, 6])\n",
    "    \n",
    "    \n",
    "    embed0 = tf.keras.layers.SpatialDropout1D(.2)(embed0)\n",
    "    embed1 = tf.keras.layers.SpatialDropout1D(.2)(embed1)\n",
    "    embed2 = tf.keras.layers.SpatialDropout1D(.2)(embed2)\n",
    "    embed3 = tf.keras.layers.SpatialDropout1D(.2)(embed3)\n",
    "    embed4 = tf.keras.layers.SpatialDropout1D(.2)(embed4)\n",
    "    embed5 = tf.keras.layers.SpatialDropout1D(.2)(embed5)\n",
    "    embed6 = tf.keras.layers.SpatialDropout1D(.2)(embed6)\n",
    "    \n",
    "    embed = tf.concat([embed0, embed1, embed2, embed3, embed4, embed5, embed6], axis=2)\n",
    "    \n",
    "    #reshaped = tf.reshape(\n",
    "    #    embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n",
    "    \n",
    "    embed = tf.keras.layers.SpatialDropout1D(.2)(embed)\n",
    "    \n",
    "    bpps = tf.keras.layers.Dense(embed_dim, activation='linear')(inputs_bpps)\n",
    "    \n",
    "    embed = tf.concat([embed, bpps], axis=2)\n",
    "    print(embed.shape)\n",
    "    \n",
    "    transformer_block = TransformerBlock(1024, 8, 1024)\n",
    "    embed = transformer_block(embed)\n",
    "    \n",
    "    hidden = gru_layer(hidden_dim, dropout)(embed)\n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "\n",
    "    \n",
    "    #only making predictions on the first part of each sequence\n",
    "    truncated = hidden[:, :pred_len]\n",
    "    \n",
    "    out1 = tf.keras.layers.Dense(5, activation='linear', name='out1')(truncated)\n",
    "    out2 = tf.keras.layers.Dense(5, activation='linear', name='out2')(truncated)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs, inputs_bpps], outputs=[out1, out2])\n",
    "\n",
    "    #some optimizers\n",
    "    adam = tf.optimizers.Adam()\n",
    "    def MCRMSE(y_true, y_pred):\n",
    "        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n",
    "    \n",
    "    model.compile(optimizer = adam, loss={'out1': MCRMSE, 'out2': 'mae'}, loss_weights={'out1': 0.7, 'out2': 0.3})\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.894673Z",
     "iopub.status.busy": "2020-09-12T05:47:15.893039Z",
     "iopub.status.idle": "2020-09-12T05:47:15.895372Z",
     "shell.execute_reply": "2020-09-12T05:47:15.895926Z"
    },
    "papermill": {
     "duration": 0.023046,
     "end_time": "2020-09-12T05:47:15.896053",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.873007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    return np.transpose(\n",
    "        np.array(\n",
    "            df[cols]\n",
    "            .applymap(lambda seq: [token2int[x] for x in seq])\n",
    "            .values\n",
    "            .tolist()\n",
    "        ),\n",
    "        (0, 2, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013134,
     "end_time": "2020-09-12T05:47:15.922732",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.909598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "      <th>reactivity_error</th>\n",
       "      <th>...</th>\n",
       "      <th>deg_error_50C</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "      <th>structure_gamma0</th>\n",
       "      <th>structure_gamma1</th>\n",
       "      <th>structure_gamma2</th>\n",
       "      <th>structure_gamma3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_001f94081</td>\n",
       "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
       "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
       "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
       "      <td>6.894</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
       "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
       "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
       "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
       "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
       "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>.......((((.......)))).((((((.((..)).))))))......</td>\n",
       "      <td>(.....(((((.......))))(((((((.((..)).)))))).)....</td>\n",
       "      <td>((....(((((..(...)))))(((((((.((..)).)))))).)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>id_0049f53ba</td>\n",
       "      <td>GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...</td>\n",
       "      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "      <td>EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...</td>\n",
       "      <td>...</td>\n",
       "      <td>[15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "      <td>..(..(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "      <td>(((..(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id_006f36f57</td>\n",
       "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
       "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
       "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
       "      <td>8.800</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
       "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
       "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
       "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
       "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
       "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
       "      <td>...................................((((......)...</td>\n",
       "      <td>.....(((((.((.....)).)))((((...((..((((......)...</td>\n",
       "      <td>(....(((((.((.....)).)((((((.(.((.(((((......)...</td>\n",
       "      <td>((...(((((.((.....)).)))((((.(.((.(((((.(...))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>id_0082d463b</td>\n",
       "      <td>GGAAAAGCGCGCGCGCGCGCGCGAAAAAGCGCGCGCGCGCGCGCGC...</td>\n",
       "      <td>......((((((((((((((((......))))))))))))))))((...</td>\n",
       "      <td>EEEEEESSSSSSSSSSSSSSSSHHHHHHSSSSSSSSSSSSSSSSSS...</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[3.5229, 6.0748, 3.0374, 3.0374, 3.0374, 3.037...</td>\n",
       "      <td>...</td>\n",
       "      <td>[15.3995, 8.1124, 7.7824, 7.7824, 7.7824, 7.78...</td>\n",
       "      <td>[0.0, 2.2399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.0, -0.5083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[3.4248, 6.8128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, -0.8365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>......(((((((((((((((((......)))))))))))))))))...</td>\n",
       "      <td>((....(((((((((((((((((......)))))))))))))))))...</td>\n",
       "      <td>((....(((((((((((((((((......)))))))))))))))))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>id_0087940f4</td>\n",
       "      <td>GGAAAAUAUAUAAUAUAUUAUAUAAAUAUAUUAUAGAAGUAUAAUA...</td>\n",
       "      <td>.....(((((((.((((((((((((.(((((((((....)))))))...</td>\n",
       "      <td>EEEEESSSSSSSBSSSSSSSSSSSSBSSSSSSSSSHHHHSSSSSSS...</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[1.665, 2.1728, 2.0041, 1.2405, 0.620200000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.3285, 3.6173, 1.3057, 1.3021, 1.1507, 1.150...</td>\n",
       "      <td>[0.8267, 2.6577, 2.8481, 0.40090000000000003, ...</td>\n",
       "      <td>[2.1058, 3.138, 2.5437000000000003, 1.0932, 0....</td>\n",
       "      <td>[4.7366, 4.6243, 1.2068, 1.1538, 0.0, 0.0, 0.7...</td>\n",
       "      <td>[2.2052, 1.7947000000000002, 0.7457, 3.1233, 0...</td>\n",
       "      <td>[0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>......(((((..(((((((((((.((((((((((....)))))))...</td>\n",
       "      <td>.....((((((.((((((((((((.((((((((((....)))))))...</td>\n",
       "      <td>.....((((((.((((((((((((.((((((((((....)))))))...</td>\n",
       "      <td>((...((((((.((((((((((((.((((((((((....)))))))...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id                                           sequence  \\\n",
       "0      0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n",
       "1      1  id_0049f53ba  GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...   \n",
       "2      2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n",
       "3      3  id_0082d463b  GGAAAAGCGCGCGCGCGCGCGCGAAAAAGCGCGCGCGCGCGCGCGC...   \n",
       "4      4  id_0087940f4  GGAAAAUAUAUAAUAUAUUAUAUAAAUAUAUUAUAGAAGUAUAAUA...   \n",
       "\n",
       "                                           structure  \\\n",
       "0  .....((((((.......)))).)).((.....((..((((((......   \n",
       "1  .....(((((((((((((((((((((((....)))))))))).)))...   \n",
       "2  .....((((.((.....((((.(((.....)))..((((......)...   \n",
       "3  ......((((((((((((((((......))))))))))))))))((...   \n",
       "4  .....(((((((.((((((((((((.(((((((((....)))))))...   \n",
       "\n",
       "                                 predicted_loop_type  signal_to_noise  \\\n",
       "0  EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n",
       "1  EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...            0.193   \n",
       "2  EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n",
       "3  EEEEEESSSSSSSSSSSSSSSSHHHHHHSSSSSSSSSSSSSSSSSS...            0.104   \n",
       "4  EEEEESSSSSSSBSSSSSSSSSSSSBSSSSSSSSSHHHHSSSSSSS...            0.423   \n",
       "\n",
       "   SN_filter  seq_length  seq_scored  \\\n",
       "0          1         107          68   \n",
       "1          0         107          68   \n",
       "2          1         107          68   \n",
       "3          0         107          68   \n",
       "4          0         107          68   \n",
       "\n",
       "                                    reactivity_error  ...  \\\n",
       "0  [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...  ...   \n",
       "1  [2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...  ...   \n",
       "2  [0.0931, 0.13290000000000002, 0.11280000000000...  ...   \n",
       "3  [3.5229, 6.0748, 3.0374, 3.0374, 3.0374, 3.037...  ...   \n",
       "4  [1.665, 2.1728, 2.0041, 1.2405, 0.620200000000...  ...   \n",
       "\n",
       "                                       deg_error_50C  \\\n",
       "0  [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...   \n",
       "1  [15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...   \n",
       "2  [0.14980000000000002, 0.1761, 0.1517, 0.116700...   \n",
       "3  [15.3995, 8.1124, 7.7824, 7.7824, 7.7824, 7.78...   \n",
       "4  [1.3285, 3.6173, 1.3057, 1.3021, 1.1507, 1.150...   \n",
       "\n",
       "                                          reactivity  \\\n",
       "0  [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n",
       "1  [0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "2  [0.44820000000000004, 1.4822, 1.1819, 0.743400...   \n",
       "3  [0.0, 2.2399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "4  [0.8267, 2.6577, 2.8481, 0.40090000000000003, ...   \n",
       "\n",
       "                                         deg_Mg_pH10  \\\n",
       "0  [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n",
       "3  [0.0, -0.5083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "4  [2.1058, 3.138, 2.5437000000000003, 1.0932, 0....   \n",
       "\n",
       "                                            deg_pH10  \\\n",
       "0  [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n",
       "1  [4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n",
       "3  [3.4248, 6.8128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4  [4.7366, 4.6243, 1.2068, 1.1538, 0.0, 0.0, 0.7...   \n",
       "\n",
       "                                          deg_Mg_50C  \\\n",
       "0  [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n",
       "1  [4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n",
       "3  [0.0, -0.8365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "4  [2.2052, 1.7947000000000002, 0.7457, 3.1233, 0...   \n",
       "\n",
       "                                             deg_50C  \\\n",
       "0  [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...   \n",
       "1  [7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  [0.9501000000000001, 1.7974999999999999, 1.499...   \n",
       "3  [7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                    structure_gamma0  \\\n",
       "0  .................................................   \n",
       "1  .....(((((((((((((((((((((((....)))))))))).)))...   \n",
       "2  ...................................((((......)...   \n",
       "3  .................................................   \n",
       "4  ......(((((..(((((((((((.((((((((((....)))))))...   \n",
       "\n",
       "                                    structure_gamma1  \\\n",
       "0  .......((((.......)))).((((((.((..)).))))))......   \n",
       "1  .....(((((((((((((((((((((((....)))))))))).)))...   \n",
       "2  .....(((((.((.....)).)))((((...((..((((......)...   \n",
       "3  ......(((((((((((((((((......)))))))))))))))))...   \n",
       "4  .....((((((.((((((((((((.((((((((((....)))))))...   \n",
       "\n",
       "                                    structure_gamma2  \\\n",
       "0  (.....(((((.......))))(((((((.((..)).)))))).)....   \n",
       "1  ..(..(((((((((((((((((((((((....)))))))))).)))...   \n",
       "2  (....(((((.((.....)).)((((((.(.((.(((((......)...   \n",
       "3  ((....(((((((((((((((((......)))))))))))))))))...   \n",
       "4  .....((((((.((((((((((((.((((((((((....)))))))...   \n",
       "\n",
       "                                    structure_gamma3  \n",
       "0  ((....(((((..(...)))))(((((((.((..)).)))))).)....  \n",
       "1  (((..(((((((((((((((((((((((....)))))))))).)))...  \n",
       "2  ((...(((((.((.....)).)))((((.(.((.(((((.(...))...  \n",
       "3  ((....(((((((((((((((((......)))))))))))))))))...  \n",
       "4  ((...((((((.((((((((((((.((((((((((....)))))))...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-12T05:47:15.957048Z",
     "iopub.status.busy": "2020-09-12T05:47:15.956359Z",
     "iopub.status.idle": "2020-09-12T05:47:16.951033Z",
     "shell.execute_reply": "2020-09-12T05:47:16.950138Z"
    },
    "papermill": {
     "duration": 1.012628,
     "end_time": "2020-09-12T05:47:16.951150",
     "exception": false,
     "start_time": "2020-09-12T05:47:15.938522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_target = pd.read_json('../input//train.json', lines=True)\n",
    "#test = pd.read_json('../input//test.json', lines=True)\n",
    "train = pd.read_csv('../input/train_v1.csv')\n",
    "test = pd.read_csv('../input/test_v1.csv')\n",
    "sample_df = pd.read_csv('../input//sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "      <th>reactivity_error</th>\n",
       "      <th>...</th>\n",
       "      <th>deg_error_50C</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "      <th>structure_gamma0</th>\n",
       "      <th>structure_gamma1</th>\n",
       "      <th>structure_gamma2</th>\n",
       "      <th>structure_gamma3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_001f94081</td>\n",
       "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
       "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
       "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
       "      <td>6.894</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
       "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
       "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
       "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
       "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
       "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>.......((((.......)))).((((((.((..)).))))))......</td>\n",
       "      <td>(.....(((((.......))))(((((((.((..)).)))))).)....</td>\n",
       "      <td>((....(((((..(...)))))(((((((.((..)).)))))).)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>id_0049f53ba</td>\n",
       "      <td>GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...</td>\n",
       "      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "      <td>EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...</td>\n",
       "      <td>...</td>\n",
       "      <td>[15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "      <td>..(..(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "      <td>(((..(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id_006f36f57</td>\n",
       "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
       "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
       "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
       "      <td>8.800</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
       "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
       "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
       "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
       "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
       "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
       "      <td>...................................((((......)...</td>\n",
       "      <td>.....(((((.((.....)).)))((((...((..((((......)...</td>\n",
       "      <td>(....(((((.((.....)).)((((((.(.((.(((((......)...</td>\n",
       "      <td>((...(((((.((.....)).)))((((.(.((.(((((.(...))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>id_0082d463b</td>\n",
       "      <td>GGAAAAGCGCGCGCGCGCGCGCGAAAAAGCGCGCGCGCGCGCGCGC...</td>\n",
       "      <td>......((((((((((((((((......))))))))))))))))((...</td>\n",
       "      <td>EEEEEESSSSSSSSSSSSSSSSHHHHHHSSSSSSSSSSSSSSSSSS...</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[3.5229, 6.0748, 3.0374, 3.0374, 3.0374, 3.037...</td>\n",
       "      <td>...</td>\n",
       "      <td>[15.3995, 8.1124, 7.7824, 7.7824, 7.7824, 7.78...</td>\n",
       "      <td>[0.0, 2.2399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.0, -0.5083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[3.4248, 6.8128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, -0.8365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>......(((((((((((((((((......)))))))))))))))))...</td>\n",
       "      <td>((....(((((((((((((((((......)))))))))))))))))...</td>\n",
       "      <td>((....(((((((((((((((((......)))))))))))))))))...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>id_0087940f4</td>\n",
       "      <td>GGAAAAUAUAUAAUAUAUUAUAUAAAUAUAUUAUAGAAGUAUAAUA...</td>\n",
       "      <td>.....(((((((.((((((((((((.(((((((((....)))))))...</td>\n",
       "      <td>EEEEESSSSSSSBSSSSSSSSSSSSBSSSSSSSSSHHHHSSSSSSS...</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[1.665, 2.1728, 2.0041, 1.2405, 0.620200000000...</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.3285, 3.6173, 1.3057, 1.3021, 1.1507, 1.150...</td>\n",
       "      <td>[0.8267, 2.6577, 2.8481, 0.40090000000000003, ...</td>\n",
       "      <td>[2.1058, 3.138, 2.5437000000000003, 1.0932, 0....</td>\n",
       "      <td>[4.7366, 4.6243, 1.2068, 1.1538, 0.0, 0.0, 0.7...</td>\n",
       "      <td>[2.2052, 1.7947000000000002, 0.7457, 3.1233, 0...</td>\n",
       "      <td>[0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>......(((((..(((((((((((.((((((((((....)))))))...</td>\n",
       "      <td>.....((((((.((((((((((((.((((((((((....)))))))...</td>\n",
       "      <td>.....((((((.((((((((((((.((((((((((....)))))))...</td>\n",
       "      <td>((...((((((.((((((((((((.((((((((((....)))))))...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id                                           sequence  \\\n",
       "0      0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n",
       "1      1  id_0049f53ba  GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...   \n",
       "2      2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n",
       "3      3  id_0082d463b  GGAAAAGCGCGCGCGCGCGCGCGAAAAAGCGCGCGCGCGCGCGCGC...   \n",
       "4      4  id_0087940f4  GGAAAAUAUAUAAUAUAUUAUAUAAAUAUAUUAUAGAAGUAUAAUA...   \n",
       "\n",
       "                                           structure  \\\n",
       "0  .....((((((.......)))).)).((.....((..((((((......   \n",
       "1  .....(((((((((((((((((((((((....)))))))))).)))...   \n",
       "2  .....((((.((.....((((.(((.....)))..((((......)...   \n",
       "3  ......((((((((((((((((......))))))))))))))))((...   \n",
       "4  .....(((((((.((((((((((((.(((((((((....)))))))...   \n",
       "\n",
       "                                 predicted_loop_type  signal_to_noise  \\\n",
       "0  EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n",
       "1  EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...            0.193   \n",
       "2  EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n",
       "3  EEEEEESSSSSSSSSSSSSSSSHHHHHHSSSSSSSSSSSSSSSSSS...            0.104   \n",
       "4  EEEEESSSSSSSBSSSSSSSSSSSSBSSSSSSSSSHHHHSSSSSSS...            0.423   \n",
       "\n",
       "   SN_filter  seq_length  seq_scored  \\\n",
       "0          1         107          68   \n",
       "1          0         107          68   \n",
       "2          1         107          68   \n",
       "3          0         107          68   \n",
       "4          0         107          68   \n",
       "\n",
       "                                    reactivity_error  ...  \\\n",
       "0  [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...  ...   \n",
       "1  [2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...  ...   \n",
       "2  [0.0931, 0.13290000000000002, 0.11280000000000...  ...   \n",
       "3  [3.5229, 6.0748, 3.0374, 3.0374, 3.0374, 3.037...  ...   \n",
       "4  [1.665, 2.1728, 2.0041, 1.2405, 0.620200000000...  ...   \n",
       "\n",
       "                                       deg_error_50C  \\\n",
       "0  [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...   \n",
       "1  [15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...   \n",
       "2  [0.14980000000000002, 0.1761, 0.1517, 0.116700...   \n",
       "3  [15.3995, 8.1124, 7.7824, 7.7824, 7.7824, 7.78...   \n",
       "4  [1.3285, 3.6173, 1.3057, 1.3021, 1.1507, 1.150...   \n",
       "\n",
       "                                          reactivity  \\\n",
       "0  [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n",
       "1  [0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "2  [0.44820000000000004, 1.4822, 1.1819, 0.743400...   \n",
       "3  [0.0, 2.2399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "4  [0.8267, 2.6577, 2.8481, 0.40090000000000003, ...   \n",
       "\n",
       "                                         deg_Mg_pH10  \\\n",
       "0  [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n",
       "3  [0.0, -0.5083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "4  [2.1058, 3.138, 2.5437000000000003, 1.0932, 0....   \n",
       "\n",
       "                                            deg_pH10  \\\n",
       "0  [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n",
       "1  [4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n",
       "3  [3.4248, 6.8128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4  [4.7366, 4.6243, 1.2068, 1.1538, 0.0, 0.0, 0.7...   \n",
       "\n",
       "                                          deg_Mg_50C  \\\n",
       "0  [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n",
       "1  [4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n",
       "3  [0.0, -0.8365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "4  [2.2052, 1.7947000000000002, 0.7457, 3.1233, 0...   \n",
       "\n",
       "                                             deg_50C  \\\n",
       "0  [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...   \n",
       "1  [7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "2  [0.9501000000000001, 1.7974999999999999, 1.499...   \n",
       "3  [7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...   \n",
       "4  [0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                    structure_gamma0  \\\n",
       "0  .................................................   \n",
       "1  .....(((((((((((((((((((((((....)))))))))).)))...   \n",
       "2  ...................................((((......)...   \n",
       "3  .................................................   \n",
       "4  ......(((((..(((((((((((.((((((((((....)))))))...   \n",
       "\n",
       "                                    structure_gamma1  \\\n",
       "0  .......((((.......)))).((((((.((..)).))))))......   \n",
       "1  .....(((((((((((((((((((((((....)))))))))).)))...   \n",
       "2  .....(((((.((.....)).)))((((...((..((((......)...   \n",
       "3  ......(((((((((((((((((......)))))))))))))))))...   \n",
       "4  .....((((((.((((((((((((.((((((((((....)))))))...   \n",
       "\n",
       "                                    structure_gamma2  \\\n",
       "0  (.....(((((.......))))(((((((.((..)).)))))).)....   \n",
       "1  ..(..(((((((((((((((((((((((....)))))))))).)))...   \n",
       "2  (....(((((.((.....)).)((((((.(.((.(((((......)...   \n",
       "3  ((....(((((((((((((((((......)))))))))))))))))...   \n",
       "4  .....((((((.((((((((((((.((((((((((....)))))))...   \n",
       "\n",
       "                                    structure_gamma3  \n",
       "0  ((....(((((..(...)))))(((((((.((..)).)))))).)....  \n",
       "1  (((..(((((((((((((((((((((((....)))))))))).)))...  \n",
       "2  ((...(((((.((.....)).)))((((.(.((.(((((.(...))...  \n",
       "3  ((....(((((((((((((((((......)))))))))))))))))...  \n",
       "4  ((...((((((.((((((((((((.((((((((((....)))))))...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target columns\n",
    "target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2int0 = {'G': 0, 'A': 1, 'C': 2, 'U': 3}\n",
    "token2int1 = {'.': 0,  '(': 1, ')': 2}\n",
    "token2int2 = {'E': 0, 'S': 1, 'H': 2, 'B': 3, 'X': 4, 'I': 5, 'M': 6}\n",
    "\n",
    "def convert_seq(x, tmp_dict):\n",
    "    return [tmp_dict[ele] for ele in x]\n",
    "\n",
    "train['sequence'] = train['sequence'].apply(lambda x: [token2int0[ele] for ele in x])\n",
    "train['structure'] = train['structure'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "train['structure_gamma0'] = train['structure_gamma0'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "train['structure_gamma1'] = train['structure_gamma1'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "train['structure_gamma2'] = train['structure_gamma2'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "train['structure_gamma3'] = train['structure_gamma3'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "train['predicted_loop_type'] = train['predicted_loop_type'].apply(lambda x: [token2int2[ele] for ele in x])\n",
    "\n",
    "train_inputs = np.transpose(np.array(train[['sequence', 'structure', 'structure_gamma0', 'structure_gamma1', \n",
    "                                            'structure_gamma2', 'structure_gamma3','predicted_loop_type']].values.tolist()), (0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = train_inputs[train.signal_to_noise > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 107, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_target[train_target.signal_to_noise > 1][target_cols].values.tolist()).transpose((0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in train['id']])\n",
    "train_bpps = train_bpps[train.signal_to_noise > 1][:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=8):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  # (batch_size, seq_len, embed_dim)\n",
    "        return output\n",
    "    \n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        return config\n",
    "    \n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 68, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros_like(train_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 107, 1024)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 107, 7)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 107)]        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 107, 128)     512         tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 107, 128)     384         tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 107, 128)     896         tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 107, 128)     896         tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 107, 128)     896         tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 107, 128)     896         tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 107, 128)     896         tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 107, 128)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 107, 128)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 107, 128)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 107, 128)     0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 107, 128)     0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 107, 128)     0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 107, 128)     0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 107, 896)]   0           spatial_dropout1d[0][0]          \n",
      "                                                                 spatial_dropout1d_1[0][0]        \n",
      "                                                                 spatial_dropout1d_2[0][0]        \n",
      "                                                                 spatial_dropout1d_3[0][0]        \n",
      "                                                                 spatial_dropout1d_4[0][0]        \n",
      "                                                                 spatial_dropout1d_5[0][0]        \n",
      "                                                                 spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_7 (SpatialDro (None, 107, 896)     0           tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 107, 128)     256         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_1 (TensorFlo [(None, 107, 1024)]  0           spatial_dropout1d_7[0][0]        \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block (TransformerB (None, 107, 1024)    6301696     tf_op_layer_concat_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 107, 768)     3248640     transformer_block[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 107, 768)     2658816     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 107, 768)     2658816     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [(None, 68, 768)]    0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_7[0][0]\n",
      "==================================================================================================\n",
      "Total params: 14,881,290\n",
      "Trainable params: 14,881,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n",
      "53/53 - 6s - loss: 0.7284 - out1_loss: 0.7677 - out2_loss: 0.6368 - val_loss: 0.3891 - val_out1_loss: 0.4273 - val_out2_loss: 0.2999\n",
      "Epoch 2/120\n",
      "53/53 - 5s - loss: 0.3872 - out1_loss: 0.4275 - out2_loss: 0.2931 - val_loss: 0.3767 - val_out1_loss: 0.4152 - val_out2_loss: 0.2870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/120\n",
      "53/53 - 5s - loss: 0.3804 - out1_loss: 0.4201 - out2_loss: 0.2876 - val_loss: 0.3576 - val_out1_loss: 0.3942 - val_out2_loss: 0.2722\n",
      "Epoch 4/120\n",
      "53/53 - 5s - loss: 0.3496 - out1_loss: 0.3879 - out2_loss: 0.2601 - val_loss: 0.3403 - val_out1_loss: 0.3787 - val_out2_loss: 0.2508\n",
      "Epoch 5/120\n",
      "53/53 - 5s - loss: 0.3325 - out1_loss: 0.3692 - out2_loss: 0.2467 - val_loss: 0.3192 - val_out1_loss: 0.3520 - val_out2_loss: 0.2427\n",
      "Epoch 6/120\n",
      "53/53 - 5s - loss: 0.3161 - out1_loss: 0.3518 - out2_loss: 0.2326 - val_loss: 0.3043 - val_out1_loss: 0.3393 - val_out2_loss: 0.2225\n",
      "Epoch 7/120\n",
      "53/53 - 5s - loss: 0.3048 - out1_loss: 0.3405 - out2_loss: 0.2214 - val_loss: 0.2887 - val_out1_loss: 0.3222 - val_out2_loss: 0.2105\n",
      "Epoch 8/120\n",
      "53/53 - 5s - loss: 0.2918 - out1_loss: 0.3257 - out2_loss: 0.2127 - val_loss: 0.2819 - val_out1_loss: 0.3148 - val_out2_loss: 0.2053\n",
      "Epoch 9/120\n",
      "53/53 - 5s - loss: 0.2846 - out1_loss: 0.3178 - out2_loss: 0.2072 - val_loss: 0.2698 - val_out1_loss: 0.3006 - val_out2_loss: 0.1979\n",
      "Epoch 10/120\n",
      "53/53 - 5s - loss: 0.2735 - out1_loss: 0.3055 - out2_loss: 0.1987 - val_loss: 0.2661 - val_out1_loss: 0.2957 - val_out2_loss: 0.1971\n",
      "Epoch 11/120\n",
      "53/53 - 5s - loss: 0.2659 - out1_loss: 0.2967 - out2_loss: 0.1939 - val_loss: 0.2583 - val_out1_loss: 0.2855 - val_out2_loss: 0.1950\n",
      "Epoch 12/120\n",
      "53/53 - 5s - loss: 0.2583 - out1_loss: 0.2881 - out2_loss: 0.1888 - val_loss: 0.2493 - val_out1_loss: 0.2763 - val_out2_loss: 0.1865\n",
      "Epoch 13/120\n",
      "53/53 - 5s - loss: 0.2518 - out1_loss: 0.2807 - out2_loss: 0.1843 - val_loss: 0.2468 - val_out1_loss: 0.2742 - val_out2_loss: 0.1830\n",
      "Epoch 14/120\n",
      "53/53 - 5s - loss: 0.2452 - out1_loss: 0.2731 - out2_loss: 0.1800 - val_loss: 0.2435 - val_out1_loss: 0.2689 - val_out2_loss: 0.1842\n",
      "Epoch 15/120\n",
      "53/53 - 5s - loss: 0.2410 - out1_loss: 0.2683 - out2_loss: 0.1773 - val_loss: 0.2362 - val_out1_loss: 0.2636 - val_out2_loss: 0.1723\n",
      "Epoch 16/120\n",
      "53/53 - 5s - loss: 0.2353 - out1_loss: 0.2618 - out2_loss: 0.1733 - val_loss: 0.2372 - val_out1_loss: 0.2646 - val_out2_loss: 0.1735\n",
      "Epoch 17/120\n",
      "53/53 - 5s - loss: 0.2314 - out1_loss: 0.2578 - out2_loss: 0.1698 - val_loss: 0.2281 - val_out1_loss: 0.2532 - val_out2_loss: 0.1697\n",
      "Epoch 18/120\n",
      "53/53 - 5s - loss: 0.2237 - out1_loss: 0.2486 - out2_loss: 0.1656 - val_loss: 0.2277 - val_out1_loss: 0.2515 - val_out2_loss: 0.1720\n",
      "Epoch 19/120\n",
      "53/53 - 5s - loss: 0.2181 - out1_loss: 0.2420 - out2_loss: 0.1622 - val_loss: 0.2184 - val_out1_loss: 0.2399 - val_out2_loss: 0.1681\n",
      "Epoch 20/120\n",
      "53/53 - 5s - loss: 0.2165 - out1_loss: 0.2397 - out2_loss: 0.1624 - val_loss: 0.2211 - val_out1_loss: 0.2444 - val_out2_loss: 0.1669\n",
      "Epoch 21/120\n",
      "53/53 - 5s - loss: 0.2126 - out1_loss: 0.2357 - out2_loss: 0.1588 - val_loss: 0.2192 - val_out1_loss: 0.2430 - val_out2_loss: 0.1636\n",
      "Epoch 22/120\n",
      "53/53 - 5s - loss: 0.2079 - out1_loss: 0.2303 - out2_loss: 0.1556 - val_loss: 0.2120 - val_out1_loss: 0.2341 - val_out2_loss: 0.1604\n",
      "Epoch 23/120\n",
      "53/53 - 5s - loss: 0.2045 - out1_loss: 0.2266 - out2_loss: 0.1530 - val_loss: 0.2150 - val_out1_loss: 0.2384 - val_out2_loss: 0.1604\n",
      "Epoch 24/120\n",
      "53/53 - 6s - loss: 0.2015 - out1_loss: 0.2238 - out2_loss: 0.1496 - val_loss: 0.2142 - val_out1_loss: 0.2381 - val_out2_loss: 0.1584\n",
      "Epoch 25/120\n",
      "53/53 - 5s - loss: 0.1996 - out1_loss: 0.2213 - out2_loss: 0.1492 - val_loss: 0.2091 - val_out1_loss: 0.2316 - val_out2_loss: 0.1565\n",
      "Epoch 26/120\n",
      "53/53 - 6s - loss: 0.1974 - out1_loss: 0.2189 - out2_loss: 0.1473 - val_loss: 0.2088 - val_out1_loss: 0.2312 - val_out2_loss: 0.1563\n",
      "Epoch 27/120\n",
      "53/53 - 6s - loss: 0.1945 - out1_loss: 0.2157 - out2_loss: 0.1450 - val_loss: 0.2116 - val_out1_loss: 0.2347 - val_out2_loss: 0.1577\n",
      "Epoch 28/120\n",
      "53/53 - 6s - loss: 0.1952 - out1_loss: 0.2159 - out2_loss: 0.1467 - val_loss: 0.2091 - val_out1_loss: 0.2323 - val_out2_loss: 0.1550\n",
      "Epoch 29/120\n",
      "53/53 - 6s - loss: 0.1901 - out1_loss: 0.2103 - out2_loss: 0.1431 - val_loss: 0.2069 - val_out1_loss: 0.2286 - val_out2_loss: 0.1564\n",
      "Epoch 30/120\n",
      "53/53 - 6s - loss: 0.1906 - out1_loss: 0.2106 - out2_loss: 0.1441 - val_loss: 0.2123 - val_out1_loss: 0.2350 - val_out2_loss: 0.1592\n",
      "Epoch 31/120\n",
      "53/53 - 6s - loss: 0.1857 - out1_loss: 0.2053 - out2_loss: 0.1401 - val_loss: 0.2046 - val_out1_loss: 0.2276 - val_out2_loss: 0.1508\n",
      "Epoch 32/120\n",
      "53/53 - 6s - loss: 0.1820 - out1_loss: 0.2014 - out2_loss: 0.1367 - val_loss: 0.2051 - val_out1_loss: 0.2276 - val_out2_loss: 0.1525\n",
      "Epoch 33/120\n",
      "53/53 - 6s - loss: 0.1822 - out1_loss: 0.2012 - out2_loss: 0.1377 - val_loss: 0.2050 - val_out1_loss: 0.2281 - val_out2_loss: 0.1512\n",
      "Epoch 34/120\n",
      "53/53 - 6s - loss: 0.1804 - out1_loss: 0.1992 - out2_loss: 0.1365 - val_loss: 0.2050 - val_out1_loss: 0.2269 - val_out2_loss: 0.1539\n",
      "Epoch 35/120\n",
      "53/53 - 6s - loss: 0.1767 - out1_loss: 0.1951 - out2_loss: 0.1339 - val_loss: 0.2008 - val_out1_loss: 0.2223 - val_out2_loss: 0.1506\n",
      "Epoch 36/120\n",
      "53/53 - 6s - loss: 0.1785 - out1_loss: 0.1966 - out2_loss: 0.1364 - val_loss: 0.2087 - val_out1_loss: 0.2309 - val_out2_loss: 0.1568\n",
      "Epoch 37/120\n",
      "53/53 - 6s - loss: 0.1751 - out1_loss: 0.1930 - out2_loss: 0.1333 - val_loss: 0.2000 - val_out1_loss: 0.2223 - val_out2_loss: 0.1480\n",
      "Epoch 38/120\n",
      "53/53 - 6s - loss: 0.1755 - out1_loss: 0.1930 - out2_loss: 0.1344 - val_loss: 0.1997 - val_out1_loss: 0.2218 - val_out2_loss: 0.1482\n",
      "Epoch 39/120\n",
      "53/53 - 6s - loss: 0.1706 - out1_loss: 0.1882 - out2_loss: 0.1296 - val_loss: 0.1983 - val_out1_loss: 0.2201 - val_out2_loss: 0.1474\n",
      "Epoch 40/120\n",
      "53/53 - 6s - loss: 0.1679 - out1_loss: 0.1851 - out2_loss: 0.1279 - val_loss: 0.1991 - val_out1_loss: 0.2215 - val_out2_loss: 0.1469\n",
      "Epoch 41/120\n",
      "53/53 - 6s - loss: 0.1668 - out1_loss: 0.1838 - out2_loss: 0.1272 - val_loss: 0.2002 - val_out1_loss: 0.2217 - val_out2_loss: 0.1501\n",
      "Epoch 42/120\n",
      "53/53 - 6s - loss: 0.1659 - out1_loss: 0.1826 - out2_loss: 0.1268 - val_loss: 0.1985 - val_out1_loss: 0.2201 - val_out2_loss: 0.1482\n",
      "Epoch 43/120\n",
      "53/53 - 6s - loss: 0.1655 - out1_loss: 0.1822 - out2_loss: 0.1265 - val_loss: 0.1979 - val_out1_loss: 0.2194 - val_out2_loss: 0.1478\n",
      "Epoch 44/120\n",
      "53/53 - 6s - loss: 0.1644 - out1_loss: 0.1810 - out2_loss: 0.1257 - val_loss: 0.2009 - val_out1_loss: 0.2228 - val_out2_loss: 0.1498\n",
      "Epoch 45/120\n",
      "53/53 - 6s - loss: 0.1629 - out1_loss: 0.1793 - out2_loss: 0.1244 - val_loss: 0.2008 - val_out1_loss: 0.2219 - val_out2_loss: 0.1515\n",
      "Epoch 46/120\n",
      "53/53 - 6s - loss: 0.1617 - out1_loss: 0.1775 - out2_loss: 0.1249 - val_loss: 0.2005 - val_out1_loss: 0.2229 - val_out2_loss: 0.1481\n",
      "Epoch 47/120\n",
      "53/53 - 6s - loss: 0.1601 - out1_loss: 0.1759 - out2_loss: 0.1234 - val_loss: 0.1972 - val_out1_loss: 0.2189 - val_out2_loss: 0.1465\n",
      "Epoch 48/120\n",
      "53/53 - 6s - loss: 0.1610 - out1_loss: 0.1768 - out2_loss: 0.1240 - val_loss: 0.2011 - val_out1_loss: 0.2227 - val_out2_loss: 0.1506\n",
      "Epoch 49/120\n",
      "53/53 - 6s - loss: 0.1590 - out1_loss: 0.1745 - out2_loss: 0.1231 - val_loss: 0.1999 - val_out1_loss: 0.2222 - val_out2_loss: 0.1477\n",
      "Epoch 50/120\n",
      "53/53 - 6s - loss: 0.1567 - out1_loss: 0.1720 - out2_loss: 0.1208 - val_loss: 0.1998 - val_out1_loss: 0.2219 - val_out2_loss: 0.1482\n",
      "Epoch 51/120\n",
      "53/53 - 6s - loss: 0.1548 - out1_loss: 0.1702 - out2_loss: 0.1191 - val_loss: 0.1960 - val_out1_loss: 0.2175 - val_out2_loss: 0.1458\n",
      "Epoch 52/120\n",
      "53/53 - 6s - loss: 0.1555 - out1_loss: 0.1705 - out2_loss: 0.1205 - val_loss: 0.2012 - val_out1_loss: 0.2229 - val_out2_loss: 0.1505\n",
      "Epoch 53/120\n",
      "53/53 - 6s - loss: 0.1548 - out1_loss: 0.1697 - out2_loss: 0.1201 - val_loss: 0.1976 - val_out1_loss: 0.2187 - val_out2_loss: 0.1483\n",
      "Epoch 54/120\n",
      "53/53 - 6s - loss: 0.1527 - out1_loss: 0.1674 - out2_loss: 0.1185 - val_loss: 0.1961 - val_out1_loss: 0.2173 - val_out2_loss: 0.1467\n",
      "Epoch 55/120\n",
      "53/53 - 6s - loss: 0.1513 - out1_loss: 0.1659 - out2_loss: 0.1173 - val_loss: 0.1995 - val_out1_loss: 0.2220 - val_out2_loss: 0.1471\n",
      "Epoch 56/120\n",
      "53/53 - 6s - loss: 0.1529 - out1_loss: 0.1669 - out2_loss: 0.1201 - val_loss: 0.2014 - val_out1_loss: 0.2235 - val_out2_loss: 0.1500\n",
      "Epoch 57/120\n",
      "53/53 - 6s - loss: 0.1516 - out1_loss: 0.1661 - out2_loss: 0.1179 - val_loss: 0.1994 - val_out1_loss: 0.2210 - val_out2_loss: 0.1492\n",
      "Epoch 58/120\n",
      "53/53 - 6s - loss: 0.1502 - out1_loss: 0.1645 - out2_loss: 0.1167 - val_loss: 0.1973 - val_out1_loss: 0.2195 - val_out2_loss: 0.1455\n",
      "Epoch 59/120\n",
      "53/53 - 6s - loss: 0.1485 - out1_loss: 0.1626 - out2_loss: 0.1155 - val_loss: 0.1955 - val_out1_loss: 0.2172 - val_out2_loss: 0.1450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/120\n",
      "53/53 - 6s - loss: 0.1468 - out1_loss: 0.1606 - out2_loss: 0.1145 - val_loss: 0.1962 - val_out1_loss: 0.2176 - val_out2_loss: 0.1462\n",
      "Epoch 61/120\n",
      "53/53 - 6s - loss: 0.1457 - out1_loss: 0.1595 - out2_loss: 0.1138 - val_loss: 0.1954 - val_out1_loss: 0.2167 - val_out2_loss: 0.1459\n",
      "Epoch 62/120\n",
      "53/53 - 6s - loss: 0.1483 - out1_loss: 0.1619 - out2_loss: 0.1165 - val_loss: 0.1966 - val_out1_loss: 0.2184 - val_out2_loss: 0.1457\n",
      "Epoch 63/120\n",
      "53/53 - 6s - loss: 0.1448 - out1_loss: 0.1584 - out2_loss: 0.1131 - val_loss: 0.1953 - val_out1_loss: 0.2169 - val_out2_loss: 0.1449\n",
      "Epoch 64/120\n",
      "53/53 - 6s - loss: 0.1436 - out1_loss: 0.1570 - out2_loss: 0.1123 - val_loss: 0.1970 - val_out1_loss: 0.2180 - val_out2_loss: 0.1480\n",
      "Epoch 65/120\n",
      "53/53 - 6s - loss: 0.1437 - out1_loss: 0.1570 - out2_loss: 0.1128 - val_loss: 0.1948 - val_out1_loss: 0.2165 - val_out2_loss: 0.1442\n",
      "Epoch 66/120\n",
      "53/53 - 6s - loss: 0.1447 - out1_loss: 0.1573 - out2_loss: 0.1153 - val_loss: 0.1996 - val_out1_loss: 0.2189 - val_out2_loss: 0.1545\n",
      "Epoch 67/120\n",
      "53/53 - 6s - loss: 0.1433 - out1_loss: 0.1555 - out2_loss: 0.1149 - val_loss: 0.1964 - val_out1_loss: 0.2179 - val_out2_loss: 0.1462\n",
      "Epoch 68/120\n",
      "53/53 - 6s - loss: 0.1417 - out1_loss: 0.1548 - out2_loss: 0.1112 - val_loss: 0.1953 - val_out1_loss: 0.2168 - val_out2_loss: 0.1450\n",
      "Epoch 69/120\n",
      "53/53 - 6s - loss: 0.1410 - out1_loss: 0.1539 - out2_loss: 0.1107 - val_loss: 0.1968 - val_out1_loss: 0.2184 - val_out2_loss: 0.1465\n",
      "Epoch 70/120\n",
      "53/53 - 6s - loss: 0.1393 - out1_loss: 0.1520 - out2_loss: 0.1095 - val_loss: 0.1961 - val_out1_loss: 0.2173 - val_out2_loss: 0.1467\n",
      "Epoch 71/120\n",
      "53/53 - 6s - loss: 0.1393 - out1_loss: 0.1519 - out2_loss: 0.1099 - val_loss: 0.1952 - val_out1_loss: 0.2164 - val_out2_loss: 0.1458\n",
      "Epoch 72/120\n",
      "53/53 - 6s - loss: 0.1398 - out1_loss: 0.1524 - out2_loss: 0.1105 - val_loss: 0.1967 - val_out1_loss: 0.2184 - val_out2_loss: 0.1460\n",
      "Epoch 73/120\n",
      "53/53 - 6s - loss: 0.1381 - out1_loss: 0.1507 - out2_loss: 0.1087 - val_loss: 0.1941 - val_out1_loss: 0.2151 - val_out2_loss: 0.1452\n",
      "Epoch 74/120\n",
      "53/53 - 6s - loss: 0.1377 - out1_loss: 0.1500 - out2_loss: 0.1090 - val_loss: 0.1994 - val_out1_loss: 0.2197 - val_out2_loss: 0.1521\n",
      "Epoch 75/120\n",
      "53/53 - 6s - loss: 0.1382 - out1_loss: 0.1499 - out2_loss: 0.1107 - val_loss: 0.1952 - val_out1_loss: 0.2160 - val_out2_loss: 0.1466\n",
      "Epoch 76/120\n",
      "53/53 - 6s - loss: 0.1364 - out1_loss: 0.1487 - out2_loss: 0.1078 - val_loss: 0.1958 - val_out1_loss: 0.2175 - val_out2_loss: 0.1451\n",
      "Epoch 77/120\n",
      "53/53 - 6s - loss: 0.1365 - out1_loss: 0.1486 - out2_loss: 0.1083 - val_loss: 0.1968 - val_out1_loss: 0.2184 - val_out2_loss: 0.1463\n",
      "Epoch 78/120\n",
      "53/53 - 6s - loss: 0.1356 - out1_loss: 0.1477 - out2_loss: 0.1072 - val_loss: 0.1973 - val_out1_loss: 0.2186 - val_out2_loss: 0.1475\n",
      "Epoch 79/120\n",
      "53/53 - 6s - loss: 0.1414 - out1_loss: 0.1529 - out2_loss: 0.1147 - val_loss: 0.1947 - val_out1_loss: 0.2158 - val_out2_loss: 0.1455\n",
      "Epoch 80/120\n",
      "53/53 - 6s - loss: 0.1344 - out1_loss: 0.1462 - out2_loss: 0.1067 - val_loss: 0.1954 - val_out1_loss: 0.2169 - val_out2_loss: 0.1453\n",
      "Epoch 81/120\n",
      "53/53 - 6s - loss: 0.1338 - out1_loss: 0.1457 - out2_loss: 0.1060 - val_loss: 0.1954 - val_out1_loss: 0.2162 - val_out2_loss: 0.1468\n",
      "Epoch 82/120\n",
      "53/53 - 6s - loss: 0.1334 - out1_loss: 0.1451 - out2_loss: 0.1061 - val_loss: 0.1983 - val_out1_loss: 0.2196 - val_out2_loss: 0.1488\n",
      "Epoch 83/120\n",
      "53/53 - 6s - loss: 0.1337 - out1_loss: 0.1455 - out2_loss: 0.1064 - val_loss: 0.1965 - val_out1_loss: 0.2179 - val_out2_loss: 0.1465\n",
      "Epoch 84/120\n",
      "53/53 - 6s - loss: 0.1273 - out1_loss: 0.1384 - out2_loss: 0.1015 - val_loss: 0.1922 - val_out1_loss: 0.2136 - val_out2_loss: 0.1424\n",
      "Epoch 85/120\n",
      "53/53 - 6s - loss: 0.1245 - out1_loss: 0.1353 - out2_loss: 0.0994 - val_loss: 0.1919 - val_out1_loss: 0.2133 - val_out2_loss: 0.1421\n",
      "Epoch 86/120\n",
      "53/53 - 6s - loss: 0.1232 - out1_loss: 0.1339 - out2_loss: 0.0984 - val_loss: 0.1919 - val_out1_loss: 0.2133 - val_out2_loss: 0.1422\n",
      "Epoch 87/120\n",
      "53/53 - 6s - loss: 0.1225 - out1_loss: 0.1330 - out2_loss: 0.0980 - val_loss: 0.1918 - val_out1_loss: 0.2132 - val_out2_loss: 0.1420\n",
      "Epoch 88/120\n",
      "53/53 - 6s - loss: 0.1217 - out1_loss: 0.1321 - out2_loss: 0.0975 - val_loss: 0.1916 - val_out1_loss: 0.2129 - val_out2_loss: 0.1419\n",
      "Epoch 89/120\n",
      "53/53 - 6s - loss: 0.1213 - out1_loss: 0.1316 - out2_loss: 0.0971 - val_loss: 0.1916 - val_out1_loss: 0.2130 - val_out2_loss: 0.1418\n",
      "Epoch 90/120\n",
      "53/53 - 6s - loss: 0.1210 - out1_loss: 0.1312 - out2_loss: 0.0970 - val_loss: 0.1914 - val_out1_loss: 0.2127 - val_out2_loss: 0.1417\n",
      "Epoch 91/120\n",
      "53/53 - 6s - loss: 0.1206 - out1_loss: 0.1309 - out2_loss: 0.0967 - val_loss: 0.1914 - val_out1_loss: 0.2127 - val_out2_loss: 0.1417\n",
      "Epoch 92/120\n",
      "53/53 - 6s - loss: 0.1203 - out1_loss: 0.1305 - out2_loss: 0.0965 - val_loss: 0.1915 - val_out1_loss: 0.2129 - val_out2_loss: 0.1418\n",
      "Epoch 93/120\n",
      "53/53 - 6s - loss: 0.1198 - out1_loss: 0.1299 - out2_loss: 0.0963 - val_loss: 0.1916 - val_out1_loss: 0.2129 - val_out2_loss: 0.1417\n",
      "Epoch 94/120\n",
      "53/53 - 6s - loss: 0.1197 - out1_loss: 0.1298 - out2_loss: 0.0961 - val_loss: 0.1914 - val_out1_loss: 0.2127 - val_out2_loss: 0.1417\n",
      "Epoch 95/120\n",
      "53/53 - 6s - loss: 0.1194 - out1_loss: 0.1294 - out2_loss: 0.0959 - val_loss: 0.1914 - val_out1_loss: 0.2127 - val_out2_loss: 0.1417\n",
      "Epoch 96/120\n",
      "53/53 - 6s - loss: 0.1190 - out1_loss: 0.1290 - out2_loss: 0.0957 - val_loss: 0.1914 - val_out1_loss: 0.2128 - val_out2_loss: 0.1416\n",
      "Epoch 97/120\n",
      "53/53 - 6s - loss: 0.1188 - out1_loss: 0.1288 - out2_loss: 0.0955 - val_loss: 0.1912 - val_out1_loss: 0.2124 - val_out2_loss: 0.1415\n",
      "Epoch 98/120\n",
      "53/53 - 6s - loss: 0.1186 - out1_loss: 0.1286 - out2_loss: 0.0954 - val_loss: 0.1914 - val_out1_loss: 0.2127 - val_out2_loss: 0.1417\n",
      "Epoch 99/120\n",
      "53/53 - 6s - loss: 0.1185 - out1_loss: 0.1285 - out2_loss: 0.0954 - val_loss: 0.1913 - val_out1_loss: 0.2127 - val_out2_loss: 0.1416\n",
      "Epoch 100/120\n",
      "53/53 - 6s - loss: 0.1185 - out1_loss: 0.1285 - out2_loss: 0.0953 - val_loss: 0.1912 - val_out1_loss: 0.2125 - val_out2_loss: 0.1415\n",
      "Epoch 101/120\n",
      "53/53 - 5s - loss: 0.1183 - out1_loss: 0.1281 - out2_loss: 0.0952 - val_loss: 0.1912 - val_out1_loss: 0.2125 - val_out2_loss: 0.1415\n",
      "Epoch 102/120\n",
      "53/53 - 6s - loss: 0.1181 - out1_loss: 0.1280 - out2_loss: 0.0950 - val_loss: 0.1914 - val_out1_loss: 0.2127 - val_out2_loss: 0.1416\n",
      "Epoch 103/120\n",
      "53/53 - 6s - loss: 0.1179 - out1_loss: 0.1278 - out2_loss: 0.0949 - val_loss: 0.1912 - val_out1_loss: 0.2125 - val_out2_loss: 0.1416\n",
      "Epoch 104/120\n",
      "53/53 - 6s - loss: 0.1177 - out1_loss: 0.1275 - out2_loss: 0.0948 - val_loss: 0.1913 - val_out1_loss: 0.2126 - val_out2_loss: 0.1416\n",
      "Epoch 105/120\n",
      "53/53 - 5s - loss: 0.1175 - out1_loss: 0.1273 - out2_loss: 0.0947 - val_loss: 0.1914 - val_out1_loss: 0.2127 - val_out2_loss: 0.1417\n",
      "Epoch 106/120\n",
      "53/53 - 6s - loss: 0.1173 - out1_loss: 0.1271 - out2_loss: 0.0946 - val_loss: 0.1913 - val_out1_loss: 0.2126 - val_out2_loss: 0.1416\n",
      "Epoch 107/120\n",
      "53/53 - 6s - loss: 0.1171 - out1_loss: 0.1269 - out2_loss: 0.0944 - val_loss: 0.1913 - val_out1_loss: 0.2126 - val_out2_loss: 0.1417\n",
      "Epoch 108/120\n",
      "53/53 - 6s - loss: 0.1168 - out1_loss: 0.1265 - out2_loss: 0.0942 - val_loss: 0.1911 - val_out1_loss: 0.2124 - val_out2_loss: 0.1414\n",
      "Epoch 109/120\n",
      "53/53 - 6s - loss: 0.1166 - out1_loss: 0.1263 - out2_loss: 0.0941 - val_loss: 0.1911 - val_out1_loss: 0.2123 - val_out2_loss: 0.1414\n",
      "Epoch 110/120\n",
      "53/53 - 6s - loss: 0.1164 - out1_loss: 0.1261 - out2_loss: 0.0940 - val_loss: 0.1911 - val_out1_loss: 0.2123 - val_out2_loss: 0.1414\n",
      "Epoch 111/120\n",
      "53/53 - 5s - loss: 0.1165 - out1_loss: 0.1261 - out2_loss: 0.0941 - val_loss: 0.1911 - val_out1_loss: 0.2124 - val_out2_loss: 0.1414\n",
      "Epoch 112/120\n",
      "53/53 - 6s - loss: 0.1162 - out1_loss: 0.1259 - out2_loss: 0.0938 - val_loss: 0.1912 - val_out1_loss: 0.2125 - val_out2_loss: 0.1415\n",
      "Epoch 113/120\n",
      "53/53 - 6s - loss: 0.1164 - out1_loss: 0.1260 - out2_loss: 0.0939 - val_loss: 0.1911 - val_out1_loss: 0.2125 - val_out2_loss: 0.1414\n",
      "Epoch 114/120\n",
      "53/53 - 5s - loss: 0.1162 - out1_loss: 0.1258 - out2_loss: 0.0938 - val_loss: 0.1911 - val_out1_loss: 0.2124 - val_out2_loss: 0.1414\n",
      "Epoch 115/120\n",
      "53/53 - 6s - loss: 0.1164 - out1_loss: 0.1260 - out2_loss: 0.0939 - val_loss: 0.1911 - val_out1_loss: 0.2124 - val_out2_loss: 0.1414\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 6s - loss: 0.1164 - out1_loss: 0.1260 - out2_loss: 0.0939 - val_loss: 0.1911 - val_out1_loss: 0.2124 - val_out2_loss: 0.1414\n",
      "Epoch 117/120\n",
      "53/53 - 6s - loss: 0.1161 - out1_loss: 0.1257 - out2_loss: 0.0937 - val_loss: 0.1911 - val_out1_loss: 0.2124 - val_out2_loss: 0.1414\n",
      "Epoch 118/120\n",
      "53/53 - 6s - loss: 0.1160 - out1_loss: 0.1256 - out2_loss: 0.0937 - val_loss: 0.1911 - val_out1_loss: 0.2124 - val_out2_loss: 0.1414\n",
      "Epoch 119/120\n",
      "53/53 - 6s - loss: 0.1162 - out1_loss: 0.1258 - out2_loss: 0.0938 - val_loss: 0.1910 - val_out1_loss: 0.2123 - val_out2_loss: 0.1414\n",
      "Epoch 120/120\n",
      "53/53 - 7s - loss: 0.1160 - out1_loss: 0.1256 - out2_loss: 0.0937 - val_loss: 0.1910 - val_out1_loss: 0.2123 - val_out2_loss: 0.1413\n",
      "#################### 0.3684601293738104\n",
      "(None, 107, 1024)\n",
      "(None, 130, 1024)\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "(None, 107, 1024)\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 107, 7)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_24 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_25 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_26 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_27 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_28 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_29 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_30 (T [(None, 107)]        0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_21 (Embedding)        (None, 107, 128)     512         tf_op_layer_strided_slice_24[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_25[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_23 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_26[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_24 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_27[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_25 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_28[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_26 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_29[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_27 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_30[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_24 (SpatialDr (None, 107, 128)     0           embedding_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_25 (SpatialDr (None, 107, 128)     0           embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_26 (SpatialDr (None, 107, 128)     0           embedding_23[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_27 (SpatialDr (None, 107, 128)     0           embedding_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_28 (SpatialDr (None, 107, 128)     0           embedding_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_29 (SpatialDr (None, 107, 128)     0           embedding_26[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_30 (SpatialDr (None, 107, 128)     0           embedding_27[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo [(None, 107, 896)]   0           spatial_dropout1d_24[0][0]       \n",
      "                                                                 spatial_dropout1d_25[0][0]       \n",
      "                                                                 spatial_dropout1d_26[0][0]       \n",
      "                                                                 spatial_dropout1d_27[0][0]       \n",
      "                                                                 spatial_dropout1d_28[0][0]       \n",
      "                                                                 spatial_dropout1d_29[0][0]       \n",
      "                                                                 spatial_dropout1d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_31 (SpatialDr (None, 107, 896)     0           tf_op_layer_concat_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 107, 128)     256         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_7 (TensorFlo [(None, 107, 1024)]  0           spatial_dropout1d_31[0][0]       \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_3 (Transforme (None, 107, 1024)    6301696     tf_op_layer_concat_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_9 (Bidirectional) (None, 107, 768)     3248640     transformer_block_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_10 (Bidirectional (None, 107, 768)     2658816     bidirectional_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_11 (Bidirectional (None, 107, 768)     2658816     bidirectional_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_31 (T [(None, 68, 768)]    0           bidirectional_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_31[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_31[0][0\n",
      "==================================================================================================\n",
      "Total params: 14,881,290\n",
      "Trainable params: 14,881,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 8s - loss: 0.7298 - out1_loss: 0.7889 - out2_loss: 0.5919 - val_loss: 0.3870 - val_out1_loss: 0.4265 - val_out2_loss: 0.2949\n",
      "Epoch 2/120\n",
      "53/53 - 6s - loss: 0.3889 - out1_loss: 0.4291 - out2_loss: 0.2950 - val_loss: 0.3881 - val_out1_loss: 0.4296 - val_out2_loss: 0.2911\n",
      "Epoch 3/120\n",
      "53/53 - 6s - loss: 0.3844 - out1_loss: 0.4230 - out2_loss: 0.2942 - val_loss: 0.3768 - val_out1_loss: 0.4134 - val_out2_loss: 0.2912\n",
      "Epoch 4/120\n",
      "53/53 - 6s - loss: 0.3790 - out1_loss: 0.4171 - out2_loss: 0.2900 - val_loss: 0.3747 - val_out1_loss: 0.4133 - val_out2_loss: 0.2846\n",
      "Epoch 5/120\n",
      "53/53 - 6s - loss: 0.3771 - out1_loss: 0.4159 - out2_loss: 0.2865 - val_loss: 0.3810 - val_out1_loss: 0.4212 - val_out2_loss: 0.2872\n",
      "Epoch 6/120\n",
      "53/53 - 6s - loss: 0.3777 - out1_loss: 0.4168 - out2_loss: 0.2866 - val_loss: 0.3766 - val_out1_loss: 0.4152 - val_out2_loss: 0.2866\n",
      "Epoch 7/120\n",
      "53/53 - 6s - loss: 0.3682 - out1_loss: 0.4072 - out2_loss: 0.2773 - val_loss: 0.3655 - val_out1_loss: 0.4062 - val_out2_loss: 0.2706\n",
      "Epoch 8/120\n",
      "53/53 - 6s - loss: 0.3506 - out1_loss: 0.3887 - out2_loss: 0.2618 - val_loss: 0.3440 - val_out1_loss: 0.3779 - val_out2_loss: 0.2651\n",
      "Epoch 9/120\n",
      "53/53 - 6s - loss: 0.3357 - out1_loss: 0.3730 - out2_loss: 0.2486 - val_loss: 0.3236 - val_out1_loss: 0.3595 - val_out2_loss: 0.2398\n",
      "Epoch 10/120\n",
      "53/53 - 6s - loss: 0.3204 - out1_loss: 0.3567 - out2_loss: 0.2358 - val_loss: 0.3013 - val_out1_loss: 0.3371 - val_out2_loss: 0.2176\n",
      "Epoch 11/120\n",
      "53/53 - 6s - loss: 0.3023 - out1_loss: 0.3373 - out2_loss: 0.2204 - val_loss: 0.2880 - val_out1_loss: 0.3218 - val_out2_loss: 0.2091\n",
      "Epoch 12/120\n",
      "53/53 - 6s - loss: 0.2922 - out1_loss: 0.3259 - out2_loss: 0.2136 - val_loss: 0.2807 - val_out1_loss: 0.3134 - val_out2_loss: 0.2042\n",
      "Epoch 13/120\n",
      "53/53 - 6s - loss: 0.2835 - out1_loss: 0.3162 - out2_loss: 0.2073 - val_loss: 0.2703 - val_out1_loss: 0.3014 - val_out2_loss: 0.1977\n",
      "Epoch 14/120\n",
      "53/53 - 6s - loss: 0.2744 - out1_loss: 0.3059 - out2_loss: 0.2009 - val_loss: 0.2726 - val_out1_loss: 0.3037 - val_out2_loss: 0.1998\n",
      "Epoch 15/120\n",
      "53/53 - 6s - loss: 0.2699 - out1_loss: 0.3007 - out2_loss: 0.1982 - val_loss: 0.2574 - val_out1_loss: 0.2868 - val_out2_loss: 0.1888\n",
      "Epoch 16/120\n",
      "53/53 - 6s - loss: 0.2611 - out1_loss: 0.2907 - out2_loss: 0.1919 - val_loss: 0.2670 - val_out1_loss: 0.2980 - val_out2_loss: 0.1947\n",
      "Epoch 17/120\n",
      "53/53 - 6s - loss: 0.2585 - out1_loss: 0.2874 - out2_loss: 0.1910 - val_loss: 0.2451 - val_out1_loss: 0.2741 - val_out2_loss: 0.1777\n",
      "Epoch 18/120\n",
      "53/53 - 6s - loss: 0.2470 - out1_loss: 0.2749 - out2_loss: 0.1821 - val_loss: 0.2539 - val_out1_loss: 0.2854 - val_out2_loss: 0.1805\n",
      "Epoch 19/120\n",
      "53/53 - 6s - loss: 0.2415 - out1_loss: 0.2685 - out2_loss: 0.1786 - val_loss: 0.2414 - val_out1_loss: 0.2699 - val_out2_loss: 0.1750\n",
      "Epoch 20/120\n",
      "53/53 - 6s - loss: 0.2370 - out1_loss: 0.2631 - out2_loss: 0.1761 - val_loss: 0.2298 - val_out1_loss: 0.2548 - val_out2_loss: 0.1714\n",
      "Epoch 21/120\n",
      "53/53 - 6s - loss: 0.2302 - out1_loss: 0.2552 - out2_loss: 0.1717 - val_loss: 0.2318 - val_out1_loss: 0.2568 - val_out2_loss: 0.1736\n",
      "Epoch 22/120\n",
      "53/53 - 6s - loss: 0.2282 - out1_loss: 0.2527 - out2_loss: 0.1712 - val_loss: 0.2255 - val_out1_loss: 0.2487 - val_out2_loss: 0.1712\n",
      "Epoch 23/120\n",
      "53/53 - 6s - loss: 0.2210 - out1_loss: 0.2448 - out2_loss: 0.1654 - val_loss: 0.2204 - val_out1_loss: 0.2438 - val_out2_loss: 0.1658\n",
      "Epoch 24/120\n",
      "53/53 - 6s - loss: 0.2164 - out1_loss: 0.2399 - out2_loss: 0.1615 - val_loss: 0.2148 - val_out1_loss: 0.2397 - val_out2_loss: 0.1569\n",
      "Epoch 25/120\n",
      "53/53 - 6s - loss: 0.2133 - out1_loss: 0.2363 - out2_loss: 0.1595 - val_loss: 0.2121 - val_out1_loss: 0.2360 - val_out2_loss: 0.1563\n",
      "Epoch 26/120\n",
      "53/53 - 6s - loss: 0.2104 - out1_loss: 0.2333 - out2_loss: 0.1572 - val_loss: 0.2201 - val_out1_loss: 0.2452 - val_out2_loss: 0.1613\n",
      "Epoch 27/120\n",
      "53/53 - 6s - loss: 0.2088 - out1_loss: 0.2314 - out2_loss: 0.1560 - val_loss: 0.2131 - val_out1_loss: 0.2341 - val_out2_loss: 0.1639\n",
      "Epoch 28/120\n",
      "53/53 - 6s - loss: 0.2035 - out1_loss: 0.2255 - out2_loss: 0.1520 - val_loss: 0.2072 - val_out1_loss: 0.2303 - val_out2_loss: 0.1533\n",
      "Epoch 29/120\n",
      "53/53 - 6s - loss: 0.2030 - out1_loss: 0.2248 - out2_loss: 0.1521 - val_loss: 0.2061 - val_out1_loss: 0.2292 - val_out2_loss: 0.1523\n",
      "Epoch 30/120\n",
      "53/53 - 6s - loss: 0.1982 - out1_loss: 0.2197 - out2_loss: 0.1481 - val_loss: 0.2036 - val_out1_loss: 0.2272 - val_out2_loss: 0.1485\n",
      "Epoch 31/120\n",
      "53/53 - 6s - loss: 0.1960 - out1_loss: 0.2174 - out2_loss: 0.1461 - val_loss: 0.2114 - val_out1_loss: 0.2346 - val_out2_loss: 0.1574\n",
      "Epoch 32/120\n",
      "53/53 - 6s - loss: 0.1937 - out1_loss: 0.2145 - out2_loss: 0.1452 - val_loss: 0.2021 - val_out1_loss: 0.2246 - val_out2_loss: 0.1495\n",
      "Epoch 33/120\n",
      "53/53 - 6s - loss: 0.1913 - out1_loss: 0.2119 - out2_loss: 0.1433 - val_loss: 0.2026 - val_out1_loss: 0.2252 - val_out2_loss: 0.1498\n",
      "Epoch 34/120\n",
      "53/53 - 6s - loss: 0.1908 - out1_loss: 0.2104 - out2_loss: 0.1450 - val_loss: 0.2014 - val_out1_loss: 0.2241 - val_out2_loss: 0.1484\n",
      "Epoch 35/120\n",
      "53/53 - 6s - loss: 0.1883 - out1_loss: 0.2079 - out2_loss: 0.1427 - val_loss: 0.2065 - val_out1_loss: 0.2292 - val_out2_loss: 0.1537\n",
      "Epoch 36/120\n",
      "53/53 - 6s - loss: 0.1847 - out1_loss: 0.2042 - out2_loss: 0.1392 - val_loss: 0.2013 - val_out1_loss: 0.2246 - val_out2_loss: 0.1470\n",
      "Epoch 37/120\n",
      "53/53 - 6s - loss: 0.1819 - out1_loss: 0.2011 - out2_loss: 0.1372 - val_loss: 0.1991 - val_out1_loss: 0.2213 - val_out2_loss: 0.1473\n",
      "Epoch 38/120\n",
      "53/53 - 6s - loss: 0.1803 - out1_loss: 0.1987 - out2_loss: 0.1375 - val_loss: 0.1998 - val_out1_loss: 0.2219 - val_out2_loss: 0.1482\n",
      "Epoch 39/120\n",
      "53/53 - 6s - loss: 0.1796 - out1_loss: 0.1981 - out2_loss: 0.1363 - val_loss: 0.2003 - val_out1_loss: 0.2233 - val_out2_loss: 0.1467\n",
      "Epoch 40/120\n",
      "53/53 - 6s - loss: 0.1776 - out1_loss: 0.1957 - out2_loss: 0.1353 - val_loss: 0.1986 - val_out1_loss: 0.2206 - val_out2_loss: 0.1474\n",
      "Epoch 41/120\n",
      "53/53 - 6s - loss: 0.1780 - out1_loss: 0.1963 - out2_loss: 0.1354 - val_loss: 0.1996 - val_out1_loss: 0.2218 - val_out2_loss: 0.1478\n",
      "Epoch 42/120\n",
      "53/53 - 6s - loss: 0.1740 - out1_loss: 0.1917 - out2_loss: 0.1326 - val_loss: 0.1978 - val_out1_loss: 0.2203 - val_out2_loss: 0.1454\n",
      "Epoch 43/120\n",
      "53/53 - 6s - loss: 0.1711 - out1_loss: 0.1884 - out2_loss: 0.1309 - val_loss: 0.2013 - val_out1_loss: 0.2217 - val_out2_loss: 0.1538\n",
      "Epoch 44/120\n",
      "53/53 - 6s - loss: 0.1699 - out1_loss: 0.1864 - out2_loss: 0.1312 - val_loss: 0.1954 - val_out1_loss: 0.2176 - val_out2_loss: 0.1438\n",
      "Epoch 45/120\n",
      "53/53 - 6s - loss: 0.1677 - out1_loss: 0.1844 - out2_loss: 0.1286 - val_loss: 0.1957 - val_out1_loss: 0.2179 - val_out2_loss: 0.1438\n",
      "Epoch 46/120\n",
      "53/53 - 6s - loss: 0.1738 - out1_loss: 0.1911 - out2_loss: 0.1335 - val_loss: 0.2020 - val_out1_loss: 0.2239 - val_out2_loss: 0.1510\n",
      "Epoch 47/120\n",
      "53/53 - 6s - loss: 0.1695 - out1_loss: 0.1858 - out2_loss: 0.1314 - val_loss: 0.1982 - val_out1_loss: 0.2205 - val_out2_loss: 0.1464\n",
      "Epoch 48/120\n",
      "53/53 - 6s - loss: 0.1663 - out1_loss: 0.1828 - out2_loss: 0.1278 - val_loss: 0.1992 - val_out1_loss: 0.2219 - val_out2_loss: 0.1464\n",
      "Epoch 49/120\n",
      "53/53 - 6s - loss: 0.1640 - out1_loss: 0.1802 - out2_loss: 0.1262 - val_loss: 0.1954 - val_out1_loss: 0.2178 - val_out2_loss: 0.1432\n",
      "Epoch 50/120\n",
      "53/53 - 6s - loss: 0.1612 - out1_loss: 0.1769 - out2_loss: 0.1245 - val_loss: 0.1993 - val_out1_loss: 0.2205 - val_out2_loss: 0.1499\n",
      "Epoch 51/120\n",
      "53/53 - 6s - loss: 0.1605 - out1_loss: 0.1760 - out2_loss: 0.1245 - val_loss: 0.1950 - val_out1_loss: 0.2157 - val_out2_loss: 0.1469\n",
      "Epoch 52/120\n",
      "53/53 - 6s - loss: 0.1609 - out1_loss: 0.1762 - out2_loss: 0.1253 - val_loss: 0.2022 - val_out1_loss: 0.2246 - val_out2_loss: 0.1501\n",
      "Epoch 53/120\n",
      "53/53 - 6s - loss: 0.1588 - out1_loss: 0.1741 - out2_loss: 0.1232 - val_loss: 0.1929 - val_out1_loss: 0.2147 - val_out2_loss: 0.1421\n",
      "Epoch 54/120\n",
      "53/53 - 5s - loss: 0.1565 - out1_loss: 0.1715 - out2_loss: 0.1215 - val_loss: 0.1940 - val_out1_loss: 0.2162 - val_out2_loss: 0.1420\n",
      "Epoch 55/120\n",
      "53/53 - 5s - loss: 0.1555 - out1_loss: 0.1704 - out2_loss: 0.1209 - val_loss: 0.1950 - val_out1_loss: 0.2163 - val_out2_loss: 0.1454\n",
      "Epoch 56/120\n",
      "53/53 - 6s - loss: 0.1550 - out1_loss: 0.1697 - out2_loss: 0.1207 - val_loss: 0.1947 - val_out1_loss: 0.2163 - val_out2_loss: 0.1442\n",
      "Epoch 57/120\n",
      "53/53 - 6s - loss: 0.1529 - out1_loss: 0.1675 - out2_loss: 0.1188 - val_loss: 0.1937 - val_out1_loss: 0.2154 - val_out2_loss: 0.1431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "53/53 - 5s - loss: 0.1522 - out1_loss: 0.1668 - out2_loss: 0.1183 - val_loss: 0.1934 - val_out1_loss: 0.2154 - val_out2_loss: 0.1422\n",
      "Epoch 59/120\n",
      "53/53 - 6s - loss: 0.1516 - out1_loss: 0.1658 - out2_loss: 0.1185 - val_loss: 0.1930 - val_out1_loss: 0.2146 - val_out2_loss: 0.1425\n",
      "Epoch 60/120\n",
      "53/53 - 6s - loss: 0.1505 - out1_loss: 0.1645 - out2_loss: 0.1178 - val_loss: 0.1923 - val_out1_loss: 0.2139 - val_out2_loss: 0.1419\n",
      "Epoch 61/120\n",
      "53/53 - 6s - loss: 0.1500 - out1_loss: 0.1640 - out2_loss: 0.1173 - val_loss: 0.1947 - val_out1_loss: 0.2164 - val_out2_loss: 0.1441\n",
      "Epoch 62/120\n",
      "53/53 - 6s - loss: 0.1488 - out1_loss: 0.1623 - out2_loss: 0.1173 - val_loss: 0.1942 - val_out1_loss: 0.2164 - val_out2_loss: 0.1422\n",
      "Epoch 63/120\n",
      "53/53 - 6s - loss: 0.1479 - out1_loss: 0.1616 - out2_loss: 0.1159 - val_loss: 0.1935 - val_out1_loss: 0.2148 - val_out2_loss: 0.1436\n",
      "Epoch 64/120\n",
      "53/53 - 6s - loss: 0.1478 - out1_loss: 0.1611 - out2_loss: 0.1167 - val_loss: 0.1935 - val_out1_loss: 0.2150 - val_out2_loss: 0.1434\n",
      "Epoch 65/120\n",
      "53/53 - 6s - loss: 0.1462 - out1_loss: 0.1596 - out2_loss: 0.1148 - val_loss: 0.1951 - val_out1_loss: 0.2165 - val_out2_loss: 0.1452\n",
      "Epoch 66/120\n",
      "53/53 - 6s - loss: 0.1470 - out1_loss: 0.1604 - out2_loss: 0.1159 - val_loss: 0.1973 - val_out1_loss: 0.2191 - val_out2_loss: 0.1463\n",
      "Epoch 67/120\n",
      "53/53 - 6s - loss: 0.1449 - out1_loss: 0.1581 - out2_loss: 0.1142 - val_loss: 0.1926 - val_out1_loss: 0.2142 - val_out2_loss: 0.1423\n",
      "Epoch 68/120\n",
      "53/53 - 6s - loss: 0.1437 - out1_loss: 0.1566 - out2_loss: 0.1137 - val_loss: 0.1906 - val_out1_loss: 0.2118 - val_out2_loss: 0.1411\n",
      "Epoch 69/120\n",
      "53/53 - 6s - loss: 0.1438 - out1_loss: 0.1568 - out2_loss: 0.1136 - val_loss: 0.1946 - val_out1_loss: 0.2165 - val_out2_loss: 0.1436\n",
      "Epoch 70/120\n",
      "53/53 - 6s - loss: 0.1425 - out1_loss: 0.1556 - out2_loss: 0.1121 - val_loss: 0.1943 - val_out1_loss: 0.2163 - val_out2_loss: 0.1427\n",
      "Epoch 71/120\n",
      "53/53 - 5s - loss: 0.1419 - out1_loss: 0.1547 - out2_loss: 0.1119 - val_loss: 0.1928 - val_out1_loss: 0.2139 - val_out2_loss: 0.1436\n",
      "Epoch 72/120\n",
      "53/53 - 6s - loss: 0.1404 - out1_loss: 0.1529 - out2_loss: 0.1113 - val_loss: 0.1909 - val_out1_loss: 0.2125 - val_out2_loss: 0.1403\n",
      "Epoch 73/120\n",
      "53/53 - 6s - loss: 0.1400 - out1_loss: 0.1525 - out2_loss: 0.1106 - val_loss: 0.1935 - val_out1_loss: 0.2154 - val_out2_loss: 0.1426\n",
      "Epoch 74/120\n",
      "53/53 - 6s - loss: 0.1403 - out1_loss: 0.1526 - out2_loss: 0.1116 - val_loss: 0.1921 - val_out1_loss: 0.2137 - val_out2_loss: 0.1420\n",
      "Epoch 75/120\n",
      "53/53 - 5s - loss: 0.1382 - out1_loss: 0.1506 - out2_loss: 0.1092 - val_loss: 0.1928 - val_out1_loss: 0.2145 - val_out2_loss: 0.1422\n",
      "Epoch 76/120\n",
      "53/53 - 6s - loss: 0.1387 - out1_loss: 0.1510 - out2_loss: 0.1101 - val_loss: 0.1936 - val_out1_loss: 0.2155 - val_out2_loss: 0.1427\n",
      "Epoch 77/120\n",
      "53/53 - 6s - loss: 0.1395 - out1_loss: 0.1516 - out2_loss: 0.1113 - val_loss: 0.1910 - val_out1_loss: 0.2129 - val_out2_loss: 0.1399\n",
      "Epoch 78/120\n",
      "53/53 - 6s - loss: 0.1379 - out1_loss: 0.1501 - out2_loss: 0.1096 - val_loss: 0.1928 - val_out1_loss: 0.2134 - val_out2_loss: 0.1446\n",
      "Epoch 79/120\n",
      "53/53 - 6s - loss: 0.1312 - out1_loss: 0.1426 - out2_loss: 0.1046 - val_loss: 0.1885 - val_out1_loss: 0.2100 - val_out2_loss: 0.1384\n",
      "Epoch 80/120\n",
      "53/53 - 6s - loss: 0.1285 - out1_loss: 0.1396 - out2_loss: 0.1024 - val_loss: 0.1883 - val_out1_loss: 0.2097 - val_out2_loss: 0.1381\n",
      "Epoch 81/120\n",
      "53/53 - 6s - loss: 0.1273 - out1_loss: 0.1383 - out2_loss: 0.1017 - val_loss: 0.1878 - val_out1_loss: 0.2093 - val_out2_loss: 0.1378\n",
      "Epoch 82/120\n",
      "53/53 - 6s - loss: 0.1265 - out1_loss: 0.1374 - out2_loss: 0.1011 - val_loss: 0.1880 - val_out1_loss: 0.2095 - val_out2_loss: 0.1378\n",
      "Epoch 83/120\n",
      "53/53 - 6s - loss: 0.1260 - out1_loss: 0.1368 - out2_loss: 0.1008 - val_loss: 0.1877 - val_out1_loss: 0.2091 - val_out2_loss: 0.1377\n",
      "Epoch 84/120\n",
      "53/53 - 6s - loss: 0.1253 - out1_loss: 0.1360 - out2_loss: 0.1003 - val_loss: 0.1877 - val_out1_loss: 0.2092 - val_out2_loss: 0.1377\n",
      "Epoch 85/120\n",
      "53/53 - 5s - loss: 0.1251 - out1_loss: 0.1358 - out2_loss: 0.1002 - val_loss: 0.1877 - val_out1_loss: 0.2091 - val_out2_loss: 0.1376\n",
      "Epoch 86/120\n",
      "53/53 - 6s - loss: 0.1248 - out1_loss: 0.1354 - out2_loss: 0.1000 - val_loss: 0.1878 - val_out1_loss: 0.2093 - val_out2_loss: 0.1377\n",
      "Epoch 87/120\n",
      "53/53 - 6s - loss: 0.1243 - out1_loss: 0.1348 - out2_loss: 0.0997 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1375\n",
      "Epoch 88/120\n",
      "53/53 - 6s - loss: 0.1242 - out1_loss: 0.1347 - out2_loss: 0.0996 - val_loss: 0.1877 - val_out1_loss: 0.2091 - val_out2_loss: 0.1377\n",
      "Epoch 89/120\n",
      "53/53 - 5s - loss: 0.1240 - out1_loss: 0.1345 - out2_loss: 0.0994 - val_loss: 0.1876 - val_out1_loss: 0.2090 - val_out2_loss: 0.1377\n",
      "Epoch 90/120\n",
      "53/53 - 6s - loss: 0.1237 - out1_loss: 0.1342 - out2_loss: 0.0993 - val_loss: 0.1878 - val_out1_loss: 0.2092 - val_out2_loss: 0.1377\n",
      "Epoch 91/120\n",
      "53/53 - 6s - loss: 0.1234 - out1_loss: 0.1338 - out2_loss: 0.0990 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1375\n",
      "Epoch 92/120\n",
      "53/53 - 6s - loss: 0.1233 - out1_loss: 0.1338 - out2_loss: 0.0990 - val_loss: 0.1878 - val_out1_loss: 0.2093 - val_out2_loss: 0.1376\n",
      "Epoch 93/120\n",
      "53/53 - 6s - loss: 0.1231 - out1_loss: 0.1335 - out2_loss: 0.0989 - val_loss: 0.1880 - val_out1_loss: 0.2096 - val_out2_loss: 0.1376\n",
      "Epoch 94/120\n",
      "53/53 - 6s - loss: 0.1229 - out1_loss: 0.1332 - out2_loss: 0.0987 - val_loss: 0.1877 - val_out1_loss: 0.2093 - val_out2_loss: 0.1375\n",
      "Epoch 95/120\n",
      "53/53 - 6s - loss: 0.1227 - out1_loss: 0.1331 - out2_loss: 0.0986 - val_loss: 0.1879 - val_out1_loss: 0.2093 - val_out2_loss: 0.1377\n",
      "Epoch 96/120\n",
      "53/53 - 6s - loss: 0.1225 - out1_loss: 0.1328 - out2_loss: 0.0983 - val_loss: 0.1880 - val_out1_loss: 0.2096 - val_out2_loss: 0.1376\n",
      "Epoch 97/120\n",
      "53/53 - 6s - loss: 0.1222 - out1_loss: 0.1325 - out2_loss: 0.0983 - val_loss: 0.1877 - val_out1_loss: 0.2092 - val_out2_loss: 0.1375\n",
      "Epoch 98/120\n",
      "53/53 - 6s - loss: 0.1218 - out1_loss: 0.1320 - out2_loss: 0.0980 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1374\n",
      "Epoch 99/120\n",
      "53/53 - 6s - loss: 0.1217 - out1_loss: 0.1319 - out2_loss: 0.0980 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 100/120\n",
      "53/53 - 6s - loss: 0.1217 - out1_loss: 0.1319 - out2_loss: 0.0979 - val_loss: 0.1875 - val_out1_loss: 0.2089 - val_out2_loss: 0.1373\n",
      "Epoch 101/120\n",
      "53/53 - 6s - loss: 0.1216 - out1_loss: 0.1317 - out2_loss: 0.0978 - val_loss: 0.1875 - val_out1_loss: 0.2089 - val_out2_loss: 0.1373\n",
      "Epoch 102/120\n",
      "53/53 - 6s - loss: 0.1216 - out1_loss: 0.1317 - out2_loss: 0.0979 - val_loss: 0.1875 - val_out1_loss: 0.2089 - val_out2_loss: 0.1373\n",
      "Epoch 103/120\n",
      "53/53 - 6s - loss: 0.1214 - out1_loss: 0.1316 - out2_loss: 0.0978 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 104/120\n",
      "53/53 - 6s - loss: 0.1216 - out1_loss: 0.1317 - out2_loss: 0.0979 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 105/120\n",
      "53/53 - 6s - loss: 0.1214 - out1_loss: 0.1316 - out2_loss: 0.0977 - val_loss: 0.1874 - val_out1_loss: 0.2089 - val_out2_loss: 0.1373\n",
      "Epoch 106/120\n",
      "53/53 - 6s - loss: 0.1215 - out1_loss: 0.1317 - out2_loss: 0.0978 - val_loss: 0.1874 - val_out1_loss: 0.2089 - val_out2_loss: 0.1372\n",
      "Epoch 107/120\n",
      "53/53 - 6s - loss: 0.1213 - out1_loss: 0.1314 - out2_loss: 0.0976 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 108/120\n",
      "53/53 - 6s - loss: 0.1214 - out1_loss: 0.1316 - out2_loss: 0.0977 - val_loss: 0.1874 - val_out1_loss: 0.2089 - val_out2_loss: 0.1373\n",
      "Epoch 109/120\n",
      "53/53 - 6s - loss: 0.1212 - out1_loss: 0.1314 - out2_loss: 0.0976 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 110/120\n",
      "53/53 - 6s - loss: 0.1211 - out1_loss: 0.1312 - out2_loss: 0.0976 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 111/120\n",
      "53/53 - 6s - loss: 0.1214 - out1_loss: 0.1316 - out2_loss: 0.0976 - val_loss: 0.1873 - val_out1_loss: 0.2088 - val_out2_loss: 0.1372\n",
      "Epoch 112/120\n",
      "53/53 - 6s - loss: 0.1213 - out1_loss: 0.1314 - out2_loss: 0.0976 - val_loss: 0.1875 - val_out1_loss: 0.2089 - val_out2_loss: 0.1373\n",
      "Epoch 113/120\n",
      "53/53 - 6s - loss: 0.1211 - out1_loss: 0.1312 - out2_loss: 0.0974 - val_loss: 0.1874 - val_out1_loss: 0.2089 - val_out2_loss: 0.1373\n",
      "Epoch 114/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 6s - loss: 0.1211 - out1_loss: 0.1312 - out2_loss: 0.0976 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 115/120\n",
      "53/53 - 6s - loss: 0.1213 - out1_loss: 0.1314 - out2_loss: 0.0976 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 116/120\n",
      "53/53 - 6s - loss: 0.1211 - out1_loss: 0.1312 - out2_loss: 0.0976 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 117/120\n",
      "53/53 - 6s - loss: 0.1209 - out1_loss: 0.1310 - out2_loss: 0.0975 - val_loss: 0.1875 - val_out1_loss: 0.2090 - val_out2_loss: 0.1373\n",
      "Epoch 118/120\n",
      "53/53 - 6s - loss: 0.1210 - out1_loss: 0.1311 - out2_loss: 0.0975 - val_loss: 0.1874 - val_out1_loss: 0.2089 - val_out2_loss: 0.1373\n",
      "Epoch 119/120\n",
      "53/53 - 6s - loss: 0.1210 - out1_loss: 0.1311 - out2_loss: 0.0975 - val_loss: 0.1874 - val_out1_loss: 0.2089 - val_out2_loss: 0.1373\n",
      "Epoch 120/120\n",
      "53/53 - 6s - loss: 0.1211 - out1_loss: 0.1312 - out2_loss: 0.0975 - val_loss: 0.1874 - val_out1_loss: 0.2089 - val_out2_loss: 0.1373\n",
      "#################### 0.3561661794835912\n",
      "(None, 107, 1024)\n",
      "(None, 130, 1024)\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "(None, 107, 1024)\n",
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 107, 7)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_48 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_49 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_50 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_51 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_52 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_53 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_54 (T [(None, 107)]        0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_42 (Embedding)        (None, 107, 128)     512         tf_op_layer_strided_slice_48[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_43 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_49[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_44 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_50[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_45 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_51[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_52[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_53[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_48 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_54[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_48 (SpatialDr (None, 107, 128)     0           embedding_42[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_49 (SpatialDr (None, 107, 128)     0           embedding_43[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_50 (SpatialDr (None, 107, 128)     0           embedding_44[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_51 (SpatialDr (None, 107, 128)     0           embedding_45[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_52 (SpatialDr (None, 107, 128)     0           embedding_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_53 (SpatialDr (None, 107, 128)     0           embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_54 (SpatialDr (None, 107, 128)     0           embedding_48[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_12 (TensorFl [(None, 107, 896)]   0           spatial_dropout1d_48[0][0]       \n",
      "                                                                 spatial_dropout1d_49[0][0]       \n",
      "                                                                 spatial_dropout1d_50[0][0]       \n",
      "                                                                 spatial_dropout1d_51[0][0]       \n",
      "                                                                 spatial_dropout1d_52[0][0]       \n",
      "                                                                 spatial_dropout1d_53[0][0]       \n",
      "                                                                 spatial_dropout1d_54[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_55 (SpatialDr (None, 107, 896)     0           tf_op_layer_concat_12[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 107, 128)     256         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_13 (TensorFl [(None, 107, 1024)]  0           spatial_dropout1d_55[0][0]       \n",
      "                                                                 dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_6 (Transforme (None, 107, 1024)    6301696     tf_op_layer_concat_13[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_18 (Bidirectional (None, 107, 768)     3248640     transformer_block_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_19 (Bidirectional (None, 107, 768)     2658816     bidirectional_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 107, 768)     2658816     bidirectional_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_55 (T [(None, 68, 768)]    0           bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_55[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_55[0][0\n",
      "==================================================================================================\n",
      "Total params: 14,881,290\n",
      "Trainable params: 14,881,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 7s - loss: 0.7350 - out1_loss: 0.8129 - out2_loss: 0.5533 - val_loss: 0.3949 - val_out1_loss: 0.4351 - val_out2_loss: 0.3009\n",
      "Epoch 2/120\n",
      "53/53 - 6s - loss: 0.3855 - out1_loss: 0.4243 - out2_loss: 0.2951 - val_loss: 0.3878 - val_out1_loss: 0.4263 - val_out2_loss: 0.2979\n",
      "Epoch 3/120\n",
      "53/53 - 6s - loss: 0.3815 - out1_loss: 0.4194 - out2_loss: 0.2931 - val_loss: 0.3858 - val_out1_loss: 0.4252 - val_out2_loss: 0.2938\n",
      "Epoch 4/120\n",
      "53/53 - 6s - loss: 0.3778 - out1_loss: 0.4161 - out2_loss: 0.2885 - val_loss: 0.3806 - val_out1_loss: 0.4181 - val_out2_loss: 0.2933\n",
      "Epoch 5/120\n",
      "53/53 - 6s - loss: 0.3769 - out1_loss: 0.4152 - out2_loss: 0.2877 - val_loss: 0.3842 - val_out1_loss: 0.4232 - val_out2_loss: 0.2932\n",
      "Epoch 6/120\n",
      "53/53 - 6s - loss: 0.3764 - out1_loss: 0.4149 - out2_loss: 0.2867 - val_loss: 0.3792 - val_out1_loss: 0.4179 - val_out2_loss: 0.2890\n",
      "Epoch 7/120\n",
      "53/53 - 6s - loss: 0.3745 - out1_loss: 0.4133 - out2_loss: 0.2837 - val_loss: 0.3836 - val_out1_loss: 0.4226 - val_out2_loss: 0.2927\n",
      "Epoch 8/120\n",
      "53/53 - 6s - loss: 0.3756 - out1_loss: 0.4145 - out2_loss: 0.2850 - val_loss: 0.3793 - val_out1_loss: 0.4185 - val_out2_loss: 0.2878\n",
      "Epoch 9/120\n",
      "53/53 - 6s - loss: 0.3677 - out1_loss: 0.4061 - out2_loss: 0.2781 - val_loss: 0.3551 - val_out1_loss: 0.3956 - val_out2_loss: 0.2607\n",
      "Epoch 10/120\n",
      "53/53 - 6s - loss: 0.3518 - out1_loss: 0.3895 - out2_loss: 0.2638 - val_loss: 0.3393 - val_out1_loss: 0.3786 - val_out2_loss: 0.2478\n",
      "Epoch 11/120\n",
      "53/53 - 6s - loss: 0.3341 - out1_loss: 0.3712 - out2_loss: 0.2475 - val_loss: 0.3333 - val_out1_loss: 0.3680 - val_out2_loss: 0.2523\n",
      "Epoch 12/120\n",
      "53/53 - 6s - loss: 0.3157 - out1_loss: 0.3517 - out2_loss: 0.2318 - val_loss: 0.2998 - val_out1_loss: 0.3353 - val_out2_loss: 0.2169\n",
      "Epoch 13/120\n",
      "53/53 - 6s - loss: 0.3002 - out1_loss: 0.3338 - out2_loss: 0.2217 - val_loss: 0.3044 - val_out1_loss: 0.3412 - val_out2_loss: 0.2186\n",
      "Epoch 14/120\n",
      "53/53 - 6s - loss: 0.2918 - out1_loss: 0.3245 - out2_loss: 0.2154 - val_loss: 0.2801 - val_out1_loss: 0.3125 - val_out2_loss: 0.2045\n",
      "Epoch 15/120\n",
      "53/53 - 6s - loss: 0.2777 - out1_loss: 0.3094 - out2_loss: 0.2037 - val_loss: 0.2700 - val_out1_loss: 0.3003 - val_out2_loss: 0.1992\n",
      "Epoch 16/120\n",
      "53/53 - 6s - loss: 0.2743 - out1_loss: 0.3057 - out2_loss: 0.2010 - val_loss: 0.2679 - val_out1_loss: 0.2983 - val_out2_loss: 0.1971\n",
      "Epoch 17/120\n",
      "53/53 - 6s - loss: 0.2683 - out1_loss: 0.2989 - out2_loss: 0.1969 - val_loss: 0.2616 - val_out1_loss: 0.2916 - val_out2_loss: 0.1914\n",
      "Epoch 18/120\n",
      "53/53 - 6s - loss: 0.2610 - out1_loss: 0.2906 - out2_loss: 0.1921 - val_loss: 0.2571 - val_out1_loss: 0.2831 - val_out2_loss: 0.1964\n",
      "Epoch 19/120\n",
      "53/53 - 6s - loss: 0.2541 - out1_loss: 0.2828 - out2_loss: 0.1872 - val_loss: 0.2490 - val_out1_loss: 0.2770 - val_out2_loss: 0.1839\n",
      "Epoch 20/120\n",
      "53/53 - 6s - loss: 0.2491 - out1_loss: 0.2773 - out2_loss: 0.1835 - val_loss: 0.2468 - val_out1_loss: 0.2747 - val_out2_loss: 0.1818\n",
      "Epoch 21/120\n",
      "53/53 - 6s - loss: 0.2457 - out1_loss: 0.2733 - out2_loss: 0.1812 - val_loss: 0.2422 - val_out1_loss: 0.2679 - val_out2_loss: 0.1823\n",
      "Epoch 22/120\n",
      "53/53 - 6s - loss: 0.2380 - out1_loss: 0.2646 - out2_loss: 0.1760 - val_loss: 0.2367 - val_out1_loss: 0.2626 - val_out2_loss: 0.1763\n",
      "Epoch 23/120\n",
      "53/53 - 6s - loss: 0.2333 - out1_loss: 0.2590 - out2_loss: 0.1735 - val_loss: 0.2329 - val_out1_loss: 0.2591 - val_out2_loss: 0.1717\n",
      "Epoch 24/120\n",
      "53/53 - 6s - loss: 0.2327 - out1_loss: 0.2576 - out2_loss: 0.1746 - val_loss: 0.2487 - val_out1_loss: 0.2722 - val_out2_loss: 0.1940\n",
      "Epoch 25/120\n",
      "53/53 - 6s - loss: 0.2271 - out1_loss: 0.2511 - out2_loss: 0.1712 - val_loss: 0.2233 - val_out1_loss: 0.2476 - val_out2_loss: 0.1665\n",
      "Epoch 26/120\n",
      "53/53 - 6s - loss: 0.2179 - out1_loss: 0.2413 - out2_loss: 0.1635 - val_loss: 0.2202 - val_out1_loss: 0.2450 - val_out2_loss: 0.1622\n",
      "Epoch 27/120\n",
      "53/53 - 6s - loss: 0.2164 - out1_loss: 0.2395 - out2_loss: 0.1625 - val_loss: 0.2196 - val_out1_loss: 0.2434 - val_out2_loss: 0.1643\n",
      "Epoch 28/120\n",
      "53/53 - 6s - loss: 0.2123 - out1_loss: 0.2345 - out2_loss: 0.1605 - val_loss: 0.2180 - val_out1_loss: 0.2426 - val_out2_loss: 0.1607\n",
      "Epoch 29/120\n",
      "53/53 - 7s - loss: 0.2101 - out1_loss: 0.2327 - out2_loss: 0.1576 - val_loss: 0.2205 - val_out1_loss: 0.2460 - val_out2_loss: 0.1613\n",
      "Epoch 30/120\n",
      "53/53 - 6s - loss: 0.2069 - out1_loss: 0.2289 - out2_loss: 0.1555 - val_loss: 0.2128 - val_out1_loss: 0.2368 - val_out2_loss: 0.1566\n",
      "Epoch 31/120\n",
      "53/53 - 6s - loss: 0.2029 - out1_loss: 0.2246 - out2_loss: 0.1522 - val_loss: 0.2110 - val_out1_loss: 0.2341 - val_out2_loss: 0.1573\n",
      "Epoch 32/120\n",
      "53/53 - 6s - loss: 0.1998 - out1_loss: 0.2212 - out2_loss: 0.1501 - val_loss: 0.2099 - val_out1_loss: 0.2327 - val_out2_loss: 0.1567\n",
      "Epoch 33/120\n",
      "53/53 - 6s - loss: 0.2005 - out1_loss: 0.2216 - out2_loss: 0.1515 - val_loss: 0.2093 - val_out1_loss: 0.2333 - val_out2_loss: 0.1531\n",
      "Epoch 34/120\n",
      "53/53 - 6s - loss: 0.1976 - out1_loss: 0.2184 - out2_loss: 0.1488 - val_loss: 0.2125 - val_out1_loss: 0.2371 - val_out2_loss: 0.1549\n",
      "Epoch 35/120\n",
      "53/53 - 6s - loss: 0.1939 - out1_loss: 0.2143 - out2_loss: 0.1463 - val_loss: 0.2095 - val_out1_loss: 0.2332 - val_out2_loss: 0.1541\n",
      "Epoch 36/120\n",
      "53/53 - 6s - loss: 0.1923 - out1_loss: 0.2126 - out2_loss: 0.1449 - val_loss: 0.2080 - val_out1_loss: 0.2312 - val_out2_loss: 0.1537\n",
      "Epoch 37/120\n",
      "53/53 - 7s - loss: 0.1889 - out1_loss: 0.2086 - out2_loss: 0.1427 - val_loss: 0.2066 - val_out1_loss: 0.2289 - val_out2_loss: 0.1545\n",
      "Epoch 38/120\n",
      "53/53 - 6s - loss: 0.1859 - out1_loss: 0.2055 - out2_loss: 0.1401 - val_loss: 0.2073 - val_out1_loss: 0.2293 - val_out2_loss: 0.1560\n",
      "Epoch 39/120\n",
      "53/53 - 6s - loss: 0.1846 - out1_loss: 0.2036 - out2_loss: 0.1404 - val_loss: 0.2065 - val_out1_loss: 0.2285 - val_out2_loss: 0.1551\n",
      "Epoch 40/120\n",
      "53/53 - 6s - loss: 0.1818 - out1_loss: 0.2005 - out2_loss: 0.1384 - val_loss: 0.2059 - val_out1_loss: 0.2296 - val_out2_loss: 0.1507\n",
      "Epoch 41/120\n",
      "53/53 - 6s - loss: 0.1807 - out1_loss: 0.1993 - out2_loss: 0.1372 - val_loss: 0.2035 - val_out1_loss: 0.2266 - val_out2_loss: 0.1497\n",
      "Epoch 42/120\n",
      "53/53 - 6s - loss: 0.1791 - out1_loss: 0.1976 - out2_loss: 0.1361 - val_loss: 0.2046 - val_out1_loss: 0.2278 - val_out2_loss: 0.1503\n",
      "Epoch 43/120\n",
      "53/53 - 6s - loss: 0.1772 - out1_loss: 0.1954 - out2_loss: 0.1348 - val_loss: 0.2177 - val_out1_loss: 0.2410 - val_out2_loss: 0.1633\n",
      "Epoch 44/120\n",
      "53/53 - 5s - loss: 0.1777 - out1_loss: 0.1952 - out2_loss: 0.1369 - val_loss: 0.2045 - val_out1_loss: 0.2281 - val_out2_loss: 0.1492\n",
      "Epoch 45/120\n",
      "53/53 - 5s - loss: 0.1749 - out1_loss: 0.1921 - out2_loss: 0.1347 - val_loss: 0.2130 - val_out1_loss: 0.2337 - val_out2_loss: 0.1645\n",
      "Epoch 46/120\n",
      "53/53 - 6s - loss: 0.1734 - out1_loss: 0.1907 - out2_loss: 0.1330 - val_loss: 0.2051 - val_out1_loss: 0.2287 - val_out2_loss: 0.1502\n",
      "Epoch 47/120\n",
      "53/53 - 6s - loss: 0.1711 - out1_loss: 0.1881 - out2_loss: 0.1312 - val_loss: 0.2031 - val_out1_loss: 0.2266 - val_out2_loss: 0.1483\n",
      "Epoch 48/120\n",
      "53/53 - 6s - loss: 0.1682 - out1_loss: 0.1851 - out2_loss: 0.1287 - val_loss: 0.2041 - val_out1_loss: 0.2257 - val_out2_loss: 0.1537\n",
      "Epoch 49/120\n",
      "53/53 - 6s - loss: 0.1692 - out1_loss: 0.1859 - out2_loss: 0.1302 - val_loss: 0.2052 - val_out1_loss: 0.2288 - val_out2_loss: 0.1501\n",
      "Epoch 50/120\n",
      "53/53 - 6s - loss: 0.1673 - out1_loss: 0.1836 - out2_loss: 0.1293 - val_loss: 0.2010 - val_out1_loss: 0.2245 - val_out2_loss: 0.1460\n",
      "Epoch 51/120\n",
      "53/53 - 6s - loss: 0.1646 - out1_loss: 0.1807 - out2_loss: 0.1270 - val_loss: 0.2003 - val_out1_loss: 0.2217 - val_out2_loss: 0.1503\n",
      "Epoch 52/120\n",
      "53/53 - 6s - loss: 0.1635 - out1_loss: 0.1787 - out2_loss: 0.1279 - val_loss: 0.2014 - val_out1_loss: 0.2238 - val_out2_loss: 0.1491\n",
      "Epoch 53/120\n",
      "53/53 - 6s - loss: 0.1640 - out1_loss: 0.1792 - out2_loss: 0.1284 - val_loss: 0.2075 - val_out1_loss: 0.2306 - val_out2_loss: 0.1535\n",
      "Epoch 54/120\n",
      "53/53 - 6s - loss: 0.1628 - out1_loss: 0.1787 - out2_loss: 0.1258 - val_loss: 0.2009 - val_out1_loss: 0.2238 - val_out2_loss: 0.1474\n",
      "Epoch 55/120\n",
      "53/53 - 6s - loss: 0.1604 - out1_loss: 0.1760 - out2_loss: 0.1240 - val_loss: 0.1984 - val_out1_loss: 0.2208 - val_out2_loss: 0.1461\n",
      "Epoch 56/120\n",
      "53/53 - 6s - loss: 0.1596 - out1_loss: 0.1751 - out2_loss: 0.1236 - val_loss: 0.1997 - val_out1_loss: 0.2227 - val_out2_loss: 0.1459\n",
      "Epoch 57/120\n",
      "53/53 - 5s - loss: 0.1575 - out1_loss: 0.1725 - out2_loss: 0.1227 - val_loss: 0.2047 - val_out1_loss: 0.2259 - val_out2_loss: 0.1553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "53/53 - 5s - loss: 0.1584 - out1_loss: 0.1738 - out2_loss: 0.1225 - val_loss: 0.1986 - val_out1_loss: 0.2209 - val_out2_loss: 0.1467\n",
      "Epoch 59/120\n",
      "53/53 - 6s - loss: 0.1549 - out1_loss: 0.1697 - out2_loss: 0.1206 - val_loss: 0.1985 - val_out1_loss: 0.2208 - val_out2_loss: 0.1463\n",
      "Epoch 60/120\n",
      "53/53 - 6s - loss: 0.1533 - out1_loss: 0.1674 - out2_loss: 0.1204 - val_loss: 0.2004 - val_out1_loss: 0.2221 - val_out2_loss: 0.1498\n",
      "Epoch 61/120\n",
      "53/53 - 5s - loss: 0.1542 - out1_loss: 0.1681 - out2_loss: 0.1219 - val_loss: 0.1971 - val_out1_loss: 0.2192 - val_out2_loss: 0.1457\n",
      "Epoch 62/120\n",
      "53/53 - 5s - loss: 0.1535 - out1_loss: 0.1681 - out2_loss: 0.1194 - val_loss: 0.1989 - val_out1_loss: 0.2206 - val_out2_loss: 0.1484\n",
      "Epoch 63/120\n",
      "53/53 - 6s - loss: 0.1536 - out1_loss: 0.1674 - out2_loss: 0.1214 - val_loss: 0.1994 - val_out1_loss: 0.2212 - val_out2_loss: 0.1485\n",
      "Epoch 64/120\n",
      "53/53 - 6s - loss: 0.1501 - out1_loss: 0.1641 - out2_loss: 0.1173 - val_loss: 0.1985 - val_out1_loss: 0.2213 - val_out2_loss: 0.1453\n",
      "Epoch 65/120\n",
      "53/53 - 6s - loss: 0.1502 - out1_loss: 0.1643 - out2_loss: 0.1174 - val_loss: 0.1991 - val_out1_loss: 0.2219 - val_out2_loss: 0.1458\n",
      "Epoch 66/120\n",
      "53/53 - 6s - loss: 0.1486 - out1_loss: 0.1624 - out2_loss: 0.1165 - val_loss: 0.1983 - val_out1_loss: 0.2196 - val_out2_loss: 0.1485\n",
      "Epoch 67/120\n",
      "53/53 - 6s - loss: 0.1478 - out1_loss: 0.1615 - out2_loss: 0.1158 - val_loss: 0.1989 - val_out1_loss: 0.2219 - val_out2_loss: 0.1453\n",
      "Epoch 68/120\n",
      "53/53 - 6s - loss: 0.1490 - out1_loss: 0.1620 - out2_loss: 0.1186 - val_loss: 0.1990 - val_out1_loss: 0.2214 - val_out2_loss: 0.1469\n",
      "Epoch 69/120\n",
      "53/53 - 6s - loss: 0.1478 - out1_loss: 0.1614 - out2_loss: 0.1160 - val_loss: 0.2014 - val_out1_loss: 0.2246 - val_out2_loss: 0.1471\n",
      "Epoch 70/120\n",
      "53/53 - 6s - loss: 0.1472 - out1_loss: 0.1606 - out2_loss: 0.1159 - val_loss: 0.1996 - val_out1_loss: 0.2224 - val_out2_loss: 0.1466\n",
      "Epoch 71/120\n",
      "53/53 - 6s - loss: 0.1448 - out1_loss: 0.1580 - out2_loss: 0.1140 - val_loss: 0.1970 - val_out1_loss: 0.2195 - val_out2_loss: 0.1445\n",
      "Epoch 72/120\n",
      "53/53 - 6s - loss: 0.1457 - out1_loss: 0.1591 - out2_loss: 0.1146 - val_loss: 0.1990 - val_out1_loss: 0.2214 - val_out2_loss: 0.1467\n",
      "Epoch 73/120\n",
      "53/53 - 6s - loss: 0.1444 - out1_loss: 0.1573 - out2_loss: 0.1143 - val_loss: 0.2024 - val_out1_loss: 0.2243 - val_out2_loss: 0.1513\n",
      "Epoch 74/120\n",
      "53/53 - 6s - loss: 0.1432 - out1_loss: 0.1555 - out2_loss: 0.1146 - val_loss: 0.1999 - val_out1_loss: 0.2222 - val_out2_loss: 0.1479\n",
      "Epoch 75/120\n",
      "53/53 - 6s - loss: 0.1419 - out1_loss: 0.1546 - out2_loss: 0.1120 - val_loss: 0.1971 - val_out1_loss: 0.2196 - val_out2_loss: 0.1447\n",
      "Epoch 76/120\n",
      "53/53 - 6s - loss: 0.1424 - out1_loss: 0.1552 - out2_loss: 0.1125 - val_loss: 0.1985 - val_out1_loss: 0.2211 - val_out2_loss: 0.1458\n",
      "Epoch 77/120\n",
      "53/53 - 6s - loss: 0.1424 - out1_loss: 0.1551 - out2_loss: 0.1128 - val_loss: 0.1986 - val_out1_loss: 0.2214 - val_out2_loss: 0.1452\n",
      "Epoch 78/120\n",
      "53/53 - 6s - loss: 0.1429 - out1_loss: 0.1556 - out2_loss: 0.1130 - val_loss: 0.1986 - val_out1_loss: 0.2205 - val_out2_loss: 0.1476\n",
      "Epoch 79/120\n",
      "53/53 - 6s - loss: 0.1390 - out1_loss: 0.1515 - out2_loss: 0.1100 - val_loss: 0.1988 - val_out1_loss: 0.2207 - val_out2_loss: 0.1476\n",
      "Epoch 80/120\n",
      "53/53 - 6s - loss: 0.1403 - out1_loss: 0.1526 - out2_loss: 0.1117 - val_loss: 0.1989 - val_out1_loss: 0.2214 - val_out2_loss: 0.1466\n",
      "Epoch 81/120\n",
      "53/53 - 6s - loss: 0.1407 - out1_loss: 0.1530 - out2_loss: 0.1118 - val_loss: 0.1981 - val_out1_loss: 0.2206 - val_out2_loss: 0.1457\n",
      "Epoch 82/120\n",
      "53/53 - 6s - loss: 0.1330 - out1_loss: 0.1448 - out2_loss: 0.1056 - val_loss: 0.1951 - val_out1_loss: 0.2175 - val_out2_loss: 0.1428\n",
      "Epoch 83/120\n",
      "53/53 - 6s - loss: 0.1301 - out1_loss: 0.1416 - out2_loss: 0.1035 - val_loss: 0.1948 - val_out1_loss: 0.2172 - val_out2_loss: 0.1424\n",
      "Epoch 84/120\n",
      "53/53 - 6s - loss: 0.1289 - out1_loss: 0.1401 - out2_loss: 0.1027 - val_loss: 0.1948 - val_out1_loss: 0.2173 - val_out2_loss: 0.1423\n",
      "Epoch 85/120\n",
      "53/53 - 6s - loss: 0.1282 - out1_loss: 0.1392 - out2_loss: 0.1023 - val_loss: 0.1946 - val_out1_loss: 0.2170 - val_out2_loss: 0.1423\n",
      "Epoch 86/120\n",
      "53/53 - 6s - loss: 0.1278 - out1_loss: 0.1388 - out2_loss: 0.1021 - val_loss: 0.1946 - val_out1_loss: 0.2170 - val_out2_loss: 0.1422\n",
      "Epoch 87/120\n",
      "53/53 - 6s - loss: 0.1274 - out1_loss: 0.1384 - out2_loss: 0.1017 - val_loss: 0.1945 - val_out1_loss: 0.2169 - val_out2_loss: 0.1421\n",
      "Epoch 88/120\n",
      "53/53 - 7s - loss: 0.1268 - out1_loss: 0.1377 - out2_loss: 0.1015 - val_loss: 0.1942 - val_out1_loss: 0.2166 - val_out2_loss: 0.1420\n",
      "Epoch 89/120\n",
      "53/53 - 6s - loss: 0.1265 - out1_loss: 0.1373 - out2_loss: 0.1012 - val_loss: 0.1942 - val_out1_loss: 0.2165 - val_out2_loss: 0.1421\n",
      "Epoch 90/120\n",
      "53/53 - 6s - loss: 0.1262 - out1_loss: 0.1369 - out2_loss: 0.1010 - val_loss: 0.1943 - val_out1_loss: 0.2166 - val_out2_loss: 0.1421\n",
      "Epoch 91/120\n",
      "53/53 - 6s - loss: 0.1260 - out1_loss: 0.1367 - out2_loss: 0.1009 - val_loss: 0.1943 - val_out1_loss: 0.2166 - val_out2_loss: 0.1421\n",
      "Epoch 92/120\n",
      "53/53 - 6s - loss: 0.1256 - out1_loss: 0.1363 - out2_loss: 0.1006 - val_loss: 0.1941 - val_out1_loss: 0.2165 - val_out2_loss: 0.1419\n",
      "Epoch 93/120\n",
      "53/53 - 5s - loss: 0.1254 - out1_loss: 0.1361 - out2_loss: 0.1005 - val_loss: 0.1942 - val_out1_loss: 0.2166 - val_out2_loss: 0.1419\n",
      "Epoch 94/120\n",
      "53/53 - 5s - loss: 0.1251 - out1_loss: 0.1357 - out2_loss: 0.1003 - val_loss: 0.1943 - val_out1_loss: 0.2167 - val_out2_loss: 0.1419\n",
      "Epoch 95/120\n",
      "53/53 - 6s - loss: 0.1251 - out1_loss: 0.1357 - out2_loss: 0.1002 - val_loss: 0.1943 - val_out1_loss: 0.2167 - val_out2_loss: 0.1420\n",
      "Epoch 96/120\n",
      "53/53 - 6s - loss: 0.1247 - out1_loss: 0.1353 - out2_loss: 0.1000 - val_loss: 0.1941 - val_out1_loss: 0.2164 - val_out2_loss: 0.1419\n",
      "Epoch 97/120\n",
      "53/53 - 5s - loss: 0.1247 - out1_loss: 0.1353 - out2_loss: 0.1000 - val_loss: 0.1941 - val_out1_loss: 0.2166 - val_out2_loss: 0.1418\n",
      "Epoch 98/120\n",
      "53/53 - 5s - loss: 0.1244 - out1_loss: 0.1350 - out2_loss: 0.0997 - val_loss: 0.1941 - val_out1_loss: 0.2165 - val_out2_loss: 0.1418\n",
      "Epoch 99/120\n",
      "53/53 - 6s - loss: 0.1242 - out1_loss: 0.1348 - out2_loss: 0.0996 - val_loss: 0.1940 - val_out1_loss: 0.2164 - val_out2_loss: 0.1418\n",
      "Epoch 100/120\n",
      "53/53 - 5s - loss: 0.1238 - out1_loss: 0.1343 - out2_loss: 0.0994 - val_loss: 0.1942 - val_out1_loss: 0.2166 - val_out2_loss: 0.1419\n",
      "Epoch 101/120\n",
      "53/53 - 6s - loss: 0.1238 - out1_loss: 0.1343 - out2_loss: 0.0994 - val_loss: 0.1943 - val_out1_loss: 0.2167 - val_out2_loss: 0.1420\n",
      "Epoch 102/120\n",
      "53/53 - 5s - loss: 0.1236 - out1_loss: 0.1341 - out2_loss: 0.0993 - val_loss: 0.1942 - val_out1_loss: 0.2166 - val_out2_loss: 0.1419\n",
      "Epoch 103/120\n",
      "53/53 - 6s - loss: 0.1231 - out1_loss: 0.1334 - out2_loss: 0.0989 - val_loss: 0.1940 - val_out1_loss: 0.2165 - val_out2_loss: 0.1417\n",
      "Epoch 104/120\n",
      "53/53 - 6s - loss: 0.1231 - out1_loss: 0.1335 - out2_loss: 0.0990 - val_loss: 0.1940 - val_out1_loss: 0.2164 - val_out2_loss: 0.1417\n",
      "Epoch 105/120\n",
      "53/53 - 6s - loss: 0.1228 - out1_loss: 0.1331 - out2_loss: 0.0988 - val_loss: 0.1940 - val_out1_loss: 0.2164 - val_out2_loss: 0.1417\n",
      "Epoch 106/120\n",
      "53/53 - 6s - loss: 0.1230 - out1_loss: 0.1333 - out2_loss: 0.0990 - val_loss: 0.1940 - val_out1_loss: 0.2164 - val_out2_loss: 0.1417\n",
      "Epoch 107/120\n",
      "53/53 - 6s - loss: 0.1228 - out1_loss: 0.1331 - out2_loss: 0.0987 - val_loss: 0.1940 - val_out1_loss: 0.2164 - val_out2_loss: 0.1417\n",
      "Epoch 108/120\n",
      "53/53 - 6s - loss: 0.1227 - out1_loss: 0.1330 - out2_loss: 0.0986 - val_loss: 0.1939 - val_out1_loss: 0.2163 - val_out2_loss: 0.1416\n",
      "Epoch 109/120\n",
      "53/53 - 6s - loss: 0.1227 - out1_loss: 0.1329 - out2_loss: 0.0988 - val_loss: 0.1939 - val_out1_loss: 0.2163 - val_out2_loss: 0.1416\n",
      "Epoch 110/120\n",
      "53/53 - 6s - loss: 0.1227 - out1_loss: 0.1329 - out2_loss: 0.0988 - val_loss: 0.1940 - val_out1_loss: 0.2164 - val_out2_loss: 0.1417\n",
      "Epoch 111/120\n",
      "53/53 - 6s - loss: 0.1227 - out1_loss: 0.1329 - out2_loss: 0.0988 - val_loss: 0.1940 - val_out1_loss: 0.2164 - val_out2_loss: 0.1416\n",
      "Epoch 112/120\n",
      "53/53 - 6s - loss: 0.1226 - out1_loss: 0.1329 - out2_loss: 0.0987 - val_loss: 0.1939 - val_out1_loss: 0.2163 - val_out2_loss: 0.1416\n",
      "Epoch 113/120\n",
      "53/53 - 7s - loss: 0.1226 - out1_loss: 0.1328 - out2_loss: 0.0987 - val_loss: 0.1939 - val_out1_loss: 0.2163 - val_out2_loss: 0.1416\n",
      "Epoch 114/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 6s - loss: 0.1226 - out1_loss: 0.1328 - out2_loss: 0.0986 - val_loss: 0.1940 - val_out1_loss: 0.2164 - val_out2_loss: 0.1416\n",
      "Epoch 115/120\n",
      "53/53 - 6s - loss: 0.1226 - out1_loss: 0.1328 - out2_loss: 0.0986 - val_loss: 0.1940 - val_out1_loss: 0.2164 - val_out2_loss: 0.1416\n",
      "Epoch 116/120\n",
      "53/53 - 6s - loss: 0.1225 - out1_loss: 0.1328 - out2_loss: 0.0986 - val_loss: 0.1939 - val_out1_loss: 0.2164 - val_out2_loss: 0.1416\n",
      "Epoch 117/120\n",
      "53/53 - 6s - loss: 0.1225 - out1_loss: 0.1328 - out2_loss: 0.0986 - val_loss: 0.1940 - val_out1_loss: 0.2164 - val_out2_loss: 0.1417\n",
      "Epoch 118/120\n",
      "53/53 - 6s - loss: 0.1223 - out1_loss: 0.1325 - out2_loss: 0.0984 - val_loss: 0.1939 - val_out1_loss: 0.2164 - val_out2_loss: 0.1417\n",
      "Epoch 119/120\n",
      "53/53 - 6s - loss: 0.1225 - out1_loss: 0.1327 - out2_loss: 0.0986 - val_loss: 0.1939 - val_out1_loss: 0.2163 - val_out2_loss: 0.1416\n",
      "Epoch 120/120\n",
      "53/53 - 6s - loss: 0.1222 - out1_loss: 0.1324 - out2_loss: 0.0985 - val_loss: 0.1939 - val_out1_loss: 0.2163 - val_out2_loss: 0.1416\n",
      "#################### 0.3688929930143698\n",
      "(None, 107, 1024)\n",
      "(None, 130, 1024)\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "(None, 107, 1024)\n",
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 107, 7)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_72 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_73 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_74 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_75 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_76 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_77 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_78 (T [(None, 107)]        0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_63 (Embedding)        (None, 107, 128)     512         tf_op_layer_strided_slice_72[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_64 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_73[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_65 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_74[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_66 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_75[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_67 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_76[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_68 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_77[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_69 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_78[0][0\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_72 (SpatialDr (None, 107, 128)     0           embedding_63[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_73 (SpatialDr (None, 107, 128)     0           embedding_64[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_74 (SpatialDr (None, 107, 128)     0           embedding_65[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_75 (SpatialDr (None, 107, 128)     0           embedding_66[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_76 (SpatialDr (None, 107, 128)     0           embedding_67[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_77 (SpatialDr (None, 107, 128)     0           embedding_68[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_78 (SpatialDr (None, 107, 128)     0           embedding_69[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_18 (TensorFl [(None, 107, 896)]   0           spatial_dropout1d_72[0][0]       \n",
      "                                                                 spatial_dropout1d_73[0][0]       \n",
      "                                                                 spatial_dropout1d_74[0][0]       \n",
      "                                                                 spatial_dropout1d_75[0][0]       \n",
      "                                                                 spatial_dropout1d_76[0][0]       \n",
      "                                                                 spatial_dropout1d_77[0][0]       \n",
      "                                                                 spatial_dropout1d_78[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_79 (SpatialDr (None, 107, 896)     0           tf_op_layer_concat_18[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 107, 128)     256         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_19 (TensorFl [(None, 107, 1024)]  0           spatial_dropout1d_79[0][0]       \n",
      "                                                                 dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_9 (Transforme (None, 107, 1024)    6301696     tf_op_layer_concat_19[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_27 (Bidirectional (None, 107, 768)     3248640     transformer_block_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_28 (Bidirectional (None, 107, 768)     2658816     bidirectional_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_29 (Bidirectional (None, 107, 768)     2658816     bidirectional_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_79 (T [(None, 68, 768)]    0           bidirectional_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_79[0][0\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_79[0][0\n",
      "==================================================================================================\n",
      "Total params: 14,881,290\n",
      "Trainable params: 14,881,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 8s - loss: 0.7339 - out1_loss: 0.8156 - out2_loss: 0.5433 - val_loss: 0.3939 - val_out1_loss: 0.4343 - val_out2_loss: 0.2997\n",
      "Epoch 2/120\n",
      "53/53 - 6s - loss: 0.3885 - out1_loss: 0.4284 - out2_loss: 0.2952 - val_loss: 0.3872 - val_out1_loss: 0.4297 - val_out2_loss: 0.2880\n",
      "Epoch 3/120\n",
      "53/53 - 6s - loss: 0.3814 - out1_loss: 0.4205 - out2_loss: 0.2902 - val_loss: 0.3805 - val_out1_loss: 0.4205 - val_out2_loss: 0.2874\n",
      "Epoch 4/120\n",
      "53/53 - 6s - loss: 0.3785 - out1_loss: 0.4168 - out2_loss: 0.2892 - val_loss: 0.3779 - val_out1_loss: 0.4173 - val_out2_loss: 0.2859\n",
      "Epoch 5/120\n",
      "53/53 - 6s - loss: 0.3789 - out1_loss: 0.4171 - out2_loss: 0.2897 - val_loss: 0.3758 - val_out1_loss: 0.4148 - val_out2_loss: 0.2848\n",
      "Epoch 6/120\n",
      "53/53 - 7s - loss: 0.3765 - out1_loss: 0.4143 - out2_loss: 0.2883 - val_loss: 0.3752 - val_out1_loss: 0.4146 - val_out2_loss: 0.2835\n",
      "Epoch 7/120\n",
      "53/53 - 6s - loss: 0.3769 - out1_loss: 0.4155 - out2_loss: 0.2869 - val_loss: 0.3893 - val_out1_loss: 0.4271 - val_out2_loss: 0.3011\n",
      "Epoch 8/120\n",
      "53/53 - 6s - loss: 0.3769 - out1_loss: 0.4147 - out2_loss: 0.2887 - val_loss: 0.3784 - val_out1_loss: 0.4194 - val_out2_loss: 0.2828\n",
      "Epoch 9/120\n",
      "53/53 - 6s - loss: 0.3687 - out1_loss: 0.4071 - out2_loss: 0.2790 - val_loss: 0.3491 - val_out1_loss: 0.3900 - val_out2_loss: 0.2538\n",
      "Epoch 10/120\n",
      "53/53 - 6s - loss: 0.3430 - out1_loss: 0.3814 - out2_loss: 0.2533 - val_loss: 0.3296 - val_out1_loss: 0.3675 - val_out2_loss: 0.2410\n",
      "Epoch 11/120\n",
      "53/53 - 6s - loss: 0.3282 - out1_loss: 0.3645 - out2_loss: 0.2437 - val_loss: 0.3219 - val_out1_loss: 0.3614 - val_out2_loss: 0.2296\n",
      "Epoch 12/120\n",
      "53/53 - 5s - loss: 0.3193 - out1_loss: 0.3553 - out2_loss: 0.2352 - val_loss: 0.3127 - val_out1_loss: 0.3500 - val_out2_loss: 0.2256\n",
      "Epoch 13/120\n",
      "53/53 - 6s - loss: 0.3087 - out1_loss: 0.3440 - out2_loss: 0.2266 - val_loss: 0.3003 - val_out1_loss: 0.3371 - val_out2_loss: 0.2146\n",
      "Epoch 14/120\n",
      "53/53 - 5s - loss: 0.2959 - out1_loss: 0.3294 - out2_loss: 0.2177 - val_loss: 0.2953 - val_out1_loss: 0.3314 - val_out2_loss: 0.2111\n",
      "Epoch 15/120\n",
      "53/53 - 6s - loss: 0.2899 - out1_loss: 0.3227 - out2_loss: 0.2135 - val_loss: 0.2853 - val_out1_loss: 0.3176 - val_out2_loss: 0.2097\n",
      "Epoch 16/120\n",
      "53/53 - 6s - loss: 0.2809 - out1_loss: 0.3126 - out2_loss: 0.2072 - val_loss: 0.2805 - val_out1_loss: 0.3129 - val_out2_loss: 0.2049\n",
      "Epoch 17/120\n",
      "53/53 - 6s - loss: 0.2735 - out1_loss: 0.3046 - out2_loss: 0.2009 - val_loss: 0.2737 - val_out1_loss: 0.3040 - val_out2_loss: 0.2031\n",
      "Epoch 18/120\n",
      "53/53 - 6s - loss: 0.2692 - out1_loss: 0.2994 - out2_loss: 0.1988 - val_loss: 0.2646 - val_out1_loss: 0.2962 - val_out2_loss: 0.1908\n",
      "Epoch 19/120\n",
      "53/53 - 7s - loss: 0.2638 - out1_loss: 0.2935 - out2_loss: 0.1945 - val_loss: 0.2604 - val_out1_loss: 0.2909 - val_out2_loss: 0.1893\n",
      "Epoch 20/120\n",
      "53/53 - 6s - loss: 0.2571 - out1_loss: 0.2861 - out2_loss: 0.1892 - val_loss: 0.2513 - val_out1_loss: 0.2811 - val_out2_loss: 0.1818\n",
      "Epoch 21/120\n",
      "53/53 - 6s - loss: 0.2504 - out1_loss: 0.2789 - out2_loss: 0.1839 - val_loss: 0.2476 - val_out1_loss: 0.2754 - val_out2_loss: 0.1829\n",
      "Epoch 22/120\n",
      "53/53 - 6s - loss: 0.2438 - out1_loss: 0.2713 - out2_loss: 0.1798 - val_loss: 0.2438 - val_out1_loss: 0.2733 - val_out2_loss: 0.1751\n",
      "Epoch 23/120\n",
      "53/53 - 6s - loss: 0.2380 - out1_loss: 0.2643 - out2_loss: 0.1766 - val_loss: 0.2439 - val_out1_loss: 0.2718 - val_out2_loss: 0.1788\n",
      "Epoch 24/120\n",
      "53/53 - 6s - loss: 0.2332 - out1_loss: 0.2590 - out2_loss: 0.1731 - val_loss: 0.2323 - val_out1_loss: 0.2601 - val_out2_loss: 0.1672\n",
      "Epoch 25/120\n",
      "53/53 - 6s - loss: 0.2284 - out1_loss: 0.2530 - out2_loss: 0.1709 - val_loss: 0.2265 - val_out1_loss: 0.2523 - val_out2_loss: 0.1663\n",
      "Epoch 26/120\n",
      "53/53 - 6s - loss: 0.2222 - out1_loss: 0.2459 - out2_loss: 0.1668 - val_loss: 0.2249 - val_out1_loss: 0.2514 - val_out2_loss: 0.1633\n",
      "Epoch 27/120\n",
      "53/53 - 6s - loss: 0.2202 - out1_loss: 0.2439 - out2_loss: 0.1649 - val_loss: 0.2230 - val_out1_loss: 0.2475 - val_out2_loss: 0.1657\n",
      "Epoch 28/120\n",
      "53/53 - 6s - loss: 0.2148 - out1_loss: 0.2379 - out2_loss: 0.1609 - val_loss: 0.2226 - val_out1_loss: 0.2467 - val_out2_loss: 0.1664\n",
      "Epoch 29/120\n",
      "53/53 - 6s - loss: 0.2136 - out1_loss: 0.2364 - out2_loss: 0.1604 - val_loss: 0.2155 - val_out1_loss: 0.2405 - val_out2_loss: 0.1572\n",
      "Epoch 30/120\n",
      "53/53 - 5s - loss: 0.2125 - out1_loss: 0.2350 - out2_loss: 0.1601 - val_loss: 0.2153 - val_out1_loss: 0.2407 - val_out2_loss: 0.1560\n",
      "Epoch 31/120\n",
      "53/53 - 5s - loss: 0.2054 - out1_loss: 0.2274 - out2_loss: 0.1540 - val_loss: 0.2166 - val_out1_loss: 0.2394 - val_out2_loss: 0.1636\n",
      "Epoch 32/120\n",
      "53/53 - 6s - loss: 0.2032 - out1_loss: 0.2248 - out2_loss: 0.1527 - val_loss: 0.2150 - val_out1_loss: 0.2397 - val_out2_loss: 0.1575\n",
      "Epoch 33/120\n",
      "53/53 - 5s - loss: 0.2027 - out1_loss: 0.2240 - out2_loss: 0.1530 - val_loss: 0.2153 - val_out1_loss: 0.2397 - val_out2_loss: 0.1585\n",
      "Epoch 34/120\n",
      "53/53 - 5s - loss: 0.1998 - out1_loss: 0.2208 - out2_loss: 0.1507 - val_loss: 0.2127 - val_out1_loss: 0.2373 - val_out2_loss: 0.1553\n",
      "Epoch 35/120\n",
      "53/53 - 6s - loss: 0.1954 - out1_loss: 0.2160 - out2_loss: 0.1471 - val_loss: 0.2074 - val_out1_loss: 0.2313 - val_out2_loss: 0.1519\n",
      "Epoch 36/120\n",
      "53/53 - 6s - loss: 0.1965 - out1_loss: 0.2169 - out2_loss: 0.1489 - val_loss: 0.2240 - val_out1_loss: 0.2492 - val_out2_loss: 0.1652\n",
      "Epoch 37/120\n",
      "53/53 - 6s - loss: 0.1999 - out1_loss: 0.2204 - out2_loss: 0.1521 - val_loss: 0.2086 - val_out1_loss: 0.2332 - val_out2_loss: 0.1510\n",
      "Epoch 38/120\n",
      "53/53 - 6s - loss: 0.1899 - out1_loss: 0.2097 - out2_loss: 0.1437 - val_loss: 0.2174 - val_out1_loss: 0.2413 - val_out2_loss: 0.1616\n",
      "Epoch 39/120\n",
      "53/53 - 6s - loss: 0.1890 - out1_loss: 0.2088 - out2_loss: 0.1430 - val_loss: 0.2073 - val_out1_loss: 0.2311 - val_out2_loss: 0.1517\n",
      "Epoch 40/120\n",
      "53/53 - 6s - loss: 0.1851 - out1_loss: 0.2042 - out2_loss: 0.1404 - val_loss: 0.2085 - val_out1_loss: 0.2332 - val_out2_loss: 0.1509\n",
      "Epoch 41/120\n",
      "53/53 - 6s - loss: 0.1839 - out1_loss: 0.2029 - out2_loss: 0.1396 - val_loss: 0.2062 - val_out1_loss: 0.2300 - val_out2_loss: 0.1508\n",
      "Epoch 42/120\n",
      "53/53 - 6s - loss: 0.1819 - out1_loss: 0.2006 - out2_loss: 0.1383 - val_loss: 0.2124 - val_out1_loss: 0.2363 - val_out2_loss: 0.1564\n",
      "Epoch 43/120\n",
      "53/53 - 6s - loss: 0.1821 - out1_loss: 0.2005 - out2_loss: 0.1393 - val_loss: 0.2057 - val_out1_loss: 0.2300 - val_out2_loss: 0.1491\n",
      "Epoch 44/120\n",
      "53/53 - 6s - loss: 0.1780 - out1_loss: 0.1962 - out2_loss: 0.1354 - val_loss: 0.2044 - val_out1_loss: 0.2282 - val_out2_loss: 0.1489\n",
      "Epoch 45/120\n",
      "53/53 - 7s - loss: 0.1773 - out1_loss: 0.1953 - out2_loss: 0.1353 - val_loss: 0.2031 - val_out1_loss: 0.2266 - val_out2_loss: 0.1482\n",
      "Epoch 46/120\n",
      "53/53 - 6s - loss: 0.1742 - out1_loss: 0.1919 - out2_loss: 0.1330 - val_loss: 0.2019 - val_out1_loss: 0.2252 - val_out2_loss: 0.1475\n",
      "Epoch 47/120\n",
      "53/53 - 6s - loss: 0.1726 - out1_loss: 0.1899 - out2_loss: 0.1325 - val_loss: 0.2017 - val_out1_loss: 0.2248 - val_out2_loss: 0.1478\n",
      "Epoch 48/120\n",
      "53/53 - 6s - loss: 0.1714 - out1_loss: 0.1889 - out2_loss: 0.1308 - val_loss: 0.2061 - val_out1_loss: 0.2305 - val_out2_loss: 0.1490\n",
      "Epoch 49/120\n",
      "53/53 - 6s - loss: 0.1693 - out1_loss: 0.1863 - out2_loss: 0.1296 - val_loss: 0.2070 - val_out1_loss: 0.2282 - val_out2_loss: 0.1573\n",
      "Epoch 50/120\n",
      "53/53 - 6s - loss: 0.1682 - out1_loss: 0.1847 - out2_loss: 0.1295 - val_loss: 0.2022 - val_out1_loss: 0.2259 - val_out2_loss: 0.1468\n",
      "Epoch 51/120\n",
      "53/53 - 6s - loss: 0.1672 - out1_loss: 0.1838 - out2_loss: 0.1286 - val_loss: 0.2046 - val_out1_loss: 0.2278 - val_out2_loss: 0.1506\n",
      "Epoch 52/120\n",
      "53/53 - 6s - loss: 0.1662 - out1_loss: 0.1825 - out2_loss: 0.1283 - val_loss: 0.2020 - val_out1_loss: 0.2254 - val_out2_loss: 0.1473\n",
      "Epoch 53/120\n",
      "53/53 - 6s - loss: 0.1652 - out1_loss: 0.1816 - out2_loss: 0.1269 - val_loss: 0.2020 - val_out1_loss: 0.2255 - val_out2_loss: 0.1471\n",
      "Epoch 54/120\n",
      "53/53 - 6s - loss: 0.1647 - out1_loss: 0.1807 - out2_loss: 0.1272 - val_loss: 0.1998 - val_out1_loss: 0.2231 - val_out2_loss: 0.1453\n",
      "Epoch 55/120\n",
      "53/53 - 6s - loss: 0.1641 - out1_loss: 0.1799 - out2_loss: 0.1274 - val_loss: 0.2013 - val_out1_loss: 0.2250 - val_out2_loss: 0.1461\n",
      "Epoch 56/120\n",
      "53/53 - 6s - loss: 0.1617 - out1_loss: 0.1776 - out2_loss: 0.1248 - val_loss: 0.2029 - val_out1_loss: 0.2265 - val_out2_loss: 0.1477\n",
      "Epoch 57/120\n",
      "53/53 - 6s - loss: 0.1610 - out1_loss: 0.1765 - out2_loss: 0.1246 - val_loss: 0.2021 - val_out1_loss: 0.2253 - val_out2_loss: 0.1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "53/53 - 6s - loss: 0.1598 - out1_loss: 0.1750 - out2_loss: 0.1244 - val_loss: 0.2012 - val_out1_loss: 0.2242 - val_out2_loss: 0.1474\n",
      "Epoch 59/120\n",
      "53/53 - 6s - loss: 0.1584 - out1_loss: 0.1736 - out2_loss: 0.1229 - val_loss: 0.2004 - val_out1_loss: 0.2242 - val_out2_loss: 0.1449\n",
      "Epoch 60/120\n",
      "53/53 - 6s - loss: 0.1601 - out1_loss: 0.1752 - out2_loss: 0.1246 - val_loss: 0.2004 - val_out1_loss: 0.2229 - val_out2_loss: 0.1479\n",
      "Epoch 61/120\n",
      "53/53 - 6s - loss: 0.1565 - out1_loss: 0.1714 - out2_loss: 0.1219 - val_loss: 0.1998 - val_out1_loss: 0.2226 - val_out2_loss: 0.1467\n",
      "Epoch 62/120\n",
      "53/53 - 6s - loss: 0.1554 - out1_loss: 0.1701 - out2_loss: 0.1209 - val_loss: 0.1999 - val_out1_loss: 0.2226 - val_out2_loss: 0.1472\n",
      "Epoch 63/120\n",
      "53/53 - 6s - loss: 0.1563 - out1_loss: 0.1708 - out2_loss: 0.1225 - val_loss: 0.1989 - val_out1_loss: 0.2220 - val_out2_loss: 0.1451\n",
      "Epoch 64/120\n",
      "53/53 - 6s - loss: 0.1533 - out1_loss: 0.1677 - out2_loss: 0.1197 - val_loss: 0.2030 - val_out1_loss: 0.2268 - val_out2_loss: 0.1475\n",
      "Epoch 65/120\n",
      "53/53 - 6s - loss: 0.1565 - out1_loss: 0.1708 - out2_loss: 0.1232 - val_loss: 0.2021 - val_out1_loss: 0.2252 - val_out2_loss: 0.1484\n",
      "Epoch 66/120\n",
      "53/53 - 6s - loss: 0.1515 - out1_loss: 0.1656 - out2_loss: 0.1186 - val_loss: 0.2023 - val_out1_loss: 0.2245 - val_out2_loss: 0.1505\n",
      "Epoch 67/120\n",
      "53/53 - 6s - loss: 0.1512 - out1_loss: 0.1649 - out2_loss: 0.1193 - val_loss: 0.2007 - val_out1_loss: 0.2239 - val_out2_loss: 0.1467\n",
      "Epoch 68/120\n",
      "53/53 - 6s - loss: 0.1500 - out1_loss: 0.1638 - out2_loss: 0.1178 - val_loss: 0.2000 - val_out1_loss: 0.2232 - val_out2_loss: 0.1458\n",
      "Epoch 69/120\n",
      "53/53 - 6s - loss: 0.1499 - out1_loss: 0.1638 - out2_loss: 0.1173 - val_loss: 0.2052 - val_out1_loss: 0.2302 - val_out2_loss: 0.1470\n",
      "Epoch 70/120\n",
      "53/53 - 6s - loss: 0.1482 - out1_loss: 0.1617 - out2_loss: 0.1166 - val_loss: 0.1997 - val_out1_loss: 0.2224 - val_out2_loss: 0.1468\n",
      "Epoch 71/120\n",
      "53/53 - 6s - loss: 0.1482 - out1_loss: 0.1616 - out2_loss: 0.1167 - val_loss: 0.2021 - val_out1_loss: 0.2253 - val_out2_loss: 0.1478\n",
      "Epoch 72/120\n",
      "53/53 - 6s - loss: 0.1472 - out1_loss: 0.1608 - out2_loss: 0.1157 - val_loss: 0.2011 - val_out1_loss: 0.2242 - val_out2_loss: 0.1472\n",
      "Epoch 73/120\n",
      "53/53 - 6s - loss: 0.1466 - out1_loss: 0.1597 - out2_loss: 0.1160 - val_loss: 0.1993 - val_out1_loss: 0.2221 - val_out2_loss: 0.1460\n",
      "Epoch 74/120\n",
      "53/53 - 6s - loss: 0.1396 - out1_loss: 0.1522 - out2_loss: 0.1103 - val_loss: 0.1958 - val_out1_loss: 0.2187 - val_out2_loss: 0.1422\n",
      "Epoch 75/120\n",
      "53/53 - 6s - loss: 0.1370 - out1_loss: 0.1492 - out2_loss: 0.1085 - val_loss: 0.1954 - val_out1_loss: 0.2183 - val_out2_loss: 0.1420\n",
      "Epoch 76/120\n",
      "53/53 - 6s - loss: 0.1362 - out1_loss: 0.1483 - out2_loss: 0.1079 - val_loss: 0.1952 - val_out1_loss: 0.2181 - val_out2_loss: 0.1419\n",
      "Epoch 77/120\n",
      "53/53 - 6s - loss: 0.1352 - out1_loss: 0.1472 - out2_loss: 0.1073 - val_loss: 0.1951 - val_out1_loss: 0.2180 - val_out2_loss: 0.1418\n",
      "Epoch 78/120\n",
      "53/53 - 6s - loss: 0.1347 - out1_loss: 0.1466 - out2_loss: 0.1070 - val_loss: 0.1951 - val_out1_loss: 0.2179 - val_out2_loss: 0.1418\n",
      "Epoch 79/120\n",
      "53/53 - 6s - loss: 0.1342 - out1_loss: 0.1460 - out2_loss: 0.1067 - val_loss: 0.1951 - val_out1_loss: 0.2179 - val_out2_loss: 0.1417\n",
      "Epoch 80/120\n",
      "53/53 - 6s - loss: 0.1339 - out1_loss: 0.1456 - out2_loss: 0.1065 - val_loss: 0.1950 - val_out1_loss: 0.2179 - val_out2_loss: 0.1417\n",
      "Epoch 81/120\n",
      "53/53 - 6s - loss: 0.1336 - out1_loss: 0.1453 - out2_loss: 0.1061 - val_loss: 0.1951 - val_out1_loss: 0.2179 - val_out2_loss: 0.1418\n",
      "Epoch 82/120\n",
      "53/53 - 6s - loss: 0.1331 - out1_loss: 0.1447 - out2_loss: 0.1059 - val_loss: 0.1949 - val_out1_loss: 0.2177 - val_out2_loss: 0.1417\n",
      "Epoch 83/120\n",
      "53/53 - 6s - loss: 0.1329 - out1_loss: 0.1445 - out2_loss: 0.1058 - val_loss: 0.1948 - val_out1_loss: 0.2176 - val_out2_loss: 0.1416\n",
      "Epoch 84/120\n",
      "53/53 - 6s - loss: 0.1328 - out1_loss: 0.1444 - out2_loss: 0.1057 - val_loss: 0.1948 - val_out1_loss: 0.2176 - val_out2_loss: 0.1415\n",
      "Epoch 85/120\n",
      "53/53 - 6s - loss: 0.1324 - out1_loss: 0.1440 - out2_loss: 0.1055 - val_loss: 0.1947 - val_out1_loss: 0.2175 - val_out2_loss: 0.1414\n",
      "Epoch 86/120\n",
      "53/53 - 6s - loss: 0.1322 - out1_loss: 0.1437 - out2_loss: 0.1054 - val_loss: 0.1948 - val_out1_loss: 0.2177 - val_out2_loss: 0.1416\n",
      "Epoch 87/120\n",
      "53/53 - 6s - loss: 0.1320 - out1_loss: 0.1435 - out2_loss: 0.1052 - val_loss: 0.1948 - val_out1_loss: 0.2177 - val_out2_loss: 0.1416\n",
      "Epoch 88/120\n",
      "53/53 - 6s - loss: 0.1319 - out1_loss: 0.1434 - out2_loss: 0.1051 - val_loss: 0.1947 - val_out1_loss: 0.2175 - val_out2_loss: 0.1414\n",
      "Epoch 89/120\n",
      "53/53 - 6s - loss: 0.1316 - out1_loss: 0.1430 - out2_loss: 0.1049 - val_loss: 0.1948 - val_out1_loss: 0.2176 - val_out2_loss: 0.1415\n",
      "Epoch 90/120\n",
      "53/53 - 7s - loss: 0.1314 - out1_loss: 0.1428 - out2_loss: 0.1048 - val_loss: 0.1946 - val_out1_loss: 0.2174 - val_out2_loss: 0.1415\n",
      "Epoch 91/120\n",
      "53/53 - 6s - loss: 0.1313 - out1_loss: 0.1427 - out2_loss: 0.1047 - val_loss: 0.1948 - val_out1_loss: 0.2177 - val_out2_loss: 0.1415\n",
      "Epoch 92/120\n",
      "53/53 - 6s - loss: 0.1311 - out1_loss: 0.1425 - out2_loss: 0.1046 - val_loss: 0.1946 - val_out1_loss: 0.2175 - val_out2_loss: 0.1414\n",
      "Epoch 93/120\n",
      "53/53 - 6s - loss: 0.1308 - out1_loss: 0.1421 - out2_loss: 0.1045 - val_loss: 0.1948 - val_out1_loss: 0.2177 - val_out2_loss: 0.1415\n",
      "Epoch 94/120\n",
      "53/53 - 6s - loss: 0.1307 - out1_loss: 0.1421 - out2_loss: 0.1043 - val_loss: 0.1947 - val_out1_loss: 0.2175 - val_out2_loss: 0.1414\n",
      "Epoch 95/120\n",
      "53/53 - 6s - loss: 0.1306 - out1_loss: 0.1419 - out2_loss: 0.1043 - val_loss: 0.1947 - val_out1_loss: 0.2175 - val_out2_loss: 0.1415\n",
      "Epoch 96/120\n",
      "53/53 - 6s - loss: 0.1300 - out1_loss: 0.1412 - out2_loss: 0.1038 - val_loss: 0.1946 - val_out1_loss: 0.2174 - val_out2_loss: 0.1413\n",
      "Epoch 97/120\n",
      "53/53 - 6s - loss: 0.1298 - out1_loss: 0.1409 - out2_loss: 0.1038 - val_loss: 0.1946 - val_out1_loss: 0.2174 - val_out2_loss: 0.1413\n",
      "Epoch 98/120\n",
      "53/53 - 6s - loss: 0.1296 - out1_loss: 0.1407 - out2_loss: 0.1036 - val_loss: 0.1946 - val_out1_loss: 0.2174 - val_out2_loss: 0.1413\n",
      "Epoch 99/120\n",
      "53/53 - 6s - loss: 0.1297 - out1_loss: 0.1408 - out2_loss: 0.1037 - val_loss: 0.1945 - val_out1_loss: 0.2173 - val_out2_loss: 0.1413\n",
      "Epoch 100/120\n",
      "53/53 - 6s - loss: 0.1297 - out1_loss: 0.1409 - out2_loss: 0.1037 - val_loss: 0.1945 - val_out1_loss: 0.2174 - val_out2_loss: 0.1413\n",
      "Epoch 101/120\n",
      "53/53 - 6s - loss: 0.1297 - out1_loss: 0.1408 - out2_loss: 0.1036 - val_loss: 0.1945 - val_out1_loss: 0.2174 - val_out2_loss: 0.1412\n",
      "Epoch 102/120\n",
      "53/53 - 6s - loss: 0.1295 - out1_loss: 0.1406 - out2_loss: 0.1035 - val_loss: 0.1945 - val_out1_loss: 0.2173 - val_out2_loss: 0.1413\n",
      "Epoch 103/120\n",
      "53/53 - 6s - loss: 0.1294 - out1_loss: 0.1405 - out2_loss: 0.1035 - val_loss: 0.1946 - val_out1_loss: 0.2174 - val_out2_loss: 0.1413\n",
      "Epoch 104/120\n",
      "53/53 - 6s - loss: 0.1294 - out1_loss: 0.1405 - out2_loss: 0.1035 - val_loss: 0.1945 - val_out1_loss: 0.2174 - val_out2_loss: 0.1412\n",
      "Epoch 105/120\n",
      "53/53 - 6s - loss: 0.1295 - out1_loss: 0.1406 - out2_loss: 0.1035 - val_loss: 0.1944 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 106/120\n",
      "53/53 - 6s - loss: 0.1294 - out1_loss: 0.1405 - out2_loss: 0.1036 - val_loss: 0.1944 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 107/120\n",
      "53/53 - 6s - loss: 0.1294 - out1_loss: 0.1405 - out2_loss: 0.1035 - val_loss: 0.1945 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 108/120\n",
      "53/53 - 5s - loss: 0.1293 - out1_loss: 0.1404 - out2_loss: 0.1034 - val_loss: 0.1945 - val_out1_loss: 0.2173 - val_out2_loss: 0.1413\n",
      "Epoch 109/120\n",
      "53/53 - 6s - loss: 0.1293 - out1_loss: 0.1404 - out2_loss: 0.1034 - val_loss: 0.1945 - val_out1_loss: 0.2174 - val_out2_loss: 0.1412\n",
      "Epoch 110/120\n",
      "53/53 - 6s - loss: 0.1293 - out1_loss: 0.1404 - out2_loss: 0.1034 - val_loss: 0.1945 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 111/120\n",
      "53/53 - 5s - loss: 0.1294 - out1_loss: 0.1405 - out2_loss: 0.1034 - val_loss: 0.1944 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 112/120\n",
      "53/53 - 5s - loss: 0.1292 - out1_loss: 0.1403 - out2_loss: 0.1033 - val_loss: 0.1945 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 113/120\n",
      "53/53 - 5s - loss: 0.1292 - out1_loss: 0.1403 - out2_loss: 0.1034 - val_loss: 0.1945 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 114/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 6s - loss: 0.1291 - out1_loss: 0.1401 - out2_loss: 0.1033 - val_loss: 0.1944 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 115/120\n",
      "53/53 - 5s - loss: 0.1292 - out1_loss: 0.1403 - out2_loss: 0.1034 - val_loss: 0.1944 - val_out1_loss: 0.2172 - val_out2_loss: 0.1412\n",
      "Epoch 116/120\n",
      "53/53 - 5s - loss: 0.1291 - out1_loss: 0.1402 - out2_loss: 0.1033 - val_loss: 0.1944 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 117/120\n",
      "53/53 - 5s - loss: 0.1291 - out1_loss: 0.1401 - out2_loss: 0.1033 - val_loss: 0.1944 - val_out1_loss: 0.2172 - val_out2_loss: 0.1412\n",
      "Epoch 118/120\n",
      "53/53 - 6s - loss: 0.1291 - out1_loss: 0.1402 - out2_loss: 0.1032 - val_loss: 0.1944 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 119/120\n",
      "53/53 - 5s - loss: 0.1289 - out1_loss: 0.1399 - out2_loss: 0.1031 - val_loss: 0.1944 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "Epoch 120/120\n",
      "53/53 - 5s - loss: 0.1289 - out1_loss: 0.1400 - out2_loss: 0.1032 - val_loss: 0.1945 - val_out1_loss: 0.2173 - val_out2_loss: 0.1412\n",
      "#################### 0.3510446823845105\n",
      "(None, 107, 1024)\n",
      "(None, 130, 1024)\n",
      "(629, 107, 5) (3005, 130, 5)\n",
      "(None, 107, 1024)\n",
      "Model: \"functional_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 107, 7)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_96 (T [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_97 (T [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_98 (T [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_99 (T [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_100 ( [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_101 ( [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_102 ( [(None, 107)]        0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_84 (Embedding)        (None, 107, 128)     512         tf_op_layer_strided_slice_96[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_85 (Embedding)        (None, 107, 128)     384         tf_op_layer_strided_slice_97[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_86 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_98[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_87 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_99[0][0\n",
      "__________________________________________________________________________________________________\n",
      "embedding_88 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_100[0][\n",
      "__________________________________________________________________________________________________\n",
      "embedding_89 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_101[0][\n",
      "__________________________________________________________________________________________________\n",
      "embedding_90 (Embedding)        (None, 107, 128)     896         tf_op_layer_strided_slice_102[0][\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_96 (SpatialDr (None, 107, 128)     0           embedding_84[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_97 (SpatialDr (None, 107, 128)     0           embedding_85[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_98 (SpatialDr (None, 107, 128)     0           embedding_86[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_99 (SpatialDr (None, 107, 128)     0           embedding_87[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_100 (SpatialD (None, 107, 128)     0           embedding_88[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_101 (SpatialD (None, 107, 128)     0           embedding_89[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_102 (SpatialD (None, 107, 128)     0           embedding_90[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_24 (TensorFl [(None, 107, 896)]   0           spatial_dropout1d_96[0][0]       \n",
      "                                                                 spatial_dropout1d_97[0][0]       \n",
      "                                                                 spatial_dropout1d_98[0][0]       \n",
      "                                                                 spatial_dropout1d_99[0][0]       \n",
      "                                                                 spatial_dropout1d_100[0][0]      \n",
      "                                                                 spatial_dropout1d_101[0][0]      \n",
      "                                                                 spatial_dropout1d_102[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 107, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_103 (SpatialD (None, 107, 896)     0           tf_op_layer_concat_24[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 107, 128)     256         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_25 (TensorFl [(None, 107, 1024)]  0           spatial_dropout1d_103[0][0]      \n",
      "                                                                 dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "transformer_block_12 (Transform (None, 107, 1024)    6301696     tf_op_layer_concat_25[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 107, 768)     3248640     transformer_block_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 107, 768)     2658816     bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_38 (Bidirectional (None, 107, 768)     2658816     bidirectional_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_103 ( [(None, 68, 768)]    0           bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "out1 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_103[0][\n",
      "__________________________________________________________________________________________________\n",
      "out2 (Dense)                    (None, 68, 5)        3845        tf_op_layer_strided_slice_103[0][\n",
      "==================================================================================================\n",
      "Total params: 14,881,290\n",
      "Trainable params: 14,881,290\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 7s - loss: 0.7274 - out1_loss: 0.7748 - out2_loss: 0.6170 - val_loss: 0.3914 - val_out1_loss: 0.4318 - val_out2_loss: 0.2972\n",
      "Epoch 2/120\n",
      "53/53 - 5s - loss: 0.3865 - out1_loss: 0.4258 - out2_loss: 0.2948 - val_loss: 0.3847 - val_out1_loss: 0.4253 - val_out2_loss: 0.2898\n",
      "Epoch 3/120\n",
      "53/53 - 5s - loss: 0.3812 - out1_loss: 0.4194 - out2_loss: 0.2919 - val_loss: 0.3775 - val_out1_loss: 0.4164 - val_out2_loss: 0.2865\n",
      "Epoch 4/120\n",
      "53/53 - 5s - loss: 0.3790 - out1_loss: 0.4171 - out2_loss: 0.2901 - val_loss: 0.3877 - val_out1_loss: 0.4303 - val_out2_loss: 0.2885\n",
      "Epoch 5/120\n",
      "53/53 - 5s - loss: 0.3776 - out1_loss: 0.4155 - out2_loss: 0.2891 - val_loss: 0.3776 - val_out1_loss: 0.4174 - val_out2_loss: 0.2848\n",
      "Epoch 6/120\n",
      "53/53 - 5s - loss: 0.3775 - out1_loss: 0.4163 - out2_loss: 0.2870 - val_loss: 0.3767 - val_out1_loss: 0.4161 - val_out2_loss: 0.2847\n",
      "Epoch 7/120\n",
      "53/53 - 5s - loss: 0.3780 - out1_loss: 0.4173 - out2_loss: 0.2864 - val_loss: 0.3764 - val_out1_loss: 0.4163 - val_out2_loss: 0.2833\n",
      "Epoch 8/120\n",
      "53/53 - 5s - loss: 0.3762 - out1_loss: 0.4150 - out2_loss: 0.2856 - val_loss: 0.3769 - val_out1_loss: 0.4166 - val_out2_loss: 0.2844\n",
      "Epoch 9/120\n",
      "53/53 - 5s - loss: 0.3750 - out1_loss: 0.4139 - out2_loss: 0.2840 - val_loss: 0.3946 - val_out1_loss: 0.4386 - val_out2_loss: 0.2920\n",
      "Epoch 10/120\n",
      "53/53 - 5s - loss: 0.3534 - out1_loss: 0.3924 - out2_loss: 0.2624 - val_loss: 0.3427 - val_out1_loss: 0.3817 - val_out2_loss: 0.2518\n",
      "Epoch 11/120\n",
      "53/53 - 5s - loss: 0.3363 - out1_loss: 0.3739 - out2_loss: 0.2486 - val_loss: 0.3285 - val_out1_loss: 0.3653 - val_out2_loss: 0.2426\n",
      "Epoch 12/120\n",
      "53/53 - 5s - loss: 0.3208 - out1_loss: 0.3568 - out2_loss: 0.2368 - val_loss: 0.3182 - val_out1_loss: 0.3564 - val_out2_loss: 0.2290\n",
      "Epoch 13/120\n",
      "53/53 - 5s - loss: 0.3121 - out1_loss: 0.3475 - out2_loss: 0.2293 - val_loss: 0.3046 - val_out1_loss: 0.3415 - val_out2_loss: 0.2185\n",
      "Epoch 14/120\n",
      "53/53 - 5s - loss: 0.2996 - out1_loss: 0.3341 - out2_loss: 0.2191 - val_loss: 0.2992 - val_out1_loss: 0.3336 - val_out2_loss: 0.2191\n",
      "Epoch 15/120\n",
      "53/53 - 5s - loss: 0.2886 - out1_loss: 0.3216 - out2_loss: 0.2114 - val_loss: 0.3002 - val_out1_loss: 0.3369 - val_out2_loss: 0.2148\n",
      "Epoch 16/120\n",
      "53/53 - 5s - loss: 0.2797 - out1_loss: 0.3114 - out2_loss: 0.2057 - val_loss: 0.2754 - val_out1_loss: 0.3066 - val_out2_loss: 0.2025\n",
      "Epoch 17/120\n",
      "53/53 - 5s - loss: 0.2715 - out1_loss: 0.3017 - out2_loss: 0.2009 - val_loss: 0.2715 - val_out1_loss: 0.3034 - val_out2_loss: 0.1971\n",
      "Epoch 18/120\n",
      "53/53 - 5s - loss: 0.2641 - out1_loss: 0.2940 - out2_loss: 0.1943 - val_loss: 0.2723 - val_out1_loss: 0.3053 - val_out2_loss: 0.1951\n",
      "Epoch 19/120\n",
      "53/53 - 5s - loss: 0.2605 - out1_loss: 0.2898 - out2_loss: 0.1921 - val_loss: 0.2647 - val_out1_loss: 0.2938 - val_out2_loss: 0.1967\n",
      "Epoch 20/120\n",
      "53/53 - 5s - loss: 0.2553 - out1_loss: 0.2840 - out2_loss: 0.1882 - val_loss: 0.2548 - val_out1_loss: 0.2853 - val_out2_loss: 0.1835\n",
      "Epoch 21/120\n",
      "53/53 - 5s - loss: 0.2478 - out1_loss: 0.2760 - out2_loss: 0.1822 - val_loss: 0.2493 - val_out1_loss: 0.2760 - val_out2_loss: 0.1869\n",
      "Epoch 22/120\n",
      "53/53 - 5s - loss: 0.2441 - out1_loss: 0.2715 - out2_loss: 0.1801 - val_loss: 0.2425 - val_out1_loss: 0.2703 - val_out2_loss: 0.1777\n",
      "Epoch 23/120\n",
      "53/53 - 5s - loss: 0.2377 - out1_loss: 0.2642 - out2_loss: 0.1759 - val_loss: 0.2371 - val_out1_loss: 0.2636 - val_out2_loss: 0.1753\n",
      "Epoch 24/120\n",
      "53/53 - 5s - loss: 0.2322 - out1_loss: 0.2583 - out2_loss: 0.1714 - val_loss: 0.2331 - val_out1_loss: 0.2604 - val_out2_loss: 0.1694\n",
      "Epoch 25/120\n",
      "53/53 - 5s - loss: 0.2283 - out1_loss: 0.2537 - out2_loss: 0.1692 - val_loss: 0.2295 - val_out1_loss: 0.2555 - val_out2_loss: 0.1688\n",
      "Epoch 26/120\n",
      "53/53 - 5s - loss: 0.2221 - out1_loss: 0.2464 - out2_loss: 0.1656 - val_loss: 0.2230 - val_out1_loss: 0.2484 - val_out2_loss: 0.1636\n",
      "Epoch 27/120\n",
      "53/53 - 5s - loss: 0.2187 - out1_loss: 0.2418 - out2_loss: 0.1651 - val_loss: 0.2222 - val_out1_loss: 0.2469 - val_out2_loss: 0.1643\n",
      "Epoch 28/120\n",
      "53/53 - 5s - loss: 0.2128 - out1_loss: 0.2353 - out2_loss: 0.1602 - val_loss: 0.2207 - val_out1_loss: 0.2458 - val_out2_loss: 0.1621\n",
      "Epoch 29/120\n",
      "53/53 - 5s - loss: 0.2095 - out1_loss: 0.2320 - out2_loss: 0.1571 - val_loss: 0.2151 - val_out1_loss: 0.2396 - val_out2_loss: 0.1579\n",
      "Epoch 30/120\n",
      "53/53 - 5s - loss: 0.2057 - out1_loss: 0.2278 - out2_loss: 0.1541 - val_loss: 0.2132 - val_out1_loss: 0.2378 - val_out2_loss: 0.1558\n",
      "Epoch 31/120\n",
      "53/53 - 5s - loss: 0.2050 - out1_loss: 0.2270 - out2_loss: 0.1536 - val_loss: 0.2128 - val_out1_loss: 0.2362 - val_out2_loss: 0.1584\n",
      "Epoch 32/120\n",
      "53/53 - 5s - loss: 0.2017 - out1_loss: 0.2228 - out2_loss: 0.1524 - val_loss: 0.2104 - val_out1_loss: 0.2349 - val_out2_loss: 0.1532\n",
      "Epoch 33/120\n",
      "53/53 - 5s - loss: 0.1992 - out1_loss: 0.2201 - out2_loss: 0.1502 - val_loss: 0.2102 - val_out1_loss: 0.2342 - val_out2_loss: 0.1542\n",
      "Epoch 34/120\n",
      "53/53 - 5s - loss: 0.1966 - out1_loss: 0.2172 - out2_loss: 0.1484 - val_loss: 0.2095 - val_out1_loss: 0.2338 - val_out2_loss: 0.1528\n",
      "Epoch 35/120\n",
      "53/53 - 5s - loss: 0.1929 - out1_loss: 0.2133 - out2_loss: 0.1454 - val_loss: 0.2141 - val_out1_loss: 0.2370 - val_out2_loss: 0.1606\n",
      "Epoch 36/120\n",
      "53/53 - 5s - loss: 0.1936 - out1_loss: 0.2136 - out2_loss: 0.1469 - val_loss: 0.2097 - val_out1_loss: 0.2342 - val_out2_loss: 0.1526\n",
      "Epoch 37/120\n",
      "53/53 - 5s - loss: 0.1886 - out1_loss: 0.2084 - out2_loss: 0.1421 - val_loss: 0.2069 - val_out1_loss: 0.2310 - val_out2_loss: 0.1507\n",
      "Epoch 38/120\n",
      "53/53 - 5s - loss: 0.1854 - out1_loss: 0.2050 - out2_loss: 0.1398 - val_loss: 0.2098 - val_out1_loss: 0.2347 - val_out2_loss: 0.1518\n",
      "Epoch 39/120\n",
      "53/53 - 5s - loss: 0.1839 - out1_loss: 0.2029 - out2_loss: 0.1396 - val_loss: 0.2143 - val_out1_loss: 0.2371 - val_out2_loss: 0.1612\n",
      "Epoch 40/120\n",
      "53/53 - 5s - loss: 0.1872 - out1_loss: 0.2064 - out2_loss: 0.1425 - val_loss: 0.2078 - val_out1_loss: 0.2326 - val_out2_loss: 0.1498\n",
      "Epoch 41/120\n",
      "53/53 - 5s - loss: 0.1811 - out1_loss: 0.1994 - out2_loss: 0.1384 - val_loss: 0.2055 - val_out1_loss: 0.2295 - val_out2_loss: 0.1493\n",
      "Epoch 42/120\n",
      "53/53 - 5s - loss: 0.1794 - out1_loss: 0.1978 - out2_loss: 0.1363 - val_loss: 0.2038 - val_out1_loss: 0.2270 - val_out2_loss: 0.1498\n",
      "Epoch 43/120\n",
      "53/53 - 5s - loss: 0.1759 - out1_loss: 0.1939 - out2_loss: 0.1339 - val_loss: 0.2023 - val_out1_loss: 0.2261 - val_out2_loss: 0.1468\n",
      "Epoch 44/120\n",
      "53/53 - 5s - loss: 0.1744 - out1_loss: 0.1921 - out2_loss: 0.1333 - val_loss: 0.2050 - val_out1_loss: 0.2287 - val_out2_loss: 0.1497\n",
      "Epoch 45/120\n",
      "53/53 - 5s - loss: 0.1717 - out1_loss: 0.1891 - out2_loss: 0.1309 - val_loss: 0.2057 - val_out1_loss: 0.2273 - val_out2_loss: 0.1552\n",
      "Epoch 46/120\n",
      "53/53 - 5s - loss: 0.1722 - out1_loss: 0.1897 - out2_loss: 0.1316 - val_loss: 0.2056 - val_out1_loss: 0.2300 - val_out2_loss: 0.1488\n",
      "Epoch 47/120\n",
      "53/53 - 5s - loss: 0.1709 - out1_loss: 0.1877 - out2_loss: 0.1316 - val_loss: 0.2027 - val_out1_loss: 0.2253 - val_out2_loss: 0.1500\n",
      "Epoch 48/120\n",
      "53/53 - 5s - loss: 0.1694 - out1_loss: 0.1859 - out2_loss: 0.1307 - val_loss: 0.2059 - val_out1_loss: 0.2276 - val_out2_loss: 0.1552\n",
      "Epoch 49/120\n",
      "53/53 - 5s - loss: 0.1674 - out1_loss: 0.1837 - out2_loss: 0.1294 - val_loss: 0.2046 - val_out1_loss: 0.2294 - val_out2_loss: 0.1469\n",
      "Epoch 50/120\n",
      "53/53 - 5s - loss: 0.1660 - out1_loss: 0.1823 - out2_loss: 0.1279 - val_loss: 0.2048 - val_out1_loss: 0.2278 - val_out2_loss: 0.1512\n",
      "Epoch 51/120\n",
      "53/53 - 5s - loss: 0.1642 - out1_loss: 0.1804 - out2_loss: 0.1263 - val_loss: 0.2015 - val_out1_loss: 0.2245 - val_out2_loss: 0.1476\n",
      "Epoch 52/120\n",
      "53/53 - 5s - loss: 0.1630 - out1_loss: 0.1791 - out2_loss: 0.1256 - val_loss: 0.2034 - val_out1_loss: 0.2271 - val_out2_loss: 0.1480\n",
      "Epoch 53/120\n",
      "53/53 - 5s - loss: 0.1618 - out1_loss: 0.1776 - out2_loss: 0.1248 - val_loss: 0.2015 - val_out1_loss: 0.2239 - val_out2_loss: 0.1492\n",
      "Epoch 54/120\n",
      "53/53 - 5s - loss: 0.1598 - out1_loss: 0.1753 - out2_loss: 0.1238 - val_loss: 0.2015 - val_out1_loss: 0.2242 - val_out2_loss: 0.1487\n",
      "Epoch 55/120\n",
      "53/53 - 5s - loss: 0.1587 - out1_loss: 0.1740 - out2_loss: 0.1229 - val_loss: 0.2029 - val_out1_loss: 0.2262 - val_out2_loss: 0.1486\n",
      "Epoch 56/120\n",
      "53/53 - 5s - loss: 0.1585 - out1_loss: 0.1738 - out2_loss: 0.1229 - val_loss: 0.2004 - val_out1_loss: 0.2241 - val_out2_loss: 0.1450\n",
      "Epoch 57/120\n",
      "53/53 - 5s - loss: 0.1572 - out1_loss: 0.1724 - out2_loss: 0.1218 - val_loss: 0.2029 - val_out1_loss: 0.2267 - val_out2_loss: 0.1475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120\n",
      "53/53 - 5s - loss: 0.1571 - out1_loss: 0.1719 - out2_loss: 0.1226 - val_loss: 0.2022 - val_out1_loss: 0.2254 - val_out2_loss: 0.1481\n",
      "Epoch 59/120\n",
      "53/53 - 5s - loss: 0.1558 - out1_loss: 0.1706 - out2_loss: 0.1213 - val_loss: 0.2041 - val_out1_loss: 0.2260 - val_out2_loss: 0.1531\n",
      "Epoch 60/120\n",
      "53/53 - 5s - loss: 0.1549 - out1_loss: 0.1691 - out2_loss: 0.1218 - val_loss: 0.1992 - val_out1_loss: 0.2215 - val_out2_loss: 0.1470\n",
      "Epoch 61/120\n",
      "53/53 - 5s - loss: 0.1520 - out1_loss: 0.1662 - out2_loss: 0.1187 - val_loss: 0.1994 - val_out1_loss: 0.2218 - val_out2_loss: 0.1471\n",
      "Epoch 62/120\n",
      "53/53 - 5s - loss: 0.1517 - out1_loss: 0.1658 - out2_loss: 0.1186 - val_loss: 0.2003 - val_out1_loss: 0.2233 - val_out2_loss: 0.1464\n",
      "Epoch 63/120\n",
      "53/53 - 5s - loss: 0.1503 - out1_loss: 0.1644 - out2_loss: 0.1174 - val_loss: 0.1993 - val_out1_loss: 0.2227 - val_out2_loss: 0.1446\n",
      "Epoch 64/120\n",
      "53/53 - 5s - loss: 0.1508 - out1_loss: 0.1648 - out2_loss: 0.1181 - val_loss: 0.1991 - val_out1_loss: 0.2213 - val_out2_loss: 0.1475\n",
      "Epoch 65/120\n",
      "53/53 - 5s - loss: 0.1495 - out1_loss: 0.1629 - out2_loss: 0.1183 - val_loss: 0.1994 - val_out1_loss: 0.2217 - val_out2_loss: 0.1475\n",
      "Epoch 66/120\n",
      "53/53 - 5s - loss: 0.1483 - out1_loss: 0.1618 - out2_loss: 0.1169 - val_loss: 0.1982 - val_out1_loss: 0.2206 - val_out2_loss: 0.1459\n",
      "Epoch 67/120\n",
      "53/53 - 5s - loss: 0.1500 - out1_loss: 0.1636 - out2_loss: 0.1181 - val_loss: 0.2034 - val_out1_loss: 0.2277 - val_out2_loss: 0.1466\n",
      "Epoch 68/120\n",
      "53/53 - 5s - loss: 0.1481 - out1_loss: 0.1618 - out2_loss: 0.1160 - val_loss: 0.1985 - val_out1_loss: 0.2213 - val_out2_loss: 0.1453\n",
      "Epoch 69/120\n",
      "53/53 - 5s - loss: 0.1466 - out1_loss: 0.1600 - out2_loss: 0.1153 - val_loss: 0.1982 - val_out1_loss: 0.2218 - val_out2_loss: 0.1432\n",
      "Epoch 70/120\n",
      "53/53 - 5s - loss: 0.1450 - out1_loss: 0.1584 - out2_loss: 0.1138 - val_loss: 0.1993 - val_out1_loss: 0.2223 - val_out2_loss: 0.1457\n",
      "Epoch 71/120\n",
      "53/53 - 5s - loss: 0.1458 - out1_loss: 0.1594 - out2_loss: 0.1141 - val_loss: 0.1983 - val_out1_loss: 0.2215 - val_out2_loss: 0.1443\n",
      "Epoch 72/120\n",
      "53/53 - 5s - loss: 0.1440 - out1_loss: 0.1569 - out2_loss: 0.1141 - val_loss: 0.2006 - val_out1_loss: 0.2236 - val_out2_loss: 0.1467\n",
      "Epoch 73/120\n",
      "53/53 - 5s - loss: 0.1433 - out1_loss: 0.1561 - out2_loss: 0.1134 - val_loss: 0.1997 - val_out1_loss: 0.2229 - val_out2_loss: 0.1455\n",
      "Epoch 74/120\n",
      "53/53 - 5s - loss: 0.1420 - out1_loss: 0.1547 - out2_loss: 0.1123 - val_loss: 0.1968 - val_out1_loss: 0.2199 - val_out2_loss: 0.1429\n",
      "Epoch 75/120\n",
      "53/53 - 5s - loss: 0.1405 - out1_loss: 0.1531 - out2_loss: 0.1111 - val_loss: 0.1988 - val_out1_loss: 0.2214 - val_out2_loss: 0.1461\n",
      "Epoch 76/120\n",
      "53/53 - 5s - loss: 0.1413 - out1_loss: 0.1534 - out2_loss: 0.1130 - val_loss: 0.2051 - val_out1_loss: 0.2278 - val_out2_loss: 0.1519\n",
      "Epoch 77/120\n",
      "53/53 - 5s - loss: 0.1425 - out1_loss: 0.1550 - out2_loss: 0.1134 - val_loss: 0.2003 - val_out1_loss: 0.2242 - val_out2_loss: 0.1444\n",
      "Epoch 78/120\n",
      "53/53 - 5s - loss: 0.1398 - out1_loss: 0.1522 - out2_loss: 0.1110 - val_loss: 0.1993 - val_out1_loss: 0.2225 - val_out2_loss: 0.1453\n",
      "Epoch 79/120\n",
      "53/53 - 5s - loss: 0.1390 - out1_loss: 0.1510 - out2_loss: 0.1110 - val_loss: 0.1994 - val_out1_loss: 0.2229 - val_out2_loss: 0.1446\n",
      "Epoch 80/120\n",
      "53/53 - 5s - loss: 0.1383 - out1_loss: 0.1503 - out2_loss: 0.1101 - val_loss: 0.1992 - val_out1_loss: 0.2208 - val_out2_loss: 0.1486\n",
      "Epoch 81/120\n",
      "53/53 - 5s - loss: 0.1380 - out1_loss: 0.1500 - out2_loss: 0.1100 - val_loss: 0.1968 - val_out1_loss: 0.2200 - val_out2_loss: 0.1427\n",
      "Epoch 82/120\n",
      "53/53 - 5s - loss: 0.1382 - out1_loss: 0.1501 - out2_loss: 0.1103 - val_loss: 0.1992 - val_out1_loss: 0.2220 - val_out2_loss: 0.1460\n",
      "Epoch 83/120\n",
      "53/53 - 5s - loss: 0.1374 - out1_loss: 0.1492 - out2_loss: 0.1098 - val_loss: 0.1990 - val_out1_loss: 0.2218 - val_out2_loss: 0.1458\n",
      "Epoch 84/120\n",
      "53/53 - 5s - loss: 0.1356 - out1_loss: 0.1473 - out2_loss: 0.1081 - val_loss: 0.1993 - val_out1_loss: 0.2233 - val_out2_loss: 0.1434\n",
      "Epoch 85/120\n",
      "53/53 - 5s - loss: 0.1304 - out1_loss: 0.1417 - out2_loss: 0.1039 - val_loss: 0.1946 - val_out1_loss: 0.2176 - val_out2_loss: 0.1411\n",
      "Epoch 86/120\n",
      "53/53 - 5s - loss: 0.1274 - out1_loss: 0.1383 - out2_loss: 0.1020 - val_loss: 0.1943 - val_out1_loss: 0.2173 - val_out2_loss: 0.1408\n",
      "Epoch 87/120\n",
      "53/53 - 5s - loss: 0.1262 - out1_loss: 0.1369 - out2_loss: 0.1013 - val_loss: 0.1940 - val_out1_loss: 0.2169 - val_out2_loss: 0.1406\n",
      "Epoch 88/120\n",
      "53/53 - 5s - loss: 0.1255 - out1_loss: 0.1361 - out2_loss: 0.1008 - val_loss: 0.1939 - val_out1_loss: 0.2168 - val_out2_loss: 0.1405\n",
      "Epoch 89/120\n",
      "53/53 - 5s - loss: 0.1248 - out1_loss: 0.1354 - out2_loss: 0.1003 - val_loss: 0.1939 - val_out1_loss: 0.2168 - val_out2_loss: 0.1404\n",
      "Epoch 90/120\n",
      "53/53 - 5s - loss: 0.1244 - out1_loss: 0.1349 - out2_loss: 0.1001 - val_loss: 0.1940 - val_out1_loss: 0.2169 - val_out2_loss: 0.1406\n",
      "Epoch 91/120\n",
      "53/53 - 5s - loss: 0.1242 - out1_loss: 0.1346 - out2_loss: 0.0999 - val_loss: 0.1939 - val_out1_loss: 0.2169 - val_out2_loss: 0.1404\n",
      "Epoch 92/120\n",
      "53/53 - 5s - loss: 0.1237 - out1_loss: 0.1340 - out2_loss: 0.0996 - val_loss: 0.1940 - val_out1_loss: 0.2170 - val_out2_loss: 0.1405\n",
      "Epoch 93/120\n",
      "53/53 - 5s - loss: 0.1235 - out1_loss: 0.1338 - out2_loss: 0.0994 - val_loss: 0.1938 - val_out1_loss: 0.2167 - val_out2_loss: 0.1403\n",
      "Epoch 94/120\n",
      "53/53 - 5s - loss: 0.1231 - out1_loss: 0.1333 - out2_loss: 0.0992 - val_loss: 0.1937 - val_out1_loss: 0.2166 - val_out2_loss: 0.1401\n",
      "Epoch 95/120\n",
      "53/53 - 5s - loss: 0.1229 - out1_loss: 0.1331 - out2_loss: 0.0991 - val_loss: 0.1937 - val_out1_loss: 0.2166 - val_out2_loss: 0.1402\n",
      "Epoch 96/120\n",
      "53/53 - 5s - loss: 0.1227 - out1_loss: 0.1329 - out2_loss: 0.0989 - val_loss: 0.1939 - val_out1_loss: 0.2168 - val_out2_loss: 0.1403\n",
      "Epoch 97/120\n",
      "53/53 - 5s - loss: 0.1223 - out1_loss: 0.1325 - out2_loss: 0.0987 - val_loss: 0.1938 - val_out1_loss: 0.2168 - val_out2_loss: 0.1402\n",
      "Epoch 98/120\n",
      "53/53 - 5s - loss: 0.1224 - out1_loss: 0.1326 - out2_loss: 0.0986 - val_loss: 0.1938 - val_out1_loss: 0.2168 - val_out2_loss: 0.1403\n",
      "Epoch 99/120\n",
      "53/53 - 5s - loss: 0.1222 - out1_loss: 0.1323 - out2_loss: 0.0986 - val_loss: 0.1937 - val_out1_loss: 0.2167 - val_out2_loss: 0.1402\n",
      "Epoch 100/120\n",
      "53/53 - 5s - loss: 0.1219 - out1_loss: 0.1319 - out2_loss: 0.0984 - val_loss: 0.1936 - val_out1_loss: 0.2166 - val_out2_loss: 0.1401\n",
      "Epoch 101/120\n",
      "53/53 - 5s - loss: 0.1215 - out1_loss: 0.1315 - out2_loss: 0.0982 - val_loss: 0.1938 - val_out1_loss: 0.2167 - val_out2_loss: 0.1404\n",
      "Epoch 102/120\n",
      "53/53 - 5s - loss: 0.1216 - out1_loss: 0.1317 - out2_loss: 0.0981 - val_loss: 0.1936 - val_out1_loss: 0.2166 - val_out2_loss: 0.1401\n",
      "Epoch 103/120\n",
      "53/53 - 5s - loss: 0.1213 - out1_loss: 0.1313 - out2_loss: 0.0980 - val_loss: 0.1937 - val_out1_loss: 0.2167 - val_out2_loss: 0.1401\n",
      "Epoch 104/120\n",
      "53/53 - 5s - loss: 0.1212 - out1_loss: 0.1311 - out2_loss: 0.0979 - val_loss: 0.1937 - val_out1_loss: 0.2167 - val_out2_loss: 0.1401\n",
      "Epoch 105/120\n",
      "53/53 - 6s - loss: 0.1210 - out1_loss: 0.1310 - out2_loss: 0.0978 - val_loss: 0.1938 - val_out1_loss: 0.2168 - val_out2_loss: 0.1402\n",
      "Epoch 106/120\n",
      "53/53 - 5s - loss: 0.1209 - out1_loss: 0.1309 - out2_loss: 0.0977 - val_loss: 0.1936 - val_out1_loss: 0.2165 - val_out2_loss: 0.1401\n",
      "Epoch 107/120\n",
      "53/53 - 5s - loss: 0.1207 - out1_loss: 0.1305 - out2_loss: 0.0976 - val_loss: 0.1936 - val_out1_loss: 0.2166 - val_out2_loss: 0.1400\n",
      "Epoch 108/120\n",
      "53/53 - 5s - loss: 0.1205 - out1_loss: 0.1304 - out2_loss: 0.0975 - val_loss: 0.1935 - val_out1_loss: 0.2164 - val_out2_loss: 0.1399\n",
      "Epoch 109/120\n",
      "53/53 - 5s - loss: 0.1203 - out1_loss: 0.1302 - out2_loss: 0.0973 - val_loss: 0.1935 - val_out1_loss: 0.2164 - val_out2_loss: 0.1399\n",
      "Epoch 110/120\n",
      "53/53 - 5s - loss: 0.1203 - out1_loss: 0.1301 - out2_loss: 0.0973 - val_loss: 0.1935 - val_out1_loss: 0.2165 - val_out2_loss: 0.1400\n",
      "Epoch 111/120\n",
      "53/53 - 5s - loss: 0.1201 - out1_loss: 0.1299 - out2_loss: 0.0971 - val_loss: 0.1935 - val_out1_loss: 0.2165 - val_out2_loss: 0.1400\n",
      "Epoch 112/120\n",
      "53/53 - 5s - loss: 0.1200 - out1_loss: 0.1299 - out2_loss: 0.0972 - val_loss: 0.1935 - val_out1_loss: 0.2164 - val_out2_loss: 0.1400\n",
      "Epoch 113/120\n",
      "53/53 - 5s - loss: 0.1197 - out1_loss: 0.1294 - out2_loss: 0.0971 - val_loss: 0.1936 - val_out1_loss: 0.2165 - val_out2_loss: 0.1401\n",
      "Epoch 114/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 5s - loss: 0.1196 - out1_loss: 0.1294 - out2_loss: 0.0968 - val_loss: 0.1936 - val_out1_loss: 0.2165 - val_out2_loss: 0.1400\n",
      "Epoch 115/120\n",
      "53/53 - 5s - loss: 0.1196 - out1_loss: 0.1294 - out2_loss: 0.0969 - val_loss: 0.1936 - val_out1_loss: 0.2165 - val_out2_loss: 0.1401\n",
      "Epoch 116/120\n",
      "53/53 - 5s - loss: 0.1194 - out1_loss: 0.1291 - out2_loss: 0.0968 - val_loss: 0.1934 - val_out1_loss: 0.2164 - val_out2_loss: 0.1399\n",
      "Epoch 117/120\n",
      "53/53 - 5s - loss: 0.1192 - out1_loss: 0.1289 - out2_loss: 0.0965 - val_loss: 0.1934 - val_out1_loss: 0.2163 - val_out2_loss: 0.1399\n",
      "Epoch 118/120\n",
      "53/53 - 5s - loss: 0.1191 - out1_loss: 0.1287 - out2_loss: 0.0966 - val_loss: 0.1934 - val_out1_loss: 0.2163 - val_out2_loss: 0.1399\n",
      "Epoch 119/120\n",
      "53/53 - 5s - loss: 0.1184 - out1_loss: 0.1280 - out2_loss: 0.0961 - val_loss: 0.1933 - val_out1_loss: 0.2163 - val_out2_loss: 0.1398\n",
      "Epoch 120/120\n",
      "53/53 - 5s - loss: 0.1184 - out1_loss: 0.1280 - out2_loss: 0.0960 - val_loss: 0.1933 - val_out1_loss: 0.2162 - val_out2_loss: 0.1398\n",
      "#################### 0.376804921078069\n",
      "(None, 107, 1024)\n",
      "(None, 130, 1024)\n",
      "(629, 107, 5) (3005, 130, 5)\n"
     ]
    }
   ],
   "source": [
    "FOLDS = KFold(n_splits=5, random_state=815, shuffle=True)\n",
    "\n",
    "oofs_pred = np.zeros_like(train_labels)\n",
    "public_preds_array = []\n",
    "public_preds_array = []\n",
    "\n",
    "for i, (trn_idx, vld_idx) in enumerate(FOLDS.split(train_inputs)):\n",
    "    trn_inputs = train_inputs[trn_idx]\n",
    "    vld_inputs = train_inputs[vld_idx]\n",
    "    \n",
    "    trn_inputs_bpps = train_bpps[trn_idx]\n",
    "    vld_inputs_bpps = train_bpps[vld_idx]\n",
    "\n",
    "    trn_labels = train_labels[trn_idx]\n",
    "    vld_labels = train_labels[vld_idx]\n",
    "\n",
    "    model = build_model()\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "        [trn_inputs, trn_inputs_bpps], trn_labels, \n",
    "        validation_data=([vld_inputs, vld_inputs_bpps], vld_labels),\n",
    "        batch_size=32,\n",
    "        epochs=120,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "            tf.keras.callbacks.ModelCheckpoint('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_newStruc_815.h5')\n",
    "        ],\n",
    "        verbose=2,\n",
    "    )\n",
    "    model.load_weights('./tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_newStruc_815.h5')\n",
    "    outputs, outputs2 = model.predict([vld_inputs, vld_inputs_bpps])\n",
    "    oofs_pred[vld_idx] = outputs\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    errors = []\n",
    "    for idx in range(5):\n",
    "         errors.append(np.sqrt(mean_squared_error(vld_labels[:, idx], outputs[:, idx])))\n",
    "    final_error = np.mean(errors)\n",
    "    print('#'*20, final_error)\n",
    "\n",
    "    public_df = test.query(\"seq_length == 107\").copy()\n",
    "    private_df = test.query(\"seq_length == 130\").copy()\n",
    "    \n",
    "    public_df['sequence'] = public_df['sequence'].apply(lambda x: [token2int0[ele] for ele in x])\n",
    "    public_df['structure'] = public_df['structure'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    public_df['structure_gamma0'] = public_df['structure_gamma0'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    public_df['structure_gamma1'] = public_df['structure_gamma1'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    public_df['structure_gamma2'] = public_df['structure_gamma2'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    public_df['structure_gamma3'] = public_df['structure_gamma3'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    public_df['predicted_loop_type'] = public_df['predicted_loop_type'].apply(lambda x: [token2int2[ele] for ele in x])\n",
    "    public_inputs = np.transpose(np.array(public_df[['sequence', 'structure', 'structure_gamma0', 'structure_gamma1', \n",
    "                                            'structure_gamma2', 'structure_gamma3','predicted_loop_type']].values.tolist()), (0, 2, 1))\n",
    "    \n",
    "\n",
    "    private_df['sequence'] = private_df['sequence'].apply(lambda x: [token2int0[ele] for ele in x])\n",
    "    private_df['structure'] = private_df['structure'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    private_df['structure_gamma0'] = private_df['structure_gamma0'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    private_df['structure_gamma1'] = private_df['structure_gamma1'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    private_df['structure_gamma2'] = private_df['structure_gamma2'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    private_df['structure_gamma3'] = private_df['structure_gamma3'].apply(lambda x: [token2int1[ele] for ele in x])\n",
    "    private_df['predicted_loop_type'] = private_df['predicted_loop_type'].apply(lambda x: [token2int2[ele] for ele in x])\n",
    "    private_inputs = np.transpose(np.array(private_df[['sequence', 'structure', 'structure_gamma0', 'structure_gamma1', \n",
    "                                            'structure_gamma2', 'structure_gamma3','predicted_loop_type']].values.tolist()), (0, 2, 1))\n",
    "\n",
    "    public_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in public_df['id']])\n",
    "    public_bpps = public_bpps[:, :, np.newaxis]\n",
    "    \n",
    "    private_bpps = np.stack([1 - np.load(f'../input/bpps/{ele}.npy').sum(1) for ele in private_df['id']])\n",
    "    private_bpps = private_bpps[:, :, np.newaxis] \n",
    "\n",
    "    # Caveat: The prediction format requires the output to be the same length as the input,\n",
    "    # although it's not the case for the training data.\n",
    "    model_short = build_model(seq_len=107, pred_len=107)\n",
    "    model_long = build_model(seq_len=130, pred_len=130)\n",
    "\n",
    "    model_short.load_weights('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_newStruc_815.h5')\n",
    "    model_long.load_weights('tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_newStruc_815.h5')\n",
    "\n",
    "    public_preds, outputs2 = model_short.predict([public_inputs, public_bpps])\n",
    "    private_preds, outputs2 = model_long.predict([private_inputs,private_bpps])\n",
    "    \n",
    "    public_preds_array.append(public_preds)\n",
    "    public_preds_array.append(private_preds)\n",
    "\n",
    "    print(public_preds.shape, private_preds.shape)\n",
    "\n",
    "    preds_ls = []\n",
    "\n",
    "    for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
    "        for idx, uid in enumerate(df.id):\n",
    "            single_pred = preds[idx]\n",
    "\n",
    "            single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "            preds_ls.append(single_df)\n",
    "\n",
    "    preds_df = pd.concat(preds_ls)\n",
    "\n",
    "    submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "    submission.to_csv(f'submission_tf_simple_lstm_large_noise_more_epochs_bpps_large_new_loss_transformer_threeEmbedding_gru_twoloss_newStruc_815_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, uid in enumerate(train.id):\n",
    "#     single_pred = oofs_pred[i]\n",
    "\n",
    "#     oof_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "#     oof_df['id_seqpos'] = [f'{uid}_{x}' for x in range(oof_df.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gru 가 들어가면 좋은게 long term corelation 이 있는 것 아닐까...꼬이고 하니까\n",
    "- Positional encoding 넣으면 확 뛸거 같은디"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lyh",
   "language": "python",
   "name": "lyh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "duration": 161.997015,
   "end_time": "2020-09-12T05:49:46.470488",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-12T05:47:04.473473",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
